"""
Panelå¯è§†åŒ–è®­ç»ƒPipeline UI (Colabä¼˜åŒ–ç‰ˆ)
====================================

åŠŸèƒ½ï¼š
- åˆ†æ­¥éª¤å¯è§†åŒ–å±•ç¤ºå®Œæ•´è®­ç»ƒæµç¨‹
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- æ•°æ®å¯è§†åŒ–
- æ¨¡å‹è®­ç»ƒæ›²çº¿
- æ€§èƒ½å¯¹æ¯”å›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨Colabä¸­ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶

ä½œè€…ï¼šQuant-Stock-Transformer Team
ç‰ˆæœ¬ï¼š2.0.0 (Panelç‰ˆ)
"""

import panel as pn
import json
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import torch
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, Tuple, Optional
import io
from IPython.display import display, clear_output

# å¯¼å…¥pipelineæ¨¡å—
from complete_training_pipeline import (
    StockDataFetcher,
    StockDataProcessor,
    DualOutputSST,
    ModelTrainer,
    ModelEvaluator,
    LSTMTemporalPredictor,
    GRUTemporalPredictor,
    TCNTemporalPredictor,
    TemporalDataset
)
from torch.utils.data import DataLoader

# åˆå§‹åŒ–Panel
pn.extension('plotly', 'tabulator', sizing_mode="stretch_width")

# è®¾ç½®ç»˜å›¾æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# å…¨å±€çŠ¶æ€å­˜å‚¨
class PipelineState:
    """å­˜å‚¨pipelineæ‰§è¡ŒçŠ¶æ€"""
    def __init__(self):
        self.stocks_json = None
        self.historical_data = None
        self.processed_data = None
        self.sst_model = None
        self.lstm_model = None
        self.gru_model = None
        self.tcn_model = None
        self.trainer = None
        self.evaluator = None
        self.results = {}
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

state = PipelineState()


# ============================================================================
# æ­¥éª¤1ï¼šåŠ è½½è‚¡ç¥¨JSON
# ============================================================================

def load_stocks_json(event):
    """åŠ è½½å¹¶æ˜¾ç¤ºè‚¡ç¥¨åˆ—è¡¨"""
    try:
        json_file = file_input.value
        if json_file is None:
            step1_status.object = "âŒ è¯·ä¸Šä¼ JSONæ–‡ä»¶"
            return

        # è¯»å–JSON
        stocks_json = json.loads(json_file.decode('utf-8'))
        state.stocks_json = stocks_json

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_stocks = sum(len(v) for v in stocks_json.values())

        stats_text = f"""
## âœ… è‚¡ç¥¨åˆ—è¡¨åŠ è½½æˆåŠŸ

**æ€»è‚¡ç¥¨æ•°**: {total_stocks}åª

**å¸‚åœºåˆ†å¸ƒ**:
"""
        for market, stocks in stocks_json.items():
            stats_text += f"- **{market}å¸‚åœº**: {len(stocks)}åª\n"

        step1_status.object = stats_text

        # ç”Ÿæˆè¯¦ç»†è¡¨æ ¼
        rows = []
        for market, stocks in stocks_json.items():
            for stock in stocks:
                rows.append({
                    'å¸‚åœº': market,
                    'ä»£ç ': stock['symbol'],
                    'åç§°': stock['name'],
                    'ç±»åˆ«': stock.get('category', 'N/A'),
                    'ç†ç”±': stock.get('reason', 'N/A')
                })

        df = pd.DataFrame(rows)
        stocks_table.value = df

        # ç”Ÿæˆå¸‚åœºåˆ†å¸ƒé¥¼å›¾
        market_counts = {market: len(stocks) for market, stocks in stocks_json.items()}
        fig = px.pie(
            values=list(market_counts.values()),
            names=list(market_counts.keys()),
            title='è‚¡ç¥¨å¸‚åœºåˆ†å¸ƒ'
        )
        market_chart.object = fig

    except Exception as e:
        step1_status.object = f"âŒ åŠ è½½å¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤2ï¼šæ•°æ®æŠ“å–
# ============================================================================

def fetch_historical_data(event):
    """æŠ“å–å†å²æ•°æ®"""
    try:
        if state.stocks_json is None:
            step2_status.object = "âŒ è¯·å…ˆåŠ è½½è‚¡ç¥¨JSON"
            return

        step2_status.object = "â³ æ­£åœ¨æŠ“å–æ•°æ®..."

        fetcher = StockDataFetcher()

        # æŠ“å–æ•°æ®
        historical_data = fetcher.fetch_historical_data(
            stocks_json=state.stocks_json,
            start_date=start_date_input.value,
            end_date=end_date_input.value,
            interval="1d",
            include_market_index=True,
            batch_size=int(batch_size_input.value),
            delay_between_batches=float(delay_input.value)
        )

        state.historical_data = historical_data
        fetcher.save_data("historical_data.pkl")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… æ•°æ®æŠ“å–å®Œæˆ

**æ—¥æœŸèŒƒå›´**: {start_date_input.value} è‡³ {end_date_input.value}
**ç›®æ ‡å¸‚åœº**: {target_market_input.value}

**æ•°æ®ç»Ÿè®¡**:
"""

        rows = []
        for market, stocks_data in historical_data.items():
            for symbol, df in stocks_data.items():
                rows.append({
                    'å¸‚åœº': market,
                    'ä»£ç ': symbol,
                    'æ•°æ®æ¡æ•°': len(df),
                    'å¼€å§‹æ—¥æœŸ': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else 'N/A',
                    'ç»“æŸæ—¥æœŸ': df.index[-1].strftime('%Y-%m-%d') if len(df) > 0 else 'N/A'
                })

        df_stats = pd.DataFrame(rows)
        fetch_table.value = df_stats

        # æ£€æŸ¥ç›®æ ‡å¸‚åœºçš„æ•°æ®
        target_market = target_market_input.value
        if target_market in historical_data:
            market_data = historical_data[target_market]
            stats_text += f"\n**{target_market}å¸‚åœº**: æˆåŠŸè·å–{len(market_data)}æ”¯è‚¡ç¥¨æ•°æ®\n"
        else:
            stats_text += f"\nâš ï¸ **{target_market}å¸‚åœºæ•°æ®æœªæ‰¾åˆ°**\n"

        step2_status.object = stats_text

    except Exception as e:
        step2_status.object = f"âŒ æ•°æ®æŠ“å–å¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤3ï¼šæ•°æ®é¢„å¤„ç†
# ============================================================================

def preprocess_data(event):
    """æ•°æ®é¢„å¤„ç†"""
    try:
        if state.historical_data is None:
            step3_status.object = "âŒ è¯·å…ˆæŠ“å–å†å²æ•°æ®"
            return

        step3_status.object = "â³ æ­£åœ¨é¢„å¤„ç†æ•°æ®..."

        processor = StockDataProcessor(
            historical_data=state.historical_data,
            target_market=target_market_input.value,
            target_stock=target_stock_input.value
        )

        X, y_T, y_T1, dates = processor.prepare_training_data()

        # æ•°æ®é›†åˆ’åˆ†
        train_size = int(0.7 * len(X))
        val_size = int(0.15 * len(X))

        X_train = X[:train_size]
        y_T_train = y_T[:train_size]
        y_T1_train = y_T1[:train_size]

        X_val = X[train_size:train_size+val_size]
        y_T_val = y_T[train_size:train_size+val_size]
        y_T1_val = y_T1[train_size:train_size+val_size]

        X_test = X[train_size+val_size:]
        y_T_test = y_T[train_size+val_size:]
        y_T1_test = y_T1[train_size+val_size:]

        # ä¿å­˜åˆ°çŠ¶æ€
        state.processed_data = {
            'X_train': X_train, 'y_T_train': y_T_train, 'y_T1_train': y_T1_train,
            'X_val': X_val, 'y_T_val': y_T_val, 'y_T1_val': y_T1_val,
            'X_test': X_test, 'y_T_test': y_T_test, 'y_T1_test': y_T1_test,
            'dates': dates,
            'processor': processor
        }

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ

**ç›®æ ‡è‚¡ç¥¨**: {target_market_input.value} - {target_stock_input.value}

**æ•°æ®é›†åˆ’åˆ†**:
- è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ (70%)
- éªŒè¯é›†: {len(X_val)} æ ·æœ¬ (15%)
- æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬ (15%)

**ç‰¹å¾ç»´åº¦**: {X.shape[1]}

**ç›®æ ‡å˜é‡**:
- Tæ—¥æ”¶ç›Šç‡: {y_T.shape}
- T+1æ—¥æ”¶ç›Šç‡: {y_T1.shape}
"""

        step3_status.object = stats_text

        # ç»˜åˆ¶æ”¶ç›Šç‡åˆ†å¸ƒ
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))

        axes[0].hist(y_T_train, bins=50, alpha=0.7, edgecolor='black')
        axes[0].set_title('Tæ—¥æ”¶ç›Šç‡åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰')
        axes[0].set_xlabel('æ”¶ç›Šç‡')
        axes[0].set_ylabel('é¢‘æ•°')
        axes[0].grid(True, alpha=0.3)

        axes[1].hist(y_T1_train, bins=50, alpha=0.7, edgecolor='black')
        axes[1].set_title('T+1æ—¥æ”¶ç›Šç‡åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰')
        axes[1].set_xlabel('æ”¶ç›Šç‡')
        axes[1].set_ylabel('é¢‘æ•°')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        preprocess_plot.object = fig
        plt.close(fig)

    except Exception as e:
        step3_status.object = f"âŒ é¢„å¤„ç†å¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤4ï¼šSSTæ¨¡å‹è®­ç»ƒ
# ============================================================================

def train_sst_model(event):
    """è®­ç»ƒSSTæ¨¡å‹"""
    try:
        if state.processed_data is None:
            step4_status.object = "âŒ è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†"
            return

        step4_status.object = "â³ æ­£åœ¨è®­ç»ƒSSTæ¨¡å‹..."

        # è·å–æ•°æ®
        data = state.processed_data
        num_features = data['X_train'].shape[1]

        # åˆ›å»ºæ¨¡å‹
        sst_model = DualOutputSST(
            num_boundary_sensors=num_features,
            num_target_sensors=1,
            d_model=128,
            nhead=8,
            num_layers=3,
            dropout=0.1,
            enable_feature_extraction=True
        ).to(state.device)

        state.sst_model = sst_model

        # åˆ›å»ºè®­ç»ƒå™¨
        if state.trainer is None:
            state.trainer = ModelTrainer(device=state.device)

        # è®­ç»ƒ
        history = state.trainer.train_sst(
            sst_model,
            data['X_train'], data['y_T_train'], data['y_T1_train'],
            data['X_val'], data['y_T_val'], data['y_T1_val'],
            epochs=int(sst_epochs_input.value),
            batch_size=int(sst_batch_size_input.value),
            lr=float(sst_lr_input.value),
            verbose=False
        )

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        best_val_loss = min(history['val_loss'])
        final_train_loss = history['train_loss'][-1]

        stats_text = f"""
## âœ… SSTæ¨¡å‹è®­ç»ƒå®Œæˆ

**æ¨¡å‹å‚æ•°**: {sum(p.numel() for p in sst_model.parameters()):,}

**è®­ç»ƒé…ç½®**:
- Epochs: {sst_epochs_input.value}
- Batch Size: {sst_batch_size_input.value}
- Learning Rate: {sst_lr_input.value}

**è®­ç»ƒç»“æœ**:
- æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}
- æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}
"""

        step4_status.object = stats_text

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # æ€»æŸå¤±
        axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)
        axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)
        axes[0].set_title('SSTè®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # Tå’ŒT+1åˆ†åˆ«çš„æŸå¤±
        axes[1].plot(history['train_loss_T'], label='Train Loss (Tæ—¥)', linewidth=2)
        axes[1].plot(history['train_loss_T1'], label='Train Loss (T+1æ—¥)', linewidth=2)
        axes[1].plot(history['val_loss_T'], label='Val Loss (Tæ—¥)', linewidth=2, linestyle='--')
        axes[1].plot(history['val_loss_T1'], label='Val Loss (T+1æ—¥)', linewidth=2, linestyle='--')
        axes[1].set_title('SSTåˆ†é¡¹æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        sst_plot.object = fig
        plt.close(fig)

    except Exception as e:
        step4_status.object = f"âŒ SSTè®­ç»ƒå¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤5ï¼šç‰¹å¾æå–
# ============================================================================

def extract_features(event):
    """æå–SSTå†…éƒ¨ç‰¹å¾"""
    try:
        if state.sst_model is None:
            step5_status.object = "âŒ è¯·å…ˆè®­ç»ƒSSTæ¨¡å‹"
            return

        step5_status.object = "â³ æ­£åœ¨æå–ç‰¹å¾..."

        data = state.processed_data

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T_all = np.vstack([data['y_T_train'], data['y_T_val'], data['y_T_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])

        # æå–ç‰¹å¾
        state.sst_model.eval()
        with torch.no_grad():
            X_all_t = torch.FloatTensor(X_all).to(state.device)
            (pred_T, pred_T1), features = state.sst_model.forward_with_features(
                X_all_t,
                return_attention=True,
                return_encoder_output=True
            )

            encoder_output = features['encoder_output'].cpu().numpy()
            pooled_features = features['pooled_features'].cpu().numpy()

            # è®¡ç®—æ®‹å·®
            residual_T = y_T_all - pred_T.cpu().numpy()
            residual_T1 = y_T1_all - pred_T1.cpu().numpy()

        # ä¿å­˜ç‰¹å¾
        state.processed_data['encoder_output'] = encoder_output
        state.processed_data['pooled_features'] = pooled_features
        state.processed_data['residual_T'] = residual_T
        state.processed_data['residual_T1'] = residual_T1

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… ç‰¹å¾æå–å®Œæˆ

**æå–çš„ç‰¹å¾**:
- Encoderè¾“å‡º: {encoder_output.shape}
- æ± åŒ–ç‰¹å¾: {pooled_features.shape}
- Tæ—¥æ®‹å·®: {residual_T.shape}
- T+1æ—¥æ®‹å·®: {residual_T1.shape}

**ç‰¹å¾ç»Ÿè®¡**:
- æ± åŒ–ç‰¹å¾å‡å€¼: {np.mean(pooled_features):.6f}
- æ± åŒ–ç‰¹å¾æ ‡å‡†å·®: {np.std(pooled_features):.6f}
"""

        step5_status.object = stats_text

        # ç»˜åˆ¶ç‰¹å¾å¯è§†åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # æ± åŒ–ç‰¹å¾åˆ†å¸ƒ
        axes[0, 0].hist(pooled_features.flatten(), bins=50, alpha=0.7, edgecolor='black')
        axes[0, 0].set_title('æ± åŒ–ç‰¹å¾åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[0, 0].set_xlabel('ç‰¹å¾å€¼')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].grid(True, alpha=0.3)

        # æ®‹å·®åˆ†å¸ƒ
        axes[0, 1].hist(residual_T1.flatten(), bins=50, alpha=0.7, edgecolor='black', color='orange')
        axes[0, 1].set_title('T+1æ—¥é¢„æµ‹æ®‹å·®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[0, 1].set_xlabel('æ®‹å·®')
        axes[0, 1].set_ylabel('é¢‘æ•°')
        axes[0, 1].grid(True, alpha=0.3)

        # æ± åŒ–ç‰¹å¾çƒ­å›¾ï¼ˆå‰10ç»´ï¼‰
        feature_sample = pooled_features[:100, :10]
        im = axes[1, 0].imshow(feature_sample.T, aspect='auto', cmap='viridis')
        axes[1, 0].set_title('æ± åŒ–ç‰¹å¾çƒ­å›¾ï¼ˆæ ·æœ¬Ã—ç‰¹å¾ï¼‰', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('æ ·æœ¬')
        axes[1, 0].set_ylabel('ç‰¹å¾ç»´åº¦')
        plt.colorbar(im, ax=axes[1, 0])

        # æ®‹å·®æ—¶é—´åºåˆ—
        axes[1, 1].plot(residual_T1[:500], alpha=0.7, linewidth=1)
        axes[1, 1].set_title('T+1æ—¥æ®‹å·®æ—¶é—´åºåˆ—ï¼ˆå‰500æ ·æœ¬ï¼‰', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('æ ·æœ¬ç´¢å¼•')
        axes[1, 1].set_ylabel('æ®‹å·®')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].axhline(y=0, color='r', linestyle='--', linewidth=1)

        plt.tight_layout()

        extract_plot.object = fig
        plt.close(fig)

    except Exception as e:
        step5_status.object = f"âŒ ç‰¹å¾æå–å¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤6ï¼šæ—¶åºæ¨¡å‹è®­ç»ƒ
# ============================================================================

def train_temporal_models(event):
    """è®­ç»ƒæ—¶åºæ¨¡å‹"""
    try:
        if 'pooled_features' not in state.processed_data:
            step6_status.object = "âŒ è¯·å…ˆæå–ç‰¹å¾"
            return

        model_type = temporal_model_type_input.value
        step6_status.object = f"â³ æ­£åœ¨è®­ç»ƒ{model_type}æ¨¡å‹..."

        data = state.processed_data

        # å‡†å¤‡æ•°æ®
        train_size = len(data['X_train'])
        val_size = len(data['X_val'])

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])
        pooled_features = data['pooled_features']

        # åˆ›å»ºæ—¶åºæ•°æ®é›†
        target_stock_features = torch.FloatTensor(X_all)
        relationship_features = torch.FloatTensor(pooled_features)
        targets = torch.FloatTensor(y_T1_all)

        seq_len = int(temporal_seq_len_input.value)

        train_dataset = TemporalDataset(
            target_stock_features=target_stock_features[:train_size],
            relationship_features=relationship_features[:train_size],
            targets=targets[:train_size],
            seq_len=seq_len
        )

        val_dataset = TemporalDataset(
            target_stock_features=target_stock_features[train_size:train_size+val_size],
            relationship_features=relationship_features[train_size:train_size+val_size],
            targets=targets[train_size:train_size+val_size],
            seq_len=seq_len
        )

        train_loader = DataLoader(train_dataset, batch_size=int(temporal_batch_size_input.value), shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=int(temporal_batch_size_input.value), shuffle=False)

        # åˆ›å»ºæ¨¡å‹
        input_dim = X_all.shape[1] + pooled_features.shape[1]

        if model_type == 'LSTM':
            model = LSTMTemporalPredictor(
                input_dim=input_dim,
                hidden_dim=128,
                num_layers=2,
                output_dim=1,
                use_attention=True
            ).to(state.device)
            state.lstm_model = model
        elif model_type == 'GRU':
            model = GRUTemporalPredictor(
                input_dim=input_dim,
                hidden_dim=128,
                num_layers=2,
                output_dim=1,
                use_attention=True
            ).to(state.device)
            state.gru_model = model
        elif model_type == 'TCN':
            model = TCNTemporalPredictor(
                input_dim=input_dim,
                num_channels=[64, 128, 128, 64],
                kernel_size=3,
                output_dim=1
            ).to(state.device)
            state.tcn_model = model
        else:
            step6_status.object = f"âŒ æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}"
            return

        # è®­ç»ƒ
        if state.trainer is None:
            state.trainer = ModelTrainer(device=state.device)

        history = state.trainer.train_temporal_model(
            model,
            train_loader,
            val_loader,
            epochs=int(temporal_epochs_input.value),
            lr=float(temporal_lr_input.value),
            model_name=model_type,
            verbose=False
        )

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        best_val_loss = min(history['val_loss'])
        final_train_loss = history['train_loss'][-1]

        stats_text = f"""
## âœ… {model_type}æ¨¡å‹è®­ç»ƒå®Œæˆ

**æ¨¡å‹å‚æ•°**: {sum(p.numel() for p in model.parameters()):,}

**è®­ç»ƒé…ç½®**:
- Epochs: {temporal_epochs_input.value}
- Batch Size: {temporal_batch_size_input.value}
- Learning Rate: {temporal_lr_input.value}
- Sequence Length: {seq_len}

**è®­ç»ƒç»“æœ**:
- æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}
- æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}

**æ•°æ®é›†**:
- è®­ç»ƒæ ·æœ¬: {len(train_dataset)}
- éªŒè¯æ ·æœ¬: {len(val_dataset)}
"""

        step6_status.object = stats_text

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        fig, ax = plt.subplots(figsize=(10, 6))

        ax.plot(history['train_loss'], label='Train Loss', linewidth=2)
        ax.plot(history['val_loss'], label='Val Loss', linewidth=2)
        ax.set_title(f'{model_type}è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.legend()
        ax.grid(True, alpha=0.3)

        plt.tight_layout()

        temporal_plot.object = fig
        plt.close(fig)

    except Exception as e:
        step6_status.object = f"âŒ {model_type}è®­ç»ƒå¤±è´¥: {str(e)}"


# ============================================================================
# æ­¥éª¤7ï¼šæ¨¡å‹è¯„ä¼°
# ============================================================================

def evaluate_all_models(event):
    """è¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
    try:
        if state.sst_model is None:
            step7_status.object = "âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹"
            return

        step7_status.object = "â³ æ­£åœ¨è¯„ä¼°æ¨¡å‹..."

        # åˆ›å»ºè¯„ä¼°å™¨
        if state.evaluator is None:
            state.evaluator = ModelEvaluator(device=state.device)

        data = state.processed_data

        # è¯„ä¼°SST
        sst_metrics = state.evaluator.evaluate_sst(
            state.sst_model,
            data['X_test'],
            data['y_T_test'],
            data['y_T1_test'],
            model_name='SST'
        )

        # å‡†å¤‡æ—¶åºæ¨¡å‹æµ‹è¯•æ•°æ®
        train_size = len(data['X_train'])
        val_size = len(data['X_val'])

        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])
        pooled_features = data['pooled_features']

        target_stock_features = torch.FloatTensor(X_all)
        relationship_features = torch.FloatTensor(pooled_features)
        targets = torch.FloatTensor(y_T1_all)

        seq_len = int(eval_seq_len_input.value)

        test_dataset = TemporalDataset(
            target_stock_features=target_stock_features[train_size+val_size:],
            relationship_features=relationship_features[train_size+val_size:],
            targets=targets[train_size+val_size:],
            seq_len=seq_len
        )

        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

        # è¯„ä¼°æ—¶åºæ¨¡å‹
        if state.lstm_model is not None:
            lstm_metrics = state.evaluator.evaluate_temporal_model(
                state.lstm_model, test_loader, model_name='LSTM'
            )

        if state.gru_model is not None:
            gru_metrics = state.evaluator.evaluate_temporal_model(
                state.gru_model, test_loader, model_name='GRU'
            )

        if state.tcn_model is not None:
            tcn_metrics = state.evaluator.evaluate_temporal_model(
                state.tcn_model, test_loader, model_name='TCN'
            )

        # ç”Ÿæˆå¯¹æ¯”
        comparison_df = state.evaluator.compare_models()

        # ç”Ÿæˆç»Ÿè®¡æ–‡æœ¬
        stats_text = """
## âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ

**å·²è¯„ä¼°çš„æ¨¡å‹**:
"""
        for model_name in state.evaluator.results.keys():
            stats_text += f"- {model_name}\n"

        stats_text += "\nè¯¦ç»†æŒ‡æ ‡è¯·æŸ¥çœ‹ä¸‹æ–¹å¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨ã€‚"

        step7_status.object = stats_text
        eval_table.value = comparison_df

        # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        models = list(state.evaluator.results.keys())

        # æ—¶åºæ¨¡å‹çš„æŒ‡æ ‡ï¼ˆæ’é™¤SSTï¼‰
        temporal_models = [m for m in models if m != 'SST']

        if len(temporal_models) > 0:
            mse_values = [state.evaluator.results[m]['metrics']['MSE'] for m in temporal_models]
            mae_values = [state.evaluator.results[m]['metrics']['MAE'] for m in temporal_models]
            dir_acc_values = [state.evaluator.results[m]['metrics']['Direction_Acc'] for m in temporal_models]
            sharpe_values = [state.evaluator.results[m]['metrics']['Sharpe_Ratio'] for m in temporal_models]

            # MSEå¯¹æ¯”
            axes[0, 0].bar(temporal_models, mse_values, alpha=0.7, edgecolor='black')
            axes[0, 0].set_title('MSEå¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[0, 0].set_ylabel('MSE')
            axes[0, 0].grid(True, alpha=0.3, axis='y')

            # MAEå¯¹æ¯”
            axes[0, 1].bar(temporal_models, mae_values, alpha=0.7, edgecolor='black', color='orange')
            axes[0, 1].set_title('MAEå¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[0, 1].set_ylabel('MAE')
            axes[0, 1].grid(True, alpha=0.3, axis='y')

            # Direction Accuracyå¯¹æ¯”
            axes[1, 0].bar(temporal_models, dir_acc_values, alpha=0.7, edgecolor='black', color='green')
            axes[1, 0].set_title('æ–¹å‘å‡†ç¡®ç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[1, 0].set_ylabel('å‡†ç¡®ç‡')
            axes[1, 0].axhline(y=0.5, color='r', linestyle='--', linewidth=1, label='éšæœºçŒœæµ‹')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3, axis='y')

            # Sharpe Ratioå¯¹æ¯”
            axes[1, 1].bar(temporal_models, sharpe_values, alpha=0.7, edgecolor='black', color='purple')
            axes[1, 1].set_title('Sharpeæ¯”ç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[1, 1].set_ylabel('Sharpe Ratio')
            axes[1, 1].grid(True, alpha=0.3, axis='y')

        plt.tight_layout()

        eval_plot.object = fig
        plt.close(fig)

    except Exception as e:
        step7_status.object = f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}"


# ============================================================================
# åˆ›å»ºUIç»„ä»¶
# ============================================================================

# æ­¥éª¤1ç»„ä»¶
file_input = pn.widgets.FileInput(accept='.json', name='ä¸Šä¼ JSONæ–‡ä»¶')
load_btn = pn.widgets.Button(name='ğŸ“¥ åŠ è½½è‚¡ç¥¨åˆ—è¡¨', button_type='primary')
step1_status = pn.pane.Markdown("ç­‰å¾…ä¸Šä¼ JSONæ–‡ä»¶...")
stocks_table = pn.widgets.Tabulator(pd.DataFrame(), width=800, height=300)
market_chart = pn.pane.Plotly()

load_btn.on_click(load_stocks_json)

step1 = pn.Column(
    "## ğŸ“‹ æ­¥éª¤1: åŠ è½½è‚¡ç¥¨JSON",
    pn.Row(file_input, load_btn),
    step1_status,
    stocks_table,
    market_chart
)

# æ­¥éª¤2ç»„ä»¶
target_market_input = pn.widgets.Select(name='ç›®æ ‡å¸‚åœº', options=['US', 'CN', 'HK', 'JP'], value='CN')
start_date_input = pn.widgets.TextInput(name='å¼€å§‹æ—¥æœŸ', value='2020-01-01')
end_date_input = pn.widgets.TextInput(name='ç»“æŸæ—¥æœŸ', value='2024-12-31')
batch_size_input = pn.widgets.IntSlider(name='æ‰¹é‡å¤§å°', start=1, end=10, value=5)
delay_input = pn.widgets.FloatSlider(name='æ‰¹æ¬¡é—´å»¶è¿Ÿ(ç§’)', start=0.5, end=5.0, value=2.0, step=0.5)
fetch_btn = pn.widgets.Button(name='ğŸ“¥ å¼€å§‹æŠ“å–æ•°æ®', button_type='primary')
step2_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹æ•°æ®æŠ“å–...")
fetch_table = pn.widgets.Tabulator(pd.DataFrame(), width=800, height=300)

fetch_btn.on_click(fetch_historical_data)

step2 = pn.Column(
    "## ğŸ“Š æ­¥éª¤2: æ•°æ®æŠ“å–",
    pn.Row(
        pn.Column(target_market_input, start_date_input, end_date_input),
        pn.Column(batch_size_input, delay_input)
    ),
    fetch_btn,
    step2_status,
    fetch_table
)

# æ­¥éª¤3ç»„ä»¶
target_stock_input = pn.widgets.TextInput(name='ç›®æ ‡è‚¡ç¥¨ä»£ç ', value='600519')
preprocess_btn = pn.widgets.Button(name='ğŸ”„ å¼€å§‹é¢„å¤„ç†', button_type='primary')
step3_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹é¢„å¤„ç†...")
preprocess_plot = pn.pane.Matplotlib()

preprocess_btn.on_click(preprocess_data)

step3 = pn.Column(
    "## ğŸ”„ æ­¥éª¤3: æ•°æ®é¢„å¤„ç†",
    target_stock_input,
    preprocess_btn,
    step3_status,
    preprocess_plot
)

# æ­¥éª¤4ç»„ä»¶
sst_epochs_input = pn.widgets.IntSlider(name='è®­ç»ƒè½®æ•°', start=10, end=200, value=50, step=10)
sst_batch_size_input = pn.widgets.IntSlider(name='æ‰¹é‡å¤§å°', start=8, end=128, value=32, step=8)
sst_lr_input = pn.widgets.FloatInput(name='å­¦ä¹ ç‡', value=0.001, step=0.0001)
sst_train_btn = pn.widgets.Button(name='ğŸš€ å¼€å§‹è®­ç»ƒSST', button_type='primary')
step4_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
sst_plot = pn.pane.Matplotlib()

sst_train_btn.on_click(train_sst_model)

step4 = pn.Column(
    "## ğŸ§  æ­¥éª¤4: SSTæ¨¡å‹è®­ç»ƒ",
    pn.Row(
        pn.Column(sst_epochs_input, sst_batch_size_input),
        pn.Column(sst_lr_input)
    ),
    sst_train_btn,
    step4_status,
    sst_plot
)

# æ­¥éª¤5ç»„ä»¶
extract_btn = pn.widgets.Button(name='ğŸ” å¼€å§‹ç‰¹å¾æå–', button_type='primary')
step5_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹ç‰¹å¾æå–...")
extract_plot = pn.pane.Matplotlib()

extract_btn.on_click(extract_features)

step5 = pn.Column(
    "## ğŸ” æ­¥éª¤5: ç‰¹å¾æå–",
    extract_btn,
    step5_status,
    extract_plot
)

# æ­¥éª¤6ç»„ä»¶
temporal_model_type_input = pn.widgets.Select(name='æ¨¡å‹ç±»å‹', options=['LSTM', 'GRU', 'TCN'], value='LSTM')
temporal_epochs_input = pn.widgets.IntSlider(name='è®­ç»ƒè½®æ•°', start=10, end=200, value=100, step=10)
temporal_batch_size_input = pn.widgets.IntSlider(name='æ‰¹é‡å¤§å°', start=8, end=128, value=32, step=8)
temporal_lr_input = pn.widgets.FloatInput(name='å­¦ä¹ ç‡', value=0.001, step=0.0001)
temporal_seq_len_input = pn.widgets.IntSlider(name='åºåˆ—é•¿åº¦', start=20, end=120, value=60, step=10)
temporal_train_btn = pn.widgets.Button(name='ğŸš€ å¼€å§‹è®­ç»ƒæ—¶åºæ¨¡å‹', button_type='primary')
step6_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹è®­ç»ƒ...")
temporal_plot = pn.pane.Matplotlib()

temporal_train_btn.on_click(train_temporal_models)

step6 = pn.Column(
    "## â° æ­¥éª¤6: æ—¶åºæ¨¡å‹è®­ç»ƒ",
    pn.Row(
        pn.Column(temporal_model_type_input, temporal_epochs_input, temporal_batch_size_input),
        pn.Column(temporal_lr_input, temporal_seq_len_input)
    ),
    temporal_train_btn,
    step6_status,
    temporal_plot
)

# æ­¥éª¤7ç»„ä»¶
eval_seq_len_input = pn.widgets.IntSlider(name='åºåˆ—é•¿åº¦ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰', start=20, end=120, value=60, step=10)
eval_btn = pn.widgets.Button(name='ğŸ“Š å¼€å§‹è¯„ä¼°', button_type='primary')
step7_status = pn.pane.Markdown("ç­‰å¾…å¼€å§‹è¯„ä¼°...")
eval_table = pn.widgets.Tabulator(pd.DataFrame(), width=800, height=300)
eval_plot = pn.pane.Matplotlib()

eval_btn.on_click(evaluate_all_models)

step7 = pn.Column(
    "## ğŸ“ˆ æ­¥éª¤7: æ¨¡å‹è¯„ä¼°",
    eval_seq_len_input,
    eval_btn,
    step7_status,
    eval_table,
    eval_plot
)

# ä½¿ç”¨è¯´æ˜
usage_doc = pn.pane.Markdown("""
## ğŸ“– ä½¿ç”¨æµç¨‹

### 1ï¸âƒ£ åŠ è½½è‚¡ç¥¨JSON
- ä¸Šä¼ ä½ çš„è‚¡ç¥¨é€‰æ‹©JSONæ–‡ä»¶ï¼ˆå¦‚`data/demo.json`ï¼‰
- æŸ¥çœ‹è‚¡ç¥¨åˆ—è¡¨å’Œå¸‚åœºåˆ†å¸ƒ

### 2ï¸âƒ£ æ•°æ®æŠ“å–
- é€‰æ‹©ç›®æ ‡å¸‚åœºï¼ˆUS/CN/HK/JPï¼‰
- è®¾ç½®æ—¥æœŸèŒƒå›´
- é…ç½®æ‰¹é‡æŠ“å–å‚æ•°ï¼ˆé¿å…APIé™æµï¼‰
- ç‚¹å‡»"å¼€å§‹æŠ“å–æ•°æ®"

### 3ï¸âƒ£ æ•°æ®é¢„å¤„ç†
- è¾“å…¥ç›®æ ‡è‚¡ç¥¨ä»£ç 
- è‡ªåŠ¨è®¡ç®—æ”¶ç›Šç‡
- æ•°æ®é›†åˆ’åˆ†ï¼ˆ70% train, 15% val, 15% testï¼‰

### 4ï¸âƒ£ SSTæ¨¡å‹è®­ç»ƒ
- é…ç½®è®­ç»ƒå‚æ•°ï¼ˆepochs, batch size, learning rateï¼‰
- è®­ç»ƒåŒè¾“å‡ºSSTæ¨¡å‹
- æŸ¥çœ‹è®­ç»ƒæ›²çº¿

### 5ï¸âƒ£ ç‰¹å¾æå–
- ä»SSTæ¨¡å‹æå–å†…éƒ¨ç‰¹å¾
- åŒ…æ‹¬ï¼šEncoderè¾“å‡ºã€Attentionæƒé‡ã€æ± åŒ–ç‰¹å¾ã€æ®‹å·®

### 6ï¸âƒ£ æ—¶åºæ¨¡å‹è®­ç»ƒ
- é€‰æ‹©æ¨¡å‹ç±»å‹ï¼ˆLSTM/GRU/TCNï¼‰
- é…ç½®è®­ç»ƒå‚æ•°
- å¯ä»¥è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”

### 7ï¸âƒ£ æ¨¡å‹è¯„ä¼°
- è¯„ä¼°æ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹
- æŸ¥çœ‹æ€§èƒ½å¯¹æ¯”è¡¨å’Œå›¾è¡¨
- æŒ‡æ ‡ï¼šMSE, MAE, Direction Accuracy, Sharpe Ratio

---

## ğŸ’¡ æç¤º

- **æ•°æ®æŠ“å–**: å»ºè®®ä½¿ç”¨é»˜è®¤çš„æ‰¹é‡å‚æ•°ï¼Œé¿å…APIé™æµ
- **SSTè®­ç»ƒ**: 50ä¸ªepoché€šå¸¸è¶³å¤Ÿï¼Œå¯ä»¥å…ˆç”¨å°epochæ•°æµ‹è¯•
- **æ—¶åºæ¨¡å‹**: LSTMå’ŒGRUæ€§èƒ½æ¥è¿‘ï¼ŒTCNè®­ç»ƒæ›´å¿«
- **åºåˆ—é•¿åº¦**: 60å¤©æ˜¯å¸¸ç”¨å€¼ï¼Œå¯æ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

**SSTæ¨¡å‹**:
- åŒè¾“å‡ºæ¶æ„ï¼ˆTæ—¥ + T+1æ—¥ï¼‰
- Transformerç¼–ç å™¨ï¼ˆ8 heads, 3 layersï¼‰
- éšè—ç»´åº¦ï¼š128

**æ—¶åºæ¨¡å‹**:
- LSTM: 128 hidden, 2 layers, with Attention
- GRU: 128 hidden, 2 layers, with Attention
- TCN: [64, 128, 128, 64] channels

**è¯„ä¼°æŒ‡æ ‡**:
- MSE: å‡æ–¹è¯¯å·®
- MAE: å¹³å‡ç»å¯¹è¯¯å·®
- Direction Accuracy: æ–¹å‘å‡†ç¡®ç‡
- Sharpe Ratio: é£é™©è°ƒæ•´åæ”¶ç›Š

---

**Quant-Stock-Transformer Team** | Version 2.0.0 (Panelç‰ˆ)
""")

# åˆ›å»ºTabs
tabs = pn.Tabs(
    ('æ­¥éª¤1: åŠ è½½JSON', step1),
    ('æ­¥éª¤2: æ•°æ®æŠ“å–', step2),
    ('æ­¥éª¤3: æ•°æ®é¢„å¤„ç†', step3),
    ('æ­¥éª¤4: SSTè®­ç»ƒ', step4),
    ('æ­¥éª¤5: ç‰¹å¾æå–', step5),
    ('æ­¥éª¤6: æ—¶åºæ¨¡å‹è®­ç»ƒ', step6),
    ('æ­¥éª¤7: æ¨¡å‹è¯„ä¼°', step7),
    ('ä½¿ç”¨è¯´æ˜', usage_doc)
)

# åˆ›å»ºä¸»ç•Œé¢
dashboard = pn.template.MaterialTemplate(
    title='ğŸš€ è‚¡ç¥¨é¢„æµ‹æ¨¡å‹è®­ç»ƒPipeline (Panelç‰ˆ)',
    sidebar=[
        pn.pane.Markdown("""
## ğŸ“Š PipelineçŠ¶æ€

å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹å¯è§†åŒ–ç•Œé¢

**è®¾å¤‡**: {}

**åŠŸèƒ½**:
- âœ… é€‰è‚¡JSONå¯¼å…¥
- âœ… å†å²æ•°æ®è·å–
- âœ… æ•°æ®é¢„å¤„ç†
- âœ… SSTæ¨¡å‹è®­ç»ƒ
- âœ… ç‰¹å¾æå–
- âœ… æ—¶åºæ¨¡å‹è®­ç»ƒ
- âœ… æ¨¡å‹è¯„ä¼°å¯¹æ¯”

---

**æç¤º**:
1. æŒ‰ç…§æ­¥éª¤é¡ºåºæ‰§è¡Œ
2. æ¯æ­¥å®Œæˆåå†è¿›è¡Œä¸‹ä¸€æ­¥
3. å¯ä»¥éšæ—¶åˆ‡æ¢TabæŸ¥çœ‹ç»“æœ
        """.format(state.device))
    ],
    main=[tabs]
)


# ============================================================================
# å¯åŠ¨å‡½æ•°
# ============================================================================

def launch():
    """å¯åŠ¨Panelåº”ç”¨"""

    # æ£€æµ‹æ˜¯å¦åœ¨Colabç¯å¢ƒ
    try:
        import google.colab
        IN_COLAB = True
    except:
        IN_COLAB = False

    print("="*80)
    print("ğŸš€ è‚¡ç¥¨é¢„æµ‹Pipelineå¯è§†åŒ– - Panel UI")
    print("="*80)
    print(f"âœ… è®¾å¤‡: {state.device}")
    print(f"âœ… ç¯å¢ƒ: {'Colab' if IN_COLAB else 'æœ¬åœ°'}")
    print("âœ… Panelå·²åˆå§‹åŒ–")
    print("="*80)

    if IN_COLAB:
        print("\nğŸ“± Colabç¯å¢ƒæ£€æµ‹åˆ°!")
        print("ğŸ“ æç¤º: è¿è¡Œè¿”å›çš„å¯¹è±¡ä¼šåœ¨notebookä¸­ç›´æ¥æ˜¾ç¤ºUI")
        print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("   app = launch()")
        print("   app  # åœ¨æ–°cellä¸­è¿è¡Œè¿™è¡Œæ¥æ˜¾ç¤ºUI\n")
        print("="*80)

    # è¿”å›dashboardä»¥ä¾¿åœ¨Jupyter/Colabä¸­æ˜¾ç¤º
    return dashboard


if __name__ == "__main__":
    # æ£€æµ‹ç¯å¢ƒ
    try:
        import google.colab
        IN_COLAB = True
    except:
        IN_COLAB = False

    if IN_COLAB:
        # Colabä¸­ç›´æ¥æ˜¾ç¤ºï¼Œä¸å¯åŠ¨æœåŠ¡å™¨
        print("ğŸŒ åœ¨Colabä¸­è¿è¡Œï¼Œè¯·ä½¿ç”¨:")
        print("   from panel_pipeline_ui import dashboard")
        print("   dashboard")
    else:
        # æœ¬åœ°ç¯å¢ƒå¯åŠ¨æœåŠ¡å™¨
        print("ğŸŒ åœ¨æœ¬åœ°ç¯å¢ƒå¯åŠ¨æœåŠ¡å™¨...")
        dashboard.show(port=5006)
