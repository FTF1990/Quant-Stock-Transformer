{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ¤– è‚¡ç¥¨å…³è”åˆ†ææ™ºèƒ½ä½“ (Stock Correlation Analysis Agent)\n",
    "\n",
    "**åŠŸèƒ½æ¦‚è¿°**ï¼š\n",
    "- ğŸ§  åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½è‚¡ç¥¨é€‰æ‹©\n",
    "- ğŸŒ æ”¯æŒå¤šè‚¡å¸‚ï¼ˆç¾è‚¡ã€Aè‚¡ã€æ¸¯è‚¡ã€æ—¥è‚¡ï¼‰\n",
    "- ğŸ”— è‡ªåŠ¨åˆ†æè¡Œä¸šä¸Šä¸‹æ¸¸å…³è”\n",
    "- ğŸ“Š ç”Ÿæˆè‚¡ç¥¨åˆ—è¡¨JSONå’Œåˆ†ææŠ¥å‘Š\n",
    "- ğŸ“ˆ è‡ªåŠ¨æŠ“å–å†å²æ•°æ®ï¼ˆæŒ‰å°æ—¶/æŒ‰å¤©ï¼‰\n",
    "- â±ï¸ æ™ºèƒ½åˆ†æ‰¹å’Œå»¶è¿Ÿï¼Œé¿å…APIé™æµ\n",
    "\n",
    "**æ”¯æŒçš„LLM**ï¼š\n",
    "- DeepSeek - é»˜è®¤ï¼ˆæˆæœ¬ä½ï¼Œæ€§ä»·æ¯”é«˜ï¼‰\n",
    "- Google AI (Gemini)\n",
    "- OpenAI (GPT-4/GPT-3.5)\n",
    "- å…¶ä»–å…¼å®¹OpenAI APIçš„æ¨¡å‹\n",
    "\n",
    "---\n",
    "\n",
    "**ä½œè€…**: Quant-Stock-Transformer Team  \n",
    "**ç‰ˆæœ¬**: 1.0.1  \n",
    "**çŠ¶æ€**: ğŸš§ å¼€å‘æµ‹è¯•ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ğŸ“¦ Step 1: ç¯å¢ƒè®¾ç½®å’Œä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–\n",
    "!pip install -q google-generativeai openai akshare yfinance pandas numpy\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"âœ“ ä¾èµ–å®‰è£…å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Literal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# LLMç›¸å…³\n",
    "import google.generativeai as genai\n",
    "from openai import OpenAI\n",
    "\n",
    "# æ•°æ®è·å–\n",
    "import akshare as ak  # Aè‚¡æ•°æ®\n",
    "import yfinance as yf  # ç¾è‚¡ã€æ¸¯è‚¡ã€æ—¥è‚¡\n",
    "\n",
    "print(\"âœ“ å¯¼å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llm_config"
   },
   "source": [
    "## ğŸ”‘ Step 2: LLMé…ç½®\n",
    "\n",
    "**é»˜è®¤ä½¿ç”¨DeepSeek**ï¼ˆæˆæœ¬ä½ï¼Œæ€§ä»·æ¯”é«˜ï¼‰\n",
    "\n",
    "### è®¾ç½®API Keyï¼ˆä½¿ç”¨Colab Secrets - æ¨èï¼‰\n",
    "\n",
    "1. ç‚¹å‡»å·¦ä¾§ ğŸ”‘ **Secrets** å›¾æ ‡\n",
    "2. æ·»åŠ æ–°secretï¼š\n",
    "   - Name: `DEEPSEEK_API_KEY`\n",
    "   - Value: ä½ çš„DeepSeek API key\n",
    "3. è¿è¡Œä¸‹é¢çš„cellå³å¯\n",
    "\n",
    "**è·å–DeepSeek API Key**ï¼š\n",
    "- è®¿é—® https://platform.deepseek.com/\n",
    "- æ³¨å†Œå¹¶å……å€¼ï¼ˆæœ€ä½10å…ƒäººæ°‘å¸ï¼‰\n",
    "- åˆ›å»ºAPI Key\n",
    "\n",
    "**æˆæœ¬å‚è€ƒ**ï¼š\n",
    "- ~0.14å…ƒ/M tokens\n",
    "- 100æ¬¡è‚¡ç¥¨åˆ†æ < 0.1å…ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llm_setup"
   },
   "outputs": [],
   "source": [
    "class LLMConfig:\n",
    "    \"\"\"LLMé…ç½®ç±»\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        provider: Literal[\"google\", \"openai\", \"deepseek\", \"custom\"] = \"deepseek\",\n",
    "        api_key: Optional[str] = None,\n",
    "        model_name: Optional[str] = None,\n",
    "        base_url: Optional[str] = None\n",
    "    ):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        \n",
    "        # è®¾ç½®é»˜è®¤æ¨¡å‹\n",
    "        if model_name is None:\n",
    "            self.model_name = {\n",
    "                \"google\": \"gemini-2.0-flash-exp\",\n",
    "                \"openai\": \"gpt-4-turbo-preview\",\n",
    "                \"deepseek\": \"deepseek-chat\",\n",
    "                \"custom\": \"gpt-3.5-turbo\"\n",
    "            }[provider]\n",
    "        else:\n",
    "            self.model_name = model_name\n",
    "        \n",
    "        self.base_url = base_url\n",
    "        \n",
    "        # åˆå§‹åŒ–å®¢æˆ·ç«¯\n",
    "        self._init_client()\n",
    "    \n",
    "    def _init_client(self):\n",
    "        \"\"\"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯\"\"\"\n",
    "        if self.provider == \"google\":\n",
    "            if not self.api_key:\n",
    "                from google.colab import userdata\n",
    "                try:\n",
    "                    self.api_key = userdata.get('GOOGLE_API_KEY')\n",
    "                except:\n",
    "                    raise ValueError(\"è¯·åœ¨Colab Secretsä¸­è®¾ç½®GOOGLE_API_KEY\")\n",
    "            \n",
    "            genai.configure(api_key=self.api_key)\n",
    "            self.client = genai.GenerativeModel(self.model_name)\n",
    "            print(f\"âœ“ ä½¿ç”¨Google AI: {self.model_name}\")\n",
    "        \n",
    "        elif self.provider == \"openai\":\n",
    "            if not self.api_key:\n",
    "                from google.colab import userdata\n",
    "                try:\n",
    "                    self.api_key = userdata.get('OPENAI_API_KEY')\n",
    "                except:\n",
    "                    raise ValueError(\"è¯·åœ¨Colab Secretsä¸­è®¾ç½®OPENAI_API_KEY\")\n",
    "            \n",
    "            self.client = OpenAI(api_key=self.api_key)\n",
    "            print(f\"âœ“ ä½¿ç”¨OpenAI: {self.model_name}\")\n",
    "        \n",
    "        elif self.provider == \"deepseek\":\n",
    "            if not self.api_key:\n",
    "                from google.colab import userdata\n",
    "                try:\n",
    "                    self.api_key = userdata.get('DEEPSEEK_API_KEY')\n",
    "                except:\n",
    "                    raise ValueError(\n",
    "                        \"è¯·åœ¨Colab Secretsä¸­è®¾ç½®DEEPSEEK_API_KEY\\n\"\n",
    "                        \"æ­¥éª¤ï¼š\\n\"\n",
    "                        \"1. ç‚¹å‡»å·¦ä¾§ğŸ”‘å›¾æ ‡\\n\"\n",
    "                        \"2. æ·»åŠ  Name: DEEPSEEK_API_KEY, Value: ä½ çš„API key\"\n",
    "                    )\n",
    "            \n",
    "            self.client = OpenAI(\n",
    "                api_key=self.api_key,\n",
    "                base_url=\"https://api.deepseek.com\"\n",
    "            )\n",
    "            print(f\"âœ“ ä½¿ç”¨DeepSeek: {self.model_name}\")\n",
    "            print(f\"  æˆæœ¬ï¼š~0.14å…ƒ/M tokensï¼Œæ€§ä»·æ¯”æé«˜\")\n",
    "        \n",
    "        elif self.provider == \"custom\":\n",
    "            self.client = OpenAI(\n",
    "                api_key=self.api_key,\n",
    "                base_url=self.base_url\n",
    "            )\n",
    "            print(f\"âœ“ ä½¿ç”¨è‡ªå®šä¹‰API: {self.model_name}\")\n",
    "    \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        \"\"\"ç”Ÿæˆæ–‡æœ¬\"\"\"\n",
    "        if self.provider == \"google\":\n",
    "            response = self.client.generate_content(prompt)\n",
    "            return response.text\n",
    "        else:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# é…ç½®ä½ çš„LLM\n",
    "# ============================================================================\n",
    "\n",
    "# é»˜è®¤é€‰é¡¹ï¼šDeepSeekï¼ˆä½¿ç”¨Colab Secretsï¼‰\n",
    "# ç¡®ä¿åœ¨å·¦ä¾§ğŸ”‘Secretsä¸­æ·»åŠ äº† DEEPSEEK_API_KEY\n",
    "llm_config = LLMConfig(provider=\"deepseek\")\n",
    "\n",
    "# å…¶ä»–é€‰é¡¹ï¼š\n",
    "# llm_config = LLMConfig(provider=\"google\")      # Google AI (éœ€è¦GOOGLE_API_KEY)\n",
    "# llm_config = LLMConfig(provider=\"openai\")      # OpenAI (éœ€è¦OPENAI_API_KEY)\n",
    "# llm_config = LLMConfig(\n",
    "#     provider=\"deepseek\",\n",
    "#     api_key=\"sk-xxxx\"  # ç›´æ¥æä¾›API keyï¼ˆä¸æ¨èï¼Œä¸å®‰å…¨ï¼‰\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_llm"
   },
   "source": [
    "### ğŸ§ª æµ‹è¯•LLMè¿æ¥ï¼ˆå¯é€‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_connection"
   },
   "outputs": [],
   "source": [
    "# æµ‹è¯•LLMæ˜¯å¦é…ç½®æˆåŠŸ\n",
    "try:\n",
    "    test_response = llm_config.generate(\"ä½ å¥½ï¼Œè¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±\")\n",
    "    print(\"âœ“ LLMè¿æ¥æˆåŠŸï¼\\n\")\n",
    "    print(f\"å“åº”: {test_response}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— è¿æ¥å¤±è´¥: {e}\")\n",
    "    print(\"\\nè¯·æ£€æŸ¥ï¼š\")\n",
    "    print(\"1. Colab Secretsä¸­æ˜¯å¦æ­£ç¡®è®¾ç½®äº†API key\")\n",
    "    print(\"2. API keyæ˜¯å¦æœ‰æ•ˆä¸”æœ‰ä½™é¢\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agent"
   },
   "source": [
    "## ğŸ¤– Step 3: è‚¡ç¥¨å…³è”åˆ†ææ™ºèƒ½ä½“\n",
    "\n",
    "è¿™ä¸ªæ™ºèƒ½ä½“ä¼šæ ¹æ®æŒ‡å®šè¡Œä¸šï¼Œè‡ªåŠ¨åˆ†æå¹¶é€‰æ‹©ç›¸å…³è‚¡ç¥¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agent_class"
   },
   "outputs": [],
   "source": [
    "class StockAnalysisAgent:\n",
    "    \"\"\"è‚¡ç¥¨å…³è”åˆ†ææ™ºèƒ½ä½“\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_config: LLMConfig):\n",
    "        self.llm = llm_config\n",
    "        self.selected_stocks = {}\n",
    "        self.analysis_report = \"\"\n",
    "    \n",
    "    def analyze_industry(\n",
    "        self,\n",
    "        industry: str,\n",
    "        markets: List[Literal[\"US\", \"CN\", \"HK\", \"JP\"]],\n",
    "        min_stocks_per_market: Dict[str, int] = None\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        åˆ†ææŒ‡å®šè¡Œä¸šå¹¶é€‰æ‹©ç›¸å…³è‚¡ç¥¨\n",
    "        \n",
    "        Args:\n",
    "            industry: è¡Œä¸šåç§°ï¼ˆå¦‚\"åŠå¯¼ä½“\"ã€\"æ–°èƒ½æºæ±½è½¦\"ï¼‰\n",
    "            markets: è¦åˆ†æçš„è‚¡å¸‚åˆ—è¡¨\n",
    "            min_stocks_per_market: æ¯ä¸ªå¸‚åœºçš„æœ€å°è‚¡ç¥¨æ•°é‡\n",
    "        \n",
    "        Returns:\n",
    "            åŒ…å«è‚¡ç¥¨åˆ—è¡¨å’Œåˆ†ææŠ¥å‘Šçš„å­—å…¸\n",
    "        \"\"\"\n",
    "        if min_stocks_per_market is None:\n",
    "            min_stocks_per_market = {market: 5 for market in markets}\n",
    "        \n",
    "        print(f\"ğŸ” å¼€å§‹åˆ†æè¡Œä¸š: {industry}\")\n",
    "        print(f\"ğŸ“Š ç›®æ ‡å¸‚åœº: {', '.join(markets)}\")\n",
    "        print(f\"ğŸ“ˆ æœ€å°è‚¡ç¥¨æ•°: {min_stocks_per_market}\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        # æ„å»ºprompt\n",
    "        prompt = self._build_analysis_prompt(\n",
    "            industry, markets, min_stocks_per_market\n",
    "        )\n",
    "        \n",
    "        # è°ƒç”¨LLM\n",
    "        print(\"ğŸ¤– æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œåˆ†æ...\")\n",
    "        response = self.llm.generate(prompt)\n",
    "        \n",
    "        # è§£æç»“æœ\n",
    "        print(\"ğŸ“ æ­£åœ¨è§£æåˆ†æç»“æœ...\")\n",
    "        result = self._parse_llm_response(response, markets)\n",
    "        \n",
    "        self.selected_stocks = result['stocks']\n",
    "        self.analysis_report = result['report']\n",
    "        \n",
    "        print(\"\\nâœ“ åˆ†æå®Œæˆï¼\")\n",
    "        print(f\"\\né€‰ä¸­çš„è‚¡ç¥¨æ•°é‡:\")\n",
    "        for market, stocks in self.selected_stocks.items():\n",
    "            print(f\"  {market}: {len(stocks)}åª\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _build_analysis_prompt(self, industry, markets, min_stocks):\n",
    "        \"\"\"æ„å»ºåˆ†æprompt\"\"\"\n",
    "        \n",
    "        market_names = {\n",
    "            \"US\": \"ç¾å›½è‚¡å¸‚\",\n",
    "            \"CN\": \"ä¸­å›½Aè‚¡\",\n",
    "            \"HK\": \"é¦™æ¸¯è‚¡å¸‚\",\n",
    "            \"JP\": \"æ—¥æœ¬è‚¡å¸‚\"\n",
    "        }\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆã€‚è¯·åˆ†æã€{industry}ã€‘è¡Œä¸šçš„è‚¡ç¥¨å…³è”å…³ç³»ã€‚\n",
    "\n",
    "# ä»»åŠ¡è¦æ±‚\n",
    "\n",
    "1. **ä¸Šä¸‹æ¸¸åˆ†æ**ï¼šè¯†åˆ«è¯¥è¡Œä¸šçš„ä¸Šæ¸¸ä¾›åº”å•†ã€ä¸‹æ¸¸å®¢æˆ·\n",
    "2. **ç«äº‰å¯¹æ‰‹**ï¼šæ‰¾å‡ºä¸»è¦ç«äº‰å¯¹æ‰‹\n",
    "3. **å…³è”è¡Œä¸š**ï¼šæ‰¾å‡ºå¯èƒ½å—å½±å“çš„ç›¸å…³è¡Œä¸š\n",
    "4. **å¸‚åœºé¢†å¯¼è€…**ï¼šè¯†åˆ«å„å¸‚åœºçš„é¾™å¤´ä¼ä¸š\n",
    "\n",
    "# ç›®æ ‡å¸‚åœºå’Œæœ€å°è‚¡ç¥¨æ•°é‡\n",
    "\n",
    "\"\"\"\n",
    "        for market in markets:\n",
    "            prompt += f\"- **{market_names[market]}**: è‡³å°‘é€‰æ‹© {min_stocks[market]} åªè‚¡ç¥¨\\n\"\n",
    "        \n",
    "        prompt += f\"\"\"\n",
    "\n",
    "# è¾“å‡ºæ ¼å¼è¦æ±‚\n",
    "\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"stocks\": {{\n",
    "\"\"\"\n",
    "        for i, market in enumerate(markets):\n",
    "            prompt += f'    \"{market}\": [\\n'\n",
    "            prompt += '      {\"symbol\": \"è‚¡ç¥¨ä»£ç \", \"name\": \"å…¬å¸åç§°\", \"reason\": \"é€‰æ‹©ç†ç”±\", \"category\": \"ä¸Šæ¸¸/ä¸‹æ¸¸/ç«äº‰è€…/å…³è”\"},\\n'\n",
    "            prompt += '      ...\\n'\n",
    "            prompt += '    ]' + (',\\n' if i < len(markets)-1 else '\\n')\n",
    "        \n",
    "        prompt += f\"\"\"\n",
    "  }},\n",
    "  \"analysis\": {{\n",
    "    \"summary\": \"è¡Œä¸šæ•´ä½“åˆ†ææ€»ç»“\",\n",
    "    \"upstream\": \"ä¸Šæ¸¸åˆ†æ\",\n",
    "    \"downstream\": \"ä¸‹æ¸¸åˆ†æ\",\n",
    "    \"competitors\": \"ç«äº‰æ ¼å±€åˆ†æ\",\n",
    "    \"correlations\": \"å…³è”æ€§åˆ†æ\"\n",
    "  }}\n",
    "}}\n",
    "```\n",
    "\n",
    "# è‚¡ç¥¨ä»£ç æ ¼å¼è¯´æ˜\n",
    "\n",
    "- **ç¾è‚¡(US)**: ç›´æ¥ä½¿ç”¨tickerï¼ˆå¦‚NVDA, TSMCï¼‰\n",
    "- **Aè‚¡(CN)**: ä½¿ç”¨6ä½ä»£ç ï¼ˆå¦‚600519, 000858ï¼‰\n",
    "- **æ¸¯è‚¡(HK)**: ä½¿ç”¨æ•°å­—ä»£ç ï¼ˆå¦‚00700, 01810ï¼‰\n",
    "- **æ—¥è‚¡(JP)**: ä½¿ç”¨4ä½ä»£ç .Tï¼ˆå¦‚6758.T, 8035.Tï¼‰\n",
    "\n",
    "# æ³¨æ„äº‹é¡¹\n",
    "\n",
    "1. ç¡®ä¿æ¯ä¸ªå¸‚åœºçš„è‚¡ç¥¨æ•°é‡ >= æœ€å°è¦æ±‚\n",
    "2. è‚¡ç¥¨ä»£ç å¿…é¡»çœŸå®å­˜åœ¨ä¸”å¯äº¤æ˜“\n",
    "3. é€‰æ‹©ç†ç”±è¦å…·ä½“ï¼Œè¯´æ˜ä¸{industry}è¡Œä¸šçš„å…³è”\n",
    "4. åˆ†æè¦æ·±å…¥ï¼Œè€ƒè™‘äº§ä¸šé“¾å®Œæ•´æ€§\n",
    "\n",
    "è¯·å¼€å§‹åˆ†æå¹¶è¾“å‡ºJSONç»“æœï¼š\n",
    "\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def _parse_llm_response(self, response: str, markets: List[str]) -> Dict:\n",
    "        \"\"\"è§£æLLMè¿”å›çš„JSON\"\"\"\n",
    "        \n",
    "        # æå–JSONéƒ¨åˆ†\n",
    "        try:\n",
    "            # å°è¯•æ‰¾åˆ°JSONä»£ç å—\n",
    "            if \"```json\" in response:\n",
    "                json_str = response.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "            elif \"```\" in response:\n",
    "                json_str = response.split(\"```\")[1].strip()\n",
    "            else:\n",
    "                json_str = response.strip()\n",
    "            \n",
    "            # è§£æJSON\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # éªŒè¯ç»“æ„\n",
    "            if \"stocks\" not in data or \"analysis\" not in data:\n",
    "                raise ValueError(\"JSONæ ¼å¼ä¸å®Œæ•´\")\n",
    "            \n",
    "            # æ„å»ºæŠ¥å‘Š\n",
    "            report = self._generate_report(data, markets)\n",
    "            \n",
    "            return {\n",
    "                \"stocks\": data[\"stocks\"],\n",
    "                \"report\": report,\n",
    "                \"raw_analysis\": data[\"analysis\"]\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ è§£æå¤±è´¥: {e}\")\n",
    "            print(f\"\\nåŸå§‹å“åº”:\\n{response}\")\n",
    "            raise\n",
    "    \n",
    "    def _generate_report(self, data: Dict, markets: List[str]) -> str:\n",
    "        \"\"\"ç”Ÿæˆåˆ†ææŠ¥å‘Š\"\"\"\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# è‚¡ç¥¨å…³è”åˆ†ææŠ¥å‘Š\n",
    "\n",
    "**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## ğŸ“Š é€‰è‚¡ç»Ÿè®¡\n",
    "\n",
    "\"\"\"\n",
    "        for market in markets:\n",
    "            stocks = data['stocks'].get(market, [])\n",
    "            report += f\"- **{market}**: {len(stocks)}åªè‚¡ç¥¨\\n\"\n",
    "        \n",
    "        report += f\"\"\"\n",
    "\n",
    "## ğŸ” è¡Œä¸šåˆ†æ\n",
    "\n",
    "### æ€»ä½“æ¦‚è¿°\n",
    "{data['analysis'].get('summary', 'N/A')}\n",
    "\n",
    "### ä¸Šæ¸¸åˆ†æ\n",
    "{data['analysis'].get('upstream', 'N/A')}\n",
    "\n",
    "### ä¸‹æ¸¸åˆ†æ\n",
    "{data['analysis'].get('downstream', 'N/A')}\n",
    "\n",
    "### ç«äº‰æ ¼å±€\n",
    "{data['analysis'].get('competitors', 'N/A')}\n",
    "\n",
    "### å…³è”æ€§åˆ†æ\n",
    "{data['analysis'].get('correlations', 'N/A')}\n",
    "\n",
    "## ğŸ“‹ è‚¡ç¥¨æ˜ç»†\n",
    "\n",
    "\"\"\"\n",
    "        for market in markets:\n",
    "            stocks = data['stocks'].get(market, [])\n",
    "            if stocks:\n",
    "                report += f\"\\n### {market}å¸‚åœº\\n\\n\"\n",
    "                for stock in stocks:\n",
    "                    report += f\"- **{stock['symbol']}** ({stock['name']})\\n\"\n",
    "                    report += f\"  - ç±»åˆ«: {stock.get('category', 'N/A')}\\n\"\n",
    "                    report += f\"  - ç†ç”±: {stock.get('reason', 'N/A')}\\n\\n\"\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def save_results(\n",
    "        self,\n",
    "        json_path: str = \"selected_stocks.json\",\n",
    "        report_path: str = \"analysis_report.md\"\n",
    "    ):\n",
    "        \"\"\"ä¿å­˜ç»“æœåˆ°æ–‡ä»¶\"\"\"\n",
    "        \n",
    "        # ä¿å­˜JSON\n",
    "        with open(json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.selected_stocks, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"âœ“ JSONä¿å­˜åˆ°: {json_path}\")\n",
    "        \n",
    "        # ä¿å­˜æŠ¥å‘Š\n",
    "        with open(report_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(self.analysis_report)\n",
    "        print(f\"âœ“ æŠ¥å‘Šä¿å­˜åˆ°: {report_path}\")\n",
    "\n",
    "\n",
    "print(\"âœ“ StockAnalysisAgentç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage_example"
   },
   "source": [
    "## ğŸ¯ Step 4: è¿è¡Œæ™ºèƒ½ä½“åˆ†æ\n",
    "\n",
    "é…ç½®ä½ çš„åˆ†æå‚æ•°å¹¶è¿è¡Œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_agent"
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ™ºèƒ½ä½“\n",
    "agent = StockAnalysisAgent(llm_config)\n",
    "\n",
    "# ============================================================================\n",
    "# é…ç½®åˆ†æå‚æ•°ï¼ˆæ ¹æ®ä½ çš„éœ€æ±‚ä¿®æ”¹ï¼‰\n",
    "# ============================================================================\n",
    "\n",
    "INDUSTRY = \"åŠå¯¼ä½“\"  # è¡Œä¸šåç§°\n",
    "\n",
    "MARKETS = [\"US\", \"CN\", \"HK\", \"JP\"]  # è¦åˆ†æçš„å¸‚åœº\n",
    "# å¯é€‰: [\"US\"], [\"CN\"], [\"US\", \"CN\"], [\"US\", \"CN\", \"HK\", \"JP\"]\n",
    "\n",
    "MIN_STOCKS_PER_MARKET = {\n",
    "    \"US\": 8,   # ç¾è‚¡è‡³å°‘8åª\n",
    "    \"CN\": 10,  # Aè‚¡è‡³å°‘10åª\n",
    "    \"HK\": 5,   # æ¸¯è‚¡è‡³å°‘5åª\n",
    "    \"JP\": 5    # æ—¥è‚¡è‡³å°‘5åª\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# è¿è¡Œåˆ†æ\n",
    "# ============================================================================\n",
    "\n",
    "result = agent.analyze_industry(\n",
    "    industry=INDUSTRY,\n",
    "    markets=MARKETS,\n",
    "    min_stocks_per_market=MIN_STOCKS_PER_MARKET\n",
    ")\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "agent.save_results(\n",
    "    json_path=\"selected_stocks.json\",\n",
    "    report_path=\"analysis_report.md\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nğŸ“„ åˆ†ææŠ¥å‘Šé¢„è§ˆ:\\n\")\n",
    "print(agent.analysis_report[:500] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_fetcher"
   },
   "source": [
    "## ğŸ“ˆ Step 5: å†å²æ•°æ®æŠ“å–\n",
    "\n",
    "æ ¹æ®é€‰ä¸­çš„è‚¡ç¥¨ï¼Œè‡ªåŠ¨æŠ“å–å†å²æ•°æ®ã€‚\n",
    "\n",
    "### â±ï¸ æ™ºèƒ½åˆ†æ‰¹å’Œå»¶è¿Ÿ\n",
    "\n",
    "**ä¸ºä»€ä¹ˆéœ€è¦åˆ†æ‰¹å’Œå»¶è¿Ÿï¼Ÿ**\n",
    "- AkShareå’Œyfinanceéƒ½æœ‰é¢‘ç‡é™åˆ¶\n",
    "- é¿å…è¢«APIæœåŠ¡å™¨é™æµæˆ–å°ç¦\n",
    "- æé«˜æ•°æ®è·å–çš„ç¨³å®šæ€§\n",
    "\n",
    "**é»˜è®¤å‚æ•°ï¼ˆæ¨èï¼‰**ï¼š\n",
    "- æ¯æ‰¹5åªè‚¡ç¥¨\n",
    "- æ‰¹æ¬¡é—´å»¶è¿Ÿ2ç§’\n",
    "- è‚¡ç¥¨é—´å»¶è¿Ÿ0.5ç§’\n",
    "\n",
    "**é€‚ç”¨åœºæ™¯**ï¼š\n",
    "- å‡ åæ”¯è‚¡ç¥¨ï¼ˆ30-50æ”¯ï¼‰\n",
    "- ä¸€å¹´çš„æ¯æ—¥æˆ–å°æ—¶æ•°æ®\n",
    "- æ€»è€—æ—¶ï¼šçº¦30-50ç§’ï¼ˆå¯æ¥å—ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data_fetcher_class"
   },
   "outputs": [],
   "source": [
    "class StockDataFetcher:\n",
    "    \"\"\"å¤šå¸‚åœºè‚¡ç¥¨æ•°æ®æŠ“å–å™¨ï¼ˆæ”¯æŒæ™ºèƒ½åˆ†æ‰¹å’Œå»¶è¿Ÿï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_cache = {}\n",
    "    \n",
    "    def fetch_historical_data(\n",
    "        self,\n",
    "        stocks_json: Dict,\n",
    "        start_date: str,\n",
    "        end_date: str,\n",
    "        interval: Literal[\"1d\", \"1h\"] = \"1d\",\n",
    "        include_market_index: bool = True,\n",
    "        batch_size: int = 5,\n",
    "        delay_between_batches: float = 2.0,\n",
    "        delay_between_stocks: float = 0.5\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        æŠ“å–å†å²æ•°æ®ï¼ˆæ™ºèƒ½åˆ†æ‰¹ï¼Œé¿å…APIé™æµï¼‰\n",
    "        \n",
    "        Args:\n",
    "            stocks_json: è‚¡ç¥¨JSONï¼ˆagent.selected_stocksï¼‰\n",
    "            start_date: å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)\n",
    "            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)\n",
    "            interval: æ•°æ®ç²’åº¦ï¼ˆ\"1d\"æŒ‰å¤©ï¼Œ\"1h\"æŒ‰å°æ—¶ï¼‰\n",
    "            include_market_index: æ˜¯å¦åŒ…å«å¤§ç›˜æŒ‡æ•°\n",
    "            batch_size: æ¯æ‰¹æŠ“å–çš„è‚¡ç¥¨æ•°é‡ï¼ˆé»˜è®¤5ï¼Œæ¨è3-10ï¼‰\n",
    "            delay_between_batches: æ‰¹æ¬¡é—´å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤2.0ç§’ï¼‰\n",
    "            delay_between_stocks: åŒæ‰¹è‚¡ç¥¨é—´å»¶è¿Ÿç§’æ•°ï¼ˆé»˜è®¤0.5ç§’ï¼‰\n",
    "        \n",
    "        Returns:\n",
    "            åŒ…å«æ‰€æœ‰è‚¡ç¥¨å’ŒæŒ‡æ•°æ•°æ®çš„å­—å…¸\n",
    "        \n",
    "        æ¨èé…ç½®ï¼š\n",
    "            - å‡ åæ”¯è‚¡ç¥¨ï¼Œä¸€å¹´æ•°æ®ï¼šé»˜è®¤å‚æ•°å³å¯\n",
    "            - å¤§é‡è‚¡ç¥¨ï¼ˆ>100æ”¯ï¼‰ï¼šbatch_size=3, delay_between_batches=3.0\n",
    "            - å°‘é‡è‚¡ç¥¨ï¼ˆ<20æ”¯ï¼‰ï¼šbatch_size=10, delay_between_batches=1.0\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\nğŸ“¥ å¼€å§‹æŠ“å–å†å²æ•°æ®\")\n",
    "        print(f\"æ—¥æœŸèŒƒå›´: {start_date} è‡³ {end_date}\")\n",
    "        print(f\"æ•°æ®ç²’åº¦: {interval}\")\n",
    "        print(f\"â±ï¸  åˆ†æ‰¹é…ç½®: æ¯æ‰¹{batch_size}æ”¯ï¼Œæ‰¹æ¬¡é—´å»¶è¿Ÿ{delay_between_batches}ç§’ï¼Œè‚¡ç¥¨é—´å»¶è¿Ÿ{delay_between_stocks}ç§’\")\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        \n",
    "        all_data = {}\n",
    "        \n",
    "        for market, stocks in stocks_json.items():\n",
    "            print(f\"\\nğŸ”„ æ­£åœ¨å¤„ç†{market}å¸‚åœº ({len(stocks)}åªè‚¡ç¥¨)...\")\n",
    "            \n",
    "            market_data = {}\n",
    "            \n",
    "            # æŠ“å–å¤§ç›˜æŒ‡æ•°\n",
    "            if include_market_index:\n",
    "                index_data = self._fetch_market_index(\n",
    "                    market, start_date, end_date, interval\n",
    "                )\n",
    "                if index_data is not None:\n",
    "                    market_data['_INDEX_'] = index_data\n",
    "                    print(f\"  âœ“ å¤§ç›˜æŒ‡æ•°æ•°æ®è·å–æˆåŠŸ ({len(index_data)}æ¡è®°å½•)\")\n",
    "                time.sleep(delay_between_stocks)  # å»¶è¿Ÿåå†æŠ“å–ä¸ªè‚¡\n",
    "            \n",
    "            # åˆ†æ‰¹æŠ“å–ä¸ªè‚¡æ•°æ®\n",
    "            total_stocks = len(stocks)\n",
    "            num_batches = (total_stocks + batch_size - 1) // batch_size\n",
    "            \n",
    "            for batch_idx in range(num_batches):\n",
    "                start_idx = batch_idx * batch_size\n",
    "                end_idx = min((batch_idx + 1) * batch_size, total_stocks)\n",
    "                batch_stocks = stocks[start_idx:end_idx]\n",
    "                \n",
    "                print(f\"\\n  æ‰¹æ¬¡ [{batch_idx+1}/{num_batches}]: æŠ“å–ç¬¬{start_idx+1}-{end_idx}æ”¯è‚¡ç¥¨\")\n",
    "                \n",
    "                for i, stock in enumerate(batch_stocks, start=start_idx+1):\n",
    "                    symbol = stock['symbol']\n",
    "                    try:\n",
    "                        data = self._fetch_stock_data(\n",
    "                            market, symbol, start_date, end_date, interval\n",
    "                        )\n",
    "                        if data is not None and len(data) > 0:\n",
    "                            market_data[symbol] = data\n",
    "                            print(f\"    âœ“ [{i}/{total_stocks}] {symbol}: {len(data)}æ¡æ•°æ®\")\n",
    "                        else:\n",
    "                            print(f\"    âœ— [{i}/{total_stocks}] {symbol}: æ— æ•°æ®\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    âœ— [{i}/{total_stocks}] {symbol}: å¤±è´¥ ({str(e)[:50]})\")\n",
    "                    \n",
    "                    # åŒæ‰¹è‚¡ç¥¨é—´å»¶è¿Ÿ\n",
    "                    if i < total_stocks:\n",
    "                        time.sleep(delay_between_stocks)\n",
    "                \n",
    "                # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆæœ€åä¸€æ‰¹ä¸éœ€è¦ï¼‰\n",
    "                if batch_idx < num_batches - 1:\n",
    "                    print(f\"  â¸ï¸  æ‰¹æ¬¡å®Œæˆï¼Œç­‰å¾…{delay_between_batches}ç§’åç»§ç»­...\")\n",
    "                    time.sleep(delay_between_batches)\n",
    "            \n",
    "            all_data[market] = market_data\n",
    "            print(f\"\\n  âœ“ {market}å¸‚åœºå®Œæˆï¼šæˆåŠŸ{len(market_data)}æ”¯ï¼ˆå«æŒ‡æ•°ï¼‰\")\n",
    "        \n",
    "        self.data_cache = all_data\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"âœ“ æ‰€æœ‰æ•°æ®æŠ“å–å®Œæˆï¼\")\n",
    "        \n",
    "        # ç»Ÿè®¡\n",
    "        total_success = sum(len(v) for v in all_data.values())\n",
    "        total_requested = sum(len(v) for v in stocks_json.values()) + len(stocks_json)  # +æŒ‡æ•°\n",
    "        print(f\"\\næˆåŠŸç‡: {total_success}/{total_requested} ({100*total_success/total_requested:.1f}%)\")\n",
    "        \n",
    "        return all_data\n",
    "    \n",
    "    def _fetch_market_index(\n",
    "        self, market: str, start_date: str, end_date: str, interval: str\n",
    "    ) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"æŠ“å–å¤§ç›˜æŒ‡æ•°\"\"\"\n",
    "        \n",
    "        index_symbols = {\n",
    "            \"US\": \"^GSPC\",      # S&P 500\n",
    "            \"CN\": \"000001\",     # ä¸Šè¯æŒ‡æ•°\n",
    "            \"HK\": \"^HSI\",       # æ’ç”ŸæŒ‡æ•°\n",
    "            \"JP\": \"^N225\"       # æ—¥ç»225\n",
    "        }\n",
    "        \n",
    "        symbol = index_symbols.get(market)\n",
    "        if not symbol:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            if market == \"CN\":\n",
    "                # Aè‚¡ä½¿ç”¨akshare\n",
    "                df = ak.stock_zh_index_daily(symbol=f\"sh{symbol}\")\n",
    "                df['date'] = pd.to_datetime(df['date'])\n",
    "                df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]\n",
    "                df = df.rename(columns={'close': 'Close', 'open': 'Open', \n",
    "                                       'high': 'High', 'low': 'Low', 'volume': 'Volume'})\n",
    "            else:\n",
    "                # å…¶ä»–å¸‚åœºä½¿ç”¨yfinance\n",
    "                df = yf.download(symbol, start=start_date, end=end_date, \n",
    "                                interval=interval, progress=False)\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"    è­¦å‘Š: å¤§ç›˜æŒ‡æ•°è·å–å¤±è´¥ ({e})\")\n",
    "            return None\n",
    "    \n",
    "    def _fetch_stock_data(\n",
    "        self, market: str, symbol: str, start_date: str, end_date: str, interval: str\n",
    "    ) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"æŠ“å–ä¸ªè‚¡æ•°æ®\"\"\"\n",
    "        \n",
    "        try:\n",
    "            if market == \"CN\":\n",
    "                # Aè‚¡ä½¿ç”¨akshare\n",
    "                df = ak.stock_zh_a_hist(symbol=symbol, period=\"daily\", \n",
    "                                       start_date=start_date.replace('-', ''),\n",
    "                                       end_date=end_date.replace('-', ''))\n",
    "                df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])\n",
    "                df = df.rename(columns={\n",
    "                    'æ—¥æœŸ': 'Date', 'æ”¶ç›˜': 'Close', 'å¼€ç›˜': 'Open',\n",
    "                    'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 'æˆäº¤é‡': 'Volume'\n",
    "                })\n",
    "                df = df.set_index('Date')\n",
    "            else:\n",
    "                # å…¶ä»–å¸‚åœºä½¿ç”¨yfinance\n",
    "                # ç¡®ä¿symbolæ ¼å¼æ­£ç¡®\n",
    "                if market == \"HK\" and not symbol.endswith(\".HK\"):\n",
    "                    symbol = symbol.zfill(4) + \".HK\"\n",
    "                elif market == \"JP\" and not symbol.endswith(\".T\"):\n",
    "                    if '.' not in symbol:\n",
    "                        symbol = symbol + \".T\"\n",
    "                \n",
    "                df = yf.download(symbol, start=start_date, end=end_date,\n",
    "                                interval=interval, progress=False)\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"æ•°æ®è·å–å¤±è´¥: {e}\")\n",
    "    \n",
    "    def save_data(\n",
    "        self,\n",
    "        output_path: str = \"historical_data.pkl\"\n",
    "    ):\n",
    "        \"\"\"ä¿å­˜æ•°æ®åˆ°pickleæ–‡ä»¶\"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(self.data_cache, f)\n",
    "        \n",
    "        print(f\"âœ“ æ•°æ®å·²ä¿å­˜åˆ°: {output_path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_data(input_path: str) -> Dict:\n",
    "        \"\"\"ä»pickleæ–‡ä»¶åŠ è½½æ•°æ®\"\"\"\n",
    "        import pickle\n",
    "        \n",
    "        with open(input_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        print(f\"âœ“ æ•°æ®å·²ä» {input_path} åŠ è½½\")\n",
    "        return data\n",
    "\n",
    "\n",
    "print(\"âœ“ StockDataFetcherç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fetch_data"
   },
   "source": [
    "## ğŸ“Š Step 6: æ‰§è¡Œæ•°æ®æŠ“å–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_fetcher"
   },
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ•°æ®æŠ“å–å™¨\n",
    "fetcher = StockDataFetcher()\n",
    "\n",
    "# ============================================================================\n",
    "# é…ç½®æ•°æ®æŠ“å–å‚æ•°\n",
    "# ============================================================================\n",
    "\n",
    "START_DATE = \"2020-01-01\"  # å¼€å§‹æ—¥æœŸ\n",
    "END_DATE = \"2024-12-31\"    # ç»“æŸæ—¥æœŸ\n",
    "INTERVAL = \"1d\"            # \"1d\" æŒ‰å¤©ï¼Œ\"1h\" æŒ‰å°æ—¶\n",
    "\n",
    "# åˆ†æ‰¹å’Œå»¶è¿Ÿé…ç½®ï¼ˆä½¿ç”¨é»˜è®¤æ¨èå€¼ï¼‰\n",
    "BATCH_SIZE = 5              # æ¯æ‰¹5æ”¯è‚¡ç¥¨\n",
    "DELAY_BETWEEN_BATCHES = 2.0  # æ‰¹æ¬¡é—´å»¶è¿Ÿ2ç§’\n",
    "DELAY_BETWEEN_STOCKS = 0.5   # è‚¡ç¥¨é—´å»¶è¿Ÿ0.5ç§’\n",
    "\n",
    "# ============================================================================\n",
    "# æŠ“å–æ•°æ®\n",
    "# ============================================================================\n",
    "\n",
    "historical_data = fetcher.fetch_historical_data(\n",
    "    stocks_json=agent.selected_stocks,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    interval=INTERVAL,\n",
    "    include_market_index=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    delay_between_batches=DELAY_BETWEEN_BATCHES,\n",
    "    delay_between_stocks=DELAY_BETWEEN_STOCKS\n",
    ")\n",
    "\n",
    "# ä¿å­˜æ•°æ®\n",
    "fetcher.save_data(\"historical_data.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\næ•°æ®ç»Ÿè®¡:\")\n",
    "for market, stocks_data in historical_data.items():\n",
    "    print(f\"\\n{market}å¸‚åœº:\")\n",
    "    for symbol, df in stocks_data.items():\n",
    "        print(f\"  {symbol}: {len(df)}æ¡è®°å½•\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "end"
   },
   "source": [
    "---\n",
    "\n",
    "## âœ… æ™ºèƒ½ä½“éƒ¨åˆ†å®Œæˆ\n",
    "\n",
    "ç°åœ¨ä½ å·²ç»æ‹¥æœ‰ï¼š\n",
    "1. âœ“ è‚¡ç¥¨é€‰æ‹©JSONæ–‡ä»¶ (`selected_stocks.json`)\n",
    "2. âœ“ åˆ†ææŠ¥å‘Š (`analysis_report.md`)\n",
    "3. âœ“ å†å²æ•°æ® (`historical_data.pkl`)\n",
    "\n",
    "**ä¸‹ä¸€æ­¥**ï¼š\n",
    "- ç»§ç»­è¿è¡Œåç»­cellsè¿›è¡Œæ¨¡å‹è®­ç»ƒå’ŒéªŒè¯\n",
    "- æˆ–åœ¨æ–°çš„notebookä¸­åŠ è½½è¿™äº›æ•°æ®è¿›è¡Œåˆ†æ\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
