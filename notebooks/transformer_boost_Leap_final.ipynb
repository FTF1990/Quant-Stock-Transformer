{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INH5vrTldDKk",
        "outputId": "156cbc3b-43a3-40c0-d4a3-c6c3b7bb9395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.10.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lSJSEgNkdO_k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "import pyarrow.parquet as pq\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "891QpFckdS8L",
        "outputId": "6da2ca29-dee4-4cf4-9691-c673190fce59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/titericz/leap-dataset-giba-part-2?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.7G/15.7G [12:23<00:00, 22.7MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/titericz/leap-dataset-giba-part-2/versions/2\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"titericz/leap-dataset-giba-part-2\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1JGbcsrR9scq"
      },
      "outputs": [],
      "source": [
        "# copy one train file to cotent\n",
        "!cp /root/.cache/kagglehub/datasets/titericz/leap-dataset-giba-part-2/versions/2/train_batch/10.parquet /content/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6wAMdKiQtVl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0add1fa4",
        "outputId": "83fa1a21-eac4-4de3-b2c7-3040f03764b9"
      },
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Define the model handle\n",
        "model_handle = \"tianffan/transformer_signal_end_to_end_leap/transformers/default\"\n",
        "\n",
        "# Download the model\n",
        "path = kagglehub.model_download(model_handle)\n",
        "\n",
        "print(f\"Path to downloaded model files: {path}\")\n",
        "\n",
        "# Define the destination directory\n",
        "destination_dir = '/content/'\n",
        "\n",
        "# Copy all files from the downloaded model directory to the destination directory\n",
        "# Use shell command as it's generally more efficient for copying directories\n",
        "!cp -r \"$path\"/* \"$destination_dir\"\n",
        "\n",
        "print(f\"Successfully copied files from '{path}' to '{destination_dir}'\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to downloaded model files: /kaggle/input/transformer_signal_end_to_end_leap/transformers/default/2\n",
            "Successfully copied files from '/kaggle/input/transformer_signal_end_to_end_leap/transformers/default/2' to '/content/1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5673d347808945dd804b4a6a5c166139",
            "07352d31476b4f28b1216f34598d0713",
            "a35cb4da9c1e4d569db9a9a2294309d8",
            "27c01d7b17bd432b9b66e0e8c966d5f7",
            "3f426f6dfc4049d080bc7612b1a1da06",
            "ffd67c32bc034e96b1d83f49a2c3da74",
            "f51e260d94e6400fbd8d0cc7663644c8",
            "d70da0f7911f45aa9d05ac82abbc1c95",
            "50cf4efde43f4b628549be8d715a4c8a",
            "a5dbfa500d9e4bada083099c3c8a0eb9",
            "f71c441d09464534b75ae2b1f79f0182"
          ]
        },
        "id": "5ZRZmxR3dlbE",
        "outputId": "d1c4cd64-913b-4791-81e4-9aad262a6042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸ” LEAPæ•°æ®åŠ è½½ - 90/10é¡ºåºåˆ’åˆ†\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‚ content: æ‰¾åˆ° 2 ä¸ªæ–‡ä»¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  åŠ è½½content:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5673d347808945dd804b4a6a5c166139"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    10.parquet: 625,000 æ ·æœ¬\n",
            "    11.parquet: 625,000 æ ·æœ¬\n",
            "\n",
            "âœ… æ•°æ®åŠ è½½å®Œæˆ!\n",
            "  æ€»æ ·æœ¬æ•°: 1,250,000\n",
            "  åˆå¹¶åŽæ•°æ®å½¢çŠ¶: (1250000, 793)\n",
            "\n",
            "================================================================================\n",
            "âœ‚ï¸  æ•°æ®åˆ’åˆ† (90% Train / 10% Test)\n",
            "================================================================================\n",
            "\n",
            "ã€åˆ’åˆ†ç»“æžœã€‘\n",
            "  è®­ç»ƒé›† (å‰90%): 625,000 æ ·æœ¬\n",
            "  æµ‹è¯•é›† (åŽ10%): 625,000 æ ·æœ¬\n",
            "  åˆ’åˆ†æ¯”ä¾‹: 50.0% / 50.0%\n",
            "\n",
            "ã€Indexè¿žç»­æ€§æ£€æŸ¥ã€‘\n",
            "  è®­ç»ƒé›†indexè¿žç»­: âœ…\n",
            "  æµ‹è¯•é›†indexè¿žç»­: âœ…\n",
            "  è®­ç»ƒé›†indexèŒƒå›´: [0, 624999]\n",
            "  æµ‹è¯•é›†indexèŒƒå›´: [625000, 1249999]\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š è®­ç»ƒé›†æ•°æ®åŸºæœ¬ä¿¡æ¯\n",
            "================================================================================\n",
            "\n",
            "ã€æ•°æ®ç»´åº¦ã€‘\n",
            "  è®­ç»ƒé›†æ ·æœ¬æ•°: 625,000\n",
            "  æµ‹è¯•é›†æ ·æœ¬æ•°: 625,000\n",
            "  ç‰¹å¾æ•°: 793\n",
            "  è®­ç»ƒé›†å†…å­˜: 1988.41 MB\n",
            "  æµ‹è¯•é›†å†…å­˜: 1988.41 MB\n",
            "\n",
            "ã€ç‰¹å¾åˆ†ç±»ã€‘\n",
            "  è¾“å…¥ç‰¹å¾ (INPUT):  490 ä¸ª\n",
            "    - state_*: 361 ä¸ª\n",
            "    - pbuf_*: 120 ä¸ª\n",
            "    - cam_in_*: 9 ä¸ª\n",
            "\n",
            "  è¾“å‡ºç‰¹å¾ (OUTPUT): 302 ä¸ª\n",
            "    - ptend_*: 294 ä¸ª\n",
            "    - cam_out_*: 8 ä¸ª\n",
            "\n",
            "  å…¶ä»–åˆ—: 1 ä¸ª\n",
            "    ['sample_id']\n",
            "\n",
            "ã€æ•°æ®ç±»åž‹ã€‘\n",
            "{dtype('float32'): 751, dtype('float64'): 41, dtype('int32'): 1}\n",
            "\n",
            "ã€ç¼ºå¤±å€¼ã€‘\n",
            "  è®­ç»ƒé›†: âœ… æ— ç¼ºå¤±å€¼\n",
            "  æµ‹è¯•é›†: âœ… æ— ç¼ºå¤±å€¼\n",
            "\n",
            "ã€è¾“å…¥ç‰¹å¾ç»Ÿè®¡ - è®­ç»ƒé›†ã€‘\n",
            "  å‡å€¼èŒƒå›´: [-2.68e+03, 4.12e+02]\n",
            "  æ ‡å‡†å·®èŒƒå›´: [0.00e+00, 4.58e+03]\n",
            "  æœ€å°å€¼èŒƒå›´: [-3.17e+04, 2.26e+02]\n",
            "  æœ€å¤§å€¼èŒƒå›´: [2.80e-48, 3.54e+03]\n",
            "\n",
            "ã€è¾“å‡ºç‰¹å¾ç»Ÿè®¡ - è®­ç»ƒé›†ã€‘\n",
            "  å‡å€¼èŒƒå›´: [-8.37e-01, 4.99e+00]\n",
            "  æ ‡å‡†å·®èŒƒå›´: [0.00e+00, 3.92e+00]\n",
            "  æœ€å°å€¼èŒƒå›´: [-3.05e+03, 9.01e-01]\n",
            "  æœ€å¤§å€¼èŒƒå›´: [0.00e+00, 7.72e+02]\n",
            "\n",
            "ã€è®­ç»ƒé›†æ•°æ®é¢„è§ˆã€‘å‰5ä¸ªè¾“å…¥ç‰¹å¾ + å‰5ä¸ªè¾“å‡ºç‰¹å¾\n",
            "    state_t_0   state_t_1   state_t_2   state_t_3   state_t_4  ptend_t_0  \\\n",
            "0  208.889938  225.731461  233.789062  244.548706  252.274399   1.074721   \n",
            "1  208.210815  220.131821  232.967331  242.658417  254.078461   1.208698   \n",
            "2  208.618500  218.651993  232.694626  244.205429  257.430786   1.108290   \n",
            "3  207.701675  213.361832  229.467331  243.859924  256.912933   1.190565   \n",
            "4  209.401352  217.298538  231.653854  243.887100  255.902466   1.194205   \n",
            "\n",
            "   ptend_t_1  ptend_t_2  ptend_t_3  ptend_t_4  \n",
            "0   0.258894   0.569155   0.568198   0.253785  \n",
            "1   0.789125   0.755819   0.966556   0.770690  \n",
            "2   0.838956   0.742609   0.800857   0.353664  \n",
            "3   1.199229   1.037072   1.001736   0.817751  \n",
            "4   1.036841   0.945182   1.038204   0.959772  \n",
            "\n",
            "ã€æµ‹è¯•é›†æ•°æ®é¢„è§ˆã€‘\n",
            "         state_t_0   state_t_1   state_t_2   state_t_3   state_t_4  ptend_t_0  \\\n",
            "625000  212.025787  232.691238  240.650818  248.219955  253.819382   1.430637   \n",
            "625001  210.811157  226.546494  241.439377  249.830719  254.214264   1.476283   \n",
            "625002  214.550613  238.191132  243.981339  247.507339  249.116028   1.318064   \n",
            "625003  212.281784  238.879166  247.950272  250.275940  250.689545   1.627649   \n",
            "625004  211.272537  223.116608  239.712326  249.477875  254.343735   1.424294   \n",
            "\n",
            "        ptend_t_1  ptend_t_2  ptend_t_3  ptend_t_4  \n",
            "625000   0.246915   0.636023   0.925751   1.024450  \n",
            "625001   0.767924   0.607040   0.916156   1.195427  \n",
            "625002  -0.260925   0.343498   0.829668   0.906866  \n",
            "625003  -0.108370   0.231100   0.892290   1.191023  \n",
            "625004   0.982208   0.740454   0.986140   1.310207  \n",
            "\n",
            "ã€å®Œæ•´åˆ—ååˆ—è¡¨ã€‘\n",
            "\n",
            "è¾“å…¥ç‰¹å¾ (490ä¸ª):\n",
            "    1. state_t_0\n",
            "    2. state_t_1\n",
            "    3. state_t_2\n",
            "    4. state_t_3\n",
            "    5. state_t_4\n",
            "    6. state_t_5\n",
            "    7. state_t_6\n",
            "    8. state_t_7\n",
            "    9. state_t_8\n",
            "   10. state_t_9\n",
            "   11. state_t_10\n",
            "   12. state_t_11\n",
            "   13. state_t_12\n",
            "   14. state_t_13\n",
            "   15. state_t_14\n",
            "   16. state_t_15\n",
            "   17. state_t_16\n",
            "   18. state_t_17\n",
            "   19. state_t_18\n",
            "   20. state_t_19\n",
            "   21. state_t_20\n",
            "   22. state_t_21\n",
            "   23. state_t_22\n",
            "   24. state_t_23\n",
            "   25. state_t_24\n",
            "   26. state_t_25\n",
            "   27. state_t_26\n",
            "   28. state_t_27\n",
            "   29. state_t_28\n",
            "   30. state_t_29\n",
            "   31. state_t_30\n",
            "   32. state_t_31\n",
            "   33. state_t_32\n",
            "   34. state_t_33\n",
            "   35. state_t_34\n",
            "   36. state_t_35\n",
            "   37. state_t_36\n",
            "   38. state_t_37\n",
            "   39. state_t_38\n",
            "   40. state_t_39\n",
            "   41. state_t_40\n",
            "   42. state_t_41\n",
            "   43. state_t_42\n",
            "   44. state_t_43\n",
            "   45. state_t_44\n",
            "   46. state_t_45\n",
            "   47. state_t_46\n",
            "   48. state_t_47\n",
            "   49. state_t_48\n",
            "   50. state_t_49\n",
            "   51. state_t_50\n",
            "   52. state_t_51\n",
            "   53. state_t_52\n",
            "   54. state_t_53\n",
            "   55. state_t_54\n",
            "   56. state_t_55\n",
            "   57. state_t_56\n",
            "   58. state_t_57\n",
            "   59. state_t_58\n",
            "   60. state_t_59\n",
            "   61. state_q0001_0\n",
            "   62. state_q0001_1\n",
            "   63. state_q0001_2\n",
            "   64. state_q0001_3\n",
            "   65. state_q0001_4\n",
            "   66. state_q0001_5\n",
            "   67. state_q0001_6\n",
            "   68. state_q0001_7\n",
            "   69. state_q0001_8\n",
            "   70. state_q0001_9\n",
            "   71. state_q0001_10\n",
            "   72. state_q0001_11\n",
            "   73. state_q0001_12\n",
            "   74. state_q0001_13\n",
            "   75. state_q0001_14\n",
            "   76. state_q0001_15\n",
            "   77. state_q0001_16\n",
            "   78. state_q0001_17\n",
            "   79. state_q0001_18\n",
            "   80. state_q0001_19\n",
            "   81. state_q0001_20\n",
            "   82. state_q0001_21\n",
            "   83. state_q0001_22\n",
            "   84. state_q0001_23\n",
            "   85. state_q0001_24\n",
            "   86. state_q0001_25\n",
            "   87. state_q0001_26\n",
            "   88. state_q0001_27\n",
            "   89. state_q0001_28\n",
            "   90. state_q0001_29\n",
            "   91. state_q0001_30\n",
            "   92. state_q0001_31\n",
            "   93. state_q0001_32\n",
            "   94. state_q0001_33\n",
            "   95. state_q0001_34\n",
            "   96. state_q0001_35\n",
            "   97. state_q0001_36\n",
            "   98. state_q0001_37\n",
            "   99. state_q0001_38\n",
            "  100. state_q0001_39\n",
            "  101. state_q0001_40\n",
            "  102. state_q0001_41\n",
            "  103. state_q0001_42\n",
            "  104. state_q0001_43\n",
            "  105. state_q0001_44\n",
            "  106. state_q0001_45\n",
            "  107. state_q0001_46\n",
            "  108. state_q0001_47\n",
            "  109. state_q0001_48\n",
            "  110. state_q0001_49\n",
            "  111. state_q0001_50\n",
            "  112. state_q0001_51\n",
            "  113. state_q0001_52\n",
            "  114. state_q0001_53\n",
            "  115. state_q0001_54\n",
            "  116. state_q0001_55\n",
            "  117. state_q0001_56\n",
            "  118. state_q0001_57\n",
            "  119. state_q0001_58\n",
            "  120. state_q0001_59\n",
            "  121. state_q0002_0\n",
            "  122. state_q0002_1\n",
            "  123. state_q0002_2\n",
            "  124. state_q0002_3\n",
            "  125. state_q0002_4\n",
            "  126. state_q0002_5\n",
            "  127. state_q0002_6\n",
            "  128. state_q0002_7\n",
            "  129. state_q0002_8\n",
            "  130. state_q0002_9\n",
            "  131. state_q0002_10\n",
            "  132. state_q0002_11\n",
            "  133. state_q0002_12\n",
            "  134. state_q0002_13\n",
            "  135. state_q0002_14\n",
            "  136. state_q0002_15\n",
            "  137. state_q0002_16\n",
            "  138. state_q0002_17\n",
            "  139. state_q0002_18\n",
            "  140. state_q0002_19\n",
            "  141. state_q0002_20\n",
            "  142. state_q0002_21\n",
            "  143. state_q0002_22\n",
            "  144. state_q0002_23\n",
            "  145. state_q0002_24\n",
            "  146. state_q0002_25\n",
            "  147. state_q0002_26\n",
            "  148. state_q0002_27\n",
            "  149. state_q0002_28\n",
            "  150. state_q0002_29\n",
            "  151. state_q0002_30\n",
            "  152. state_q0002_31\n",
            "  153. state_q0002_32\n",
            "  154. state_q0002_33\n",
            "  155. state_q0002_34\n",
            "  156. state_q0002_35\n",
            "  157. state_q0002_36\n",
            "  158. state_q0002_37\n",
            "  159. state_q0002_38\n",
            "  160. state_q0002_39\n",
            "  161. state_q0002_40\n",
            "  162. state_q0002_41\n",
            "  163. state_q0002_42\n",
            "  164. state_q0002_43\n",
            "  165. state_q0002_44\n",
            "  166. state_q0002_45\n",
            "  167. state_q0002_46\n",
            "  168. state_q0002_47\n",
            "  169. state_q0002_48\n",
            "  170. state_q0002_49\n",
            "  171. state_q0002_50\n",
            "  172. state_q0002_51\n",
            "  173. state_q0002_52\n",
            "  174. state_q0002_53\n",
            "  175. state_q0002_54\n",
            "  176. state_q0002_55\n",
            "  177. state_q0002_56\n",
            "  178. state_q0002_57\n",
            "  179. state_q0002_58\n",
            "  180. state_q0002_59\n",
            "  181. state_q0003_0\n",
            "  182. state_q0003_1\n",
            "  183. state_q0003_2\n",
            "  184. state_q0003_3\n",
            "  185. state_q0003_4\n",
            "  186. state_q0003_5\n",
            "  187. state_q0003_6\n",
            "  188. state_q0003_7\n",
            "  189. state_q0003_8\n",
            "  190. state_q0003_9\n",
            "  191. state_q0003_10\n",
            "  192. state_q0003_11\n",
            "  193. state_q0003_12\n",
            "  194. state_q0003_13\n",
            "  195. state_q0003_14\n",
            "  196. state_q0003_15\n",
            "  197. state_q0003_16\n",
            "  198. state_q0003_17\n",
            "  199. state_q0003_18\n",
            "  200. state_q0003_19\n",
            "  201. state_q0003_20\n",
            "  202. state_q0003_21\n",
            "  203. state_q0003_22\n",
            "  204. state_q0003_23\n",
            "  205. state_q0003_24\n",
            "  206. state_q0003_25\n",
            "  207. state_q0003_26\n",
            "  208. state_q0003_27\n",
            "  209. state_q0003_28\n",
            "  210. state_q0003_29\n",
            "  211. state_q0003_30\n",
            "  212. state_q0003_31\n",
            "  213. state_q0003_32\n",
            "  214. state_q0003_33\n",
            "  215. state_q0003_34\n",
            "  216. state_q0003_35\n",
            "  217. state_q0003_36\n",
            "  218. state_q0003_37\n",
            "  219. state_q0003_38\n",
            "  220. state_q0003_39\n",
            "  221. state_q0003_40\n",
            "  222. state_q0003_41\n",
            "  223. state_q0003_42\n",
            "  224. state_q0003_43\n",
            "  225. state_q0003_44\n",
            "  226. state_q0003_45\n",
            "  227. state_q0003_46\n",
            "  228. state_q0003_47\n",
            "  229. state_q0003_48\n",
            "  230. state_q0003_49\n",
            "  231. state_q0003_50\n",
            "  232. state_q0003_51\n",
            "  233. state_q0003_52\n",
            "  234. state_q0003_53\n",
            "  235. state_q0003_54\n",
            "  236. state_q0003_55\n",
            "  237. state_q0003_56\n",
            "  238. state_q0003_57\n",
            "  239. state_q0003_58\n",
            "  240. state_q0003_59\n",
            "  241. state_u_0\n",
            "  242. state_u_1\n",
            "  243. state_u_2\n",
            "  244. state_u_3\n",
            "  245. state_u_4\n",
            "  246. state_u_5\n",
            "  247. state_u_6\n",
            "  248. state_u_7\n",
            "  249. state_u_8\n",
            "  250. state_u_9\n",
            "  251. state_u_10\n",
            "  252. state_u_11\n",
            "  253. state_u_12\n",
            "  254. state_u_13\n",
            "  255. state_u_14\n",
            "  256. state_u_15\n",
            "  257. state_u_16\n",
            "  258. state_u_17\n",
            "  259. state_u_18\n",
            "  260. state_u_19\n",
            "  261. state_u_20\n",
            "  262. state_u_21\n",
            "  263. state_u_22\n",
            "  264. state_u_23\n",
            "  265. state_u_24\n",
            "  266. state_u_25\n",
            "  267. state_u_26\n",
            "  268. state_u_27\n",
            "  269. state_u_28\n",
            "  270. state_u_29\n",
            "  271. state_u_30\n",
            "  272. state_u_31\n",
            "  273. state_u_32\n",
            "  274. state_u_33\n",
            "  275. state_u_34\n",
            "  276. state_u_35\n",
            "  277. state_u_36\n",
            "  278. state_u_37\n",
            "  279. state_u_38\n",
            "  280. state_u_39\n",
            "  281. state_u_40\n",
            "  282. state_u_41\n",
            "  283. state_u_42\n",
            "  284. state_u_43\n",
            "  285. state_u_44\n",
            "  286. state_u_45\n",
            "  287. state_u_46\n",
            "  288. state_u_47\n",
            "  289. state_u_48\n",
            "  290. state_u_49\n",
            "  291. state_u_50\n",
            "  292. state_u_51\n",
            "  293. state_u_52\n",
            "  294. state_u_53\n",
            "  295. state_u_54\n",
            "  296. state_u_55\n",
            "  297. state_u_56\n",
            "  298. state_u_57\n",
            "  299. state_u_58\n",
            "  300. state_u_59\n",
            "  301. state_v_0\n",
            "  302. state_v_1\n",
            "  303. state_v_2\n",
            "  304. state_v_3\n",
            "  305. state_v_4\n",
            "  306. state_v_5\n",
            "  307. state_v_6\n",
            "  308. state_v_7\n",
            "  309. state_v_8\n",
            "  310. state_v_9\n",
            "  311. state_v_10\n",
            "  312. state_v_11\n",
            "  313. state_v_12\n",
            "  314. state_v_13\n",
            "  315. state_v_14\n",
            "  316. state_v_15\n",
            "  317. state_v_16\n",
            "  318. state_v_17\n",
            "  319. state_v_18\n",
            "  320. state_v_19\n",
            "  321. state_v_20\n",
            "  322. state_v_21\n",
            "  323. state_v_22\n",
            "  324. state_v_23\n",
            "  325. state_v_24\n",
            "  326. state_v_25\n",
            "  327. state_v_26\n",
            "  328. state_v_27\n",
            "  329. state_v_28\n",
            "  330. state_v_29\n",
            "  331. state_v_30\n",
            "  332. state_v_31\n",
            "  333. state_v_32\n",
            "  334. state_v_33\n",
            "  335. state_v_34\n",
            "  336. state_v_35\n",
            "  337. state_v_36\n",
            "  338. state_v_37\n",
            "  339. state_v_38\n",
            "  340. state_v_39\n",
            "  341. state_v_40\n",
            "  342. state_v_41\n",
            "  343. state_v_42\n",
            "  344. state_v_43\n",
            "  345. state_v_44\n",
            "  346. state_v_45\n",
            "  347. state_v_46\n",
            "  348. state_v_47\n",
            "  349. state_v_48\n",
            "  350. state_v_49\n",
            "  351. state_v_50\n",
            "  352. state_v_51\n",
            "  353. state_v_52\n",
            "  354. state_v_53\n",
            "  355. state_v_54\n",
            "  356. state_v_55\n",
            "  357. state_v_56\n",
            "  358. state_v_57\n",
            "  359. state_v_58\n",
            "  360. state_v_59\n",
            "  361. state_ps\n",
            "  362. pbuf_SOLIN\n",
            "  363. pbuf_LHFLX\n",
            "  364. pbuf_SHFLX\n",
            "  365. pbuf_TAUX\n",
            "  366. pbuf_TAUY\n",
            "  367. pbuf_COSZRS\n",
            "  368. cam_in_ALDIF\n",
            "  369. cam_in_ALDIR\n",
            "  370. cam_in_ASDIF\n",
            "  371. cam_in_ASDIR\n",
            "  372. cam_in_LWUP\n",
            "  373. cam_in_ICEFRAC\n",
            "  374. cam_in_LANDFRAC\n",
            "  375. cam_in_OCNFRAC\n",
            "  376. cam_in_SNOWHLAND\n",
            "  377. pbuf_ozone_0\n",
            "  378. pbuf_ozone_1\n",
            "  379. pbuf_ozone_2\n",
            "  380. pbuf_ozone_3\n",
            "  381. pbuf_ozone_4\n",
            "  382. pbuf_ozone_5\n",
            "  383. pbuf_ozone_6\n",
            "  384. pbuf_ozone_7\n",
            "  385. pbuf_ozone_8\n",
            "  386. pbuf_ozone_9\n",
            "  387. pbuf_ozone_10\n",
            "  388. pbuf_ozone_11\n",
            "  389. pbuf_ozone_12\n",
            "  390. pbuf_ozone_13\n",
            "  391. pbuf_ozone_14\n",
            "  392. pbuf_ozone_15\n",
            "  393. pbuf_ozone_16\n",
            "  394. pbuf_ozone_17\n",
            "  395. pbuf_ozone_18\n",
            "  396. pbuf_ozone_19\n",
            "  397. pbuf_ozone_20\n",
            "  398. pbuf_ozone_21\n",
            "  399. pbuf_ozone_22\n",
            "  400. pbuf_ozone_23\n",
            "  401. pbuf_ozone_24\n",
            "  402. pbuf_ozone_25\n",
            "  403. pbuf_ozone_26\n",
            "  404. pbuf_ozone_27\n",
            "  405. pbuf_ozone_28\n",
            "  406. pbuf_ozone_29\n",
            "  407. pbuf_ozone_30\n",
            "  408. pbuf_ozone_31\n",
            "  409. pbuf_ozone_32\n",
            "  410. pbuf_ozone_33\n",
            "  411. pbuf_ozone_34\n",
            "  412. pbuf_ozone_35\n",
            "  413. pbuf_ozone_36\n",
            "  414. pbuf_ozone_37\n",
            "  415. pbuf_ozone_38\n",
            "  416. pbuf_ozone_39\n",
            "  417. pbuf_ozone_40\n",
            "  418. pbuf_ozone_41\n",
            "  419. pbuf_ozone_42\n",
            "  420. pbuf_ozone_43\n",
            "  421. pbuf_ozone_44\n",
            "  422. pbuf_ozone_45\n",
            "  423. pbuf_ozone_46\n",
            "  424. pbuf_ozone_47\n",
            "  425. pbuf_ozone_48\n",
            "  426. pbuf_ozone_49\n",
            "  427. pbuf_ozone_50\n",
            "  428. pbuf_ozone_51\n",
            "  429. pbuf_ozone_52\n",
            "  430. pbuf_ozone_53\n",
            "  431. pbuf_ozone_54\n",
            "  432. pbuf_ozone_55\n",
            "  433. pbuf_ozone_56\n",
            "  434. pbuf_ozone_57\n",
            "  435. pbuf_ozone_58\n",
            "  436. pbuf_ozone_59\n",
            "  437. pbuf_CH4_0\n",
            "  438. pbuf_CH4_1\n",
            "  439. pbuf_CH4_2\n",
            "  440. pbuf_CH4_3\n",
            "  441. pbuf_CH4_4\n",
            "  442. pbuf_CH4_5\n",
            "  443. pbuf_CH4_6\n",
            "  444. pbuf_CH4_7\n",
            "  445. pbuf_CH4_8\n",
            "  446. pbuf_CH4_9\n",
            "  447. pbuf_CH4_10\n",
            "  448. pbuf_CH4_11\n",
            "  449. pbuf_CH4_12\n",
            "  450. pbuf_CH4_13\n",
            "  451. pbuf_CH4_14\n",
            "  452. pbuf_CH4_15\n",
            "  453. pbuf_CH4_16\n",
            "  454. pbuf_CH4_17\n",
            "  455. pbuf_CH4_18\n",
            "  456. pbuf_CH4_19\n",
            "  457. pbuf_CH4_20\n",
            "  458. pbuf_CH4_21\n",
            "  459. pbuf_CH4_22\n",
            "  460. pbuf_CH4_23\n",
            "  461. pbuf_CH4_24\n",
            "  462. pbuf_CH4_25\n",
            "  463. pbuf_CH4_26\n",
            "  464. pbuf_N2O_0\n",
            "  465. pbuf_N2O_1\n",
            "  466. pbuf_N2O_2\n",
            "  467. pbuf_N2O_3\n",
            "  468. pbuf_N2O_4\n",
            "  469. pbuf_N2O_5\n",
            "  470. pbuf_N2O_6\n",
            "  471. pbuf_N2O_7\n",
            "  472. pbuf_N2O_8\n",
            "  473. pbuf_N2O_9\n",
            "  474. pbuf_N2O_10\n",
            "  475. pbuf_N2O_11\n",
            "  476. pbuf_N2O_12\n",
            "  477. pbuf_N2O_13\n",
            "  478. pbuf_N2O_14\n",
            "  479. pbuf_N2O_15\n",
            "  480. pbuf_N2O_16\n",
            "  481. pbuf_N2O_17\n",
            "  482. pbuf_N2O_18\n",
            "  483. pbuf_N2O_19\n",
            "  484. pbuf_N2O_20\n",
            "  485. pbuf_N2O_21\n",
            "  486. pbuf_N2O_22\n",
            "  487. pbuf_N2O_23\n",
            "  488. pbuf_N2O_24\n",
            "  489. pbuf_N2O_25\n",
            "  490. pbuf_N2O_26\n",
            "\n",
            "è¾“å‡ºç‰¹å¾ (302ä¸ª):\n",
            "    1. ptend_t_0\n",
            "    2. ptend_t_1\n",
            "    3. ptend_t_2\n",
            "    4. ptend_t_3\n",
            "    5. ptend_t_4\n",
            "    6. ptend_t_5\n",
            "    7. ptend_t_6\n",
            "    8. ptend_t_7\n",
            "    9. ptend_t_8\n",
            "   10. ptend_t_9\n",
            "   11. ptend_t_10\n",
            "   12. ptend_t_11\n",
            "   13. ptend_t_12\n",
            "   14. ptend_t_13\n",
            "   15. ptend_t_14\n",
            "   16. ptend_t_15\n",
            "   17. ptend_t_16\n",
            "   18. ptend_t_17\n",
            "   19. ptend_t_18\n",
            "   20. ptend_t_19\n",
            "   21. ptend_t_20\n",
            "   22. ptend_t_21\n",
            "   23. ptend_t_22\n",
            "   24. ptend_t_23\n",
            "   25. ptend_t_24\n",
            "   26. ptend_t_25\n",
            "   27. ptend_t_26\n",
            "   28. ptend_t_27\n",
            "   29. ptend_t_28\n",
            "   30. ptend_t_29\n",
            "   31. ptend_t_30\n",
            "   32. ptend_t_31\n",
            "   33. ptend_t_32\n",
            "   34. ptend_t_33\n",
            "   35. ptend_t_34\n",
            "   36. ptend_t_35\n",
            "   37. ptend_t_36\n",
            "   38. ptend_t_37\n",
            "   39. ptend_t_38\n",
            "   40. ptend_t_39\n",
            "   41. ptend_t_40\n",
            "   42. ptend_t_41\n",
            "   43. ptend_t_42\n",
            "   44. ptend_t_43\n",
            "   45. ptend_t_44\n",
            "   46. ptend_t_45\n",
            "   47. ptend_t_46\n",
            "   48. ptend_t_47\n",
            "   49. ptend_t_48\n",
            "   50. ptend_t_49\n",
            "   51. ptend_t_50\n",
            "   52. ptend_t_51\n",
            "   53. ptend_t_52\n",
            "   54. ptend_t_53\n",
            "   55. ptend_t_54\n",
            "   56. ptend_t_55\n",
            "   57. ptend_t_56\n",
            "   58. ptend_t_57\n",
            "   59. ptend_t_58\n",
            "   60. ptend_t_59\n",
            "   61. ptend_q0001_0\n",
            "   62. ptend_q0001_12\n",
            "   63. ptend_q0001_13\n",
            "   64. ptend_q0001_14\n",
            "   65. ptend_q0001_15\n",
            "   66. ptend_q0001_16\n",
            "   67. ptend_q0001_17\n",
            "   68. ptend_q0001_18\n",
            "   69. ptend_q0001_19\n",
            "   70. ptend_q0001_20\n",
            "   71. ptend_q0001_21\n",
            "   72. ptend_q0001_22\n",
            "   73. ptend_q0001_23\n",
            "   74. ptend_q0001_24\n",
            "   75. ptend_q0001_25\n",
            "   76. ptend_q0001_26\n",
            "   77. ptend_q0001_27\n",
            "   78. ptend_q0001_28\n",
            "   79. ptend_q0001_29\n",
            "   80. ptend_q0001_30\n",
            "   81. ptend_q0001_31\n",
            "   82. ptend_q0001_32\n",
            "   83. ptend_q0001_33\n",
            "   84. ptend_q0001_34\n",
            "   85. ptend_q0001_35\n",
            "   86. ptend_q0001_36\n",
            "   87. ptend_q0001_37\n",
            "   88. ptend_q0001_38\n",
            "   89. ptend_q0001_39\n",
            "   90. ptend_q0001_40\n",
            "   91. ptend_q0001_41\n",
            "   92. ptend_q0001_42\n",
            "   93. ptend_q0001_43\n",
            "   94. ptend_q0001_44\n",
            "   95. ptend_q0001_45\n",
            "   96. ptend_q0001_46\n",
            "   97. ptend_q0001_47\n",
            "   98. ptend_q0001_48\n",
            "   99. ptend_q0001_49\n",
            "  100. ptend_q0001_50\n",
            "  101. ptend_q0001_51\n",
            "  102. ptend_q0001_52\n",
            "  103. ptend_q0001_53\n",
            "  104. ptend_q0001_54\n",
            "  105. ptend_q0001_55\n",
            "  106. ptend_q0001_56\n",
            "  107. ptend_q0001_57\n",
            "  108. ptend_q0001_58\n",
            "  109. ptend_q0001_59\n",
            "  110. ptend_q0002_0\n",
            "  111. ptend_q0002_23\n",
            "  112. ptend_q0002_24\n",
            "  113. ptend_q0002_25\n",
            "  114. ptend_q0002_26\n",
            "  115. ptend_q0002_27\n",
            "  116. ptend_q0002_28\n",
            "  117. ptend_q0002_29\n",
            "  118. ptend_q0002_30\n",
            "  119. ptend_q0002_31\n",
            "  120. ptend_q0002_32\n",
            "  121. ptend_q0002_33\n",
            "  122. ptend_q0002_34\n",
            "  123. ptend_q0002_35\n",
            "  124. ptend_q0002_36\n",
            "  125. ptend_q0002_37\n",
            "  126. ptend_q0002_38\n",
            "  127. ptend_q0002_39\n",
            "  128. ptend_q0002_40\n",
            "  129. ptend_q0002_41\n",
            "  130. ptend_q0002_42\n",
            "  131. ptend_q0002_43\n",
            "  132. ptend_q0002_44\n",
            "  133. ptend_q0002_45\n",
            "  134. ptend_q0002_46\n",
            "  135. ptend_q0002_47\n",
            "  136. ptend_q0002_48\n",
            "  137. ptend_q0002_49\n",
            "  138. ptend_q0002_50\n",
            "  139. ptend_q0002_51\n",
            "  140. ptend_q0002_52\n",
            "  141. ptend_q0002_53\n",
            "  142. ptend_q0002_54\n",
            "  143. ptend_q0002_55\n",
            "  144. ptend_q0002_56\n",
            "  145. ptend_q0002_57\n",
            "  146. ptend_q0002_58\n",
            "  147. ptend_q0002_59\n",
            "  148. ptend_q0003_0\n",
            "  149. ptend_q0003_12\n",
            "  150. ptend_q0003_13\n",
            "  151. ptend_q0003_14\n",
            "  152. ptend_q0003_15\n",
            "  153. ptend_q0003_16\n",
            "  154. ptend_q0003_17\n",
            "  155. ptend_q0003_18\n",
            "  156. ptend_q0003_19\n",
            "  157. ptend_q0003_20\n",
            "  158. ptend_q0003_21\n",
            "  159. ptend_q0003_22\n",
            "  160. ptend_q0003_23\n",
            "  161. ptend_q0003_24\n",
            "  162. ptend_q0003_25\n",
            "  163. ptend_q0003_26\n",
            "  164. ptend_q0003_27\n",
            "  165. ptend_q0003_28\n",
            "  166. ptend_q0003_29\n",
            "  167. ptend_q0003_30\n",
            "  168. ptend_q0003_31\n",
            "  169. ptend_q0003_32\n",
            "  170. ptend_q0003_33\n",
            "  171. ptend_q0003_34\n",
            "  172. ptend_q0003_35\n",
            "  173. ptend_q0003_36\n",
            "  174. ptend_q0003_37\n",
            "  175. ptend_q0003_38\n",
            "  176. ptend_q0003_39\n",
            "  177. ptend_q0003_40\n",
            "  178. ptend_q0003_41\n",
            "  179. ptend_q0003_42\n",
            "  180. ptend_q0003_43\n",
            "  181. ptend_q0003_44\n",
            "  182. ptend_q0003_45\n",
            "  183. ptend_q0003_46\n",
            "  184. ptend_q0003_47\n",
            "  185. ptend_q0003_48\n",
            "  186. ptend_q0003_49\n",
            "  187. ptend_q0003_50\n",
            "  188. ptend_q0003_51\n",
            "  189. ptend_q0003_52\n",
            "  190. ptend_q0003_53\n",
            "  191. ptend_q0003_54\n",
            "  192. ptend_q0003_55\n",
            "  193. ptend_q0003_56\n",
            "  194. ptend_q0003_57\n",
            "  195. ptend_q0003_58\n",
            "  196. ptend_q0003_59\n",
            "  197. ptend_u_0\n",
            "  198. ptend_u_12\n",
            "  199. ptend_u_13\n",
            "  200. ptend_u_14\n",
            "  201. ptend_u_15\n",
            "  202. ptend_u_16\n",
            "  203. ptend_u_17\n",
            "  204. ptend_u_18\n",
            "  205. ptend_u_19\n",
            "  206. ptend_u_20\n",
            "  207. ptend_u_21\n",
            "  208. ptend_u_22\n",
            "  209. ptend_u_23\n",
            "  210. ptend_u_24\n",
            "  211. ptend_u_25\n",
            "  212. ptend_u_26\n",
            "  213. ptend_u_27\n",
            "  214. ptend_u_28\n",
            "  215. ptend_u_29\n",
            "  216. ptend_u_30\n",
            "  217. ptend_u_31\n",
            "  218. ptend_u_32\n",
            "  219. ptend_u_33\n",
            "  220. ptend_u_34\n",
            "  221. ptend_u_35\n",
            "  222. ptend_u_36\n",
            "  223. ptend_u_37\n",
            "  224. ptend_u_38\n",
            "  225. ptend_u_39\n",
            "  226. ptend_u_40\n",
            "  227. ptend_u_41\n",
            "  228. ptend_u_42\n",
            "  229. ptend_u_43\n",
            "  230. ptend_u_44\n",
            "  231. ptend_u_45\n",
            "  232. ptend_u_46\n",
            "  233. ptend_u_47\n",
            "  234. ptend_u_48\n",
            "  235. ptend_u_49\n",
            "  236. ptend_u_50\n",
            "  237. ptend_u_51\n",
            "  238. ptend_u_52\n",
            "  239. ptend_u_53\n",
            "  240. ptend_u_54\n",
            "  241. ptend_u_55\n",
            "  242. ptend_u_56\n",
            "  243. ptend_u_57\n",
            "  244. ptend_u_58\n",
            "  245. ptend_u_59\n",
            "  246. ptend_v_0\n",
            "  247. ptend_v_12\n",
            "  248. ptend_v_13\n",
            "  249. ptend_v_14\n",
            "  250. ptend_v_15\n",
            "  251. ptend_v_16\n",
            "  252. ptend_v_17\n",
            "  253. ptend_v_18\n",
            "  254. ptend_v_19\n",
            "  255. ptend_v_20\n",
            "  256. ptend_v_21\n",
            "  257. ptend_v_22\n",
            "  258. ptend_v_23\n",
            "  259. ptend_v_24\n",
            "  260. ptend_v_25\n",
            "  261. ptend_v_26\n",
            "  262. ptend_v_27\n",
            "  263. ptend_v_28\n",
            "  264. ptend_v_29\n",
            "  265. ptend_v_30\n",
            "  266. ptend_v_31\n",
            "  267. ptend_v_32\n",
            "  268. ptend_v_33\n",
            "  269. ptend_v_34\n",
            "  270. ptend_v_35\n",
            "  271. ptend_v_36\n",
            "  272. ptend_v_37\n",
            "  273. ptend_v_38\n",
            "  274. ptend_v_39\n",
            "  275. ptend_v_40\n",
            "  276. ptend_v_41\n",
            "  277. ptend_v_42\n",
            "  278. ptend_v_43\n",
            "  279. ptend_v_44\n",
            "  280. ptend_v_45\n",
            "  281. ptend_v_46\n",
            "  282. ptend_v_47\n",
            "  283. ptend_v_48\n",
            "  284. ptend_v_49\n",
            "  285. ptend_v_50\n",
            "  286. ptend_v_51\n",
            "  287. ptend_v_52\n",
            "  288. ptend_v_53\n",
            "  289. ptend_v_54\n",
            "  290. ptend_v_55\n",
            "  291. ptend_v_56\n",
            "  292. ptend_v_57\n",
            "  293. ptend_v_58\n",
            "  294. ptend_v_59\n",
            "  295. cam_out_NETSW\n",
            "  296. cam_out_FLWDS\n",
            "  297. cam_out_PRECSC\n",
            "  298. cam_out_PRECC\n",
            "  299. cam_out_SOLS\n",
            "  300. cam_out_SOLL\n",
            "  301. cam_out_SOLSD\n",
            "  302. cam_out_SOLLD\n",
            "\n",
            "================================================================================\n",
            "â° æ—¶é—´è¿žç»­æ€§éªŒè¯\n",
            "================================================================================\n",
            "\n",
            "ã€ç›¸é‚»æ ·æœ¬å˜åŒ–æ£€æŸ¥ã€‘\n",
            "  ç‰¹å¾: state_t_0\n",
            "  è®­ç»ƒé›†ç›¸é‚»æ ·æœ¬å¹³å‡å˜åŒ–: 2.818764e+00\n",
            "  è®­ç»ƒé›†ç›¸é‚»æ ·æœ¬æœ€å¤§å˜åŒ–: 7.305606e+01\n",
            "  æµ‹è¯•é›†ç›¸é‚»æ ·æœ¬å¹³å‡å˜åŒ–: 2.924769e+00\n",
            "  æµ‹è¯•é›†ç›¸é‚»æ ·æœ¬æœ€å¤§å˜åŒ–: 7.431660e+01\n",
            "\n",
            "  è®­ç»ƒ/æµ‹è¯•è¾¹ç•Œè·³è·ƒ: 3.311691e+00\n",
            "  âœ… è¾¹ç•Œè·³è·ƒæ­£å¸¸ï¼Œæ•°æ®åŸºæœ¬è¿žç»­\n",
            "\n",
            "================================================================================\n",
            "âœ… æ•°æ®æŽ¢ç´¢å®Œæˆï¼train_df å’Œ test_df å·²å‡†å¤‡å¥½\n",
            "================================================================================\n",
            "\n",
            "ðŸ’¾ å·²åˆ›å»ºå…¨å±€å˜é‡:\n",
            "  - train_df: è®­ç»ƒæ•°æ® (625000, 793)\n",
            "  - test_df: æµ‹è¯•æ•°æ® (625000, 793)\n",
            "  - INPUT_FEATURES: è¾“å…¥ç‰¹å¾åˆ—è¡¨ (é•¿åº¦: 490)\n",
            "  - OUTPUT_FEATURES: è¾“å‡ºç‰¹å¾åˆ—è¡¨ (é•¿åº¦: 302)\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ æ•°æ®å‡†å¤‡æµç¨‹:\n",
            "  1. âœ… æ•°æ®åŠ è½½\n",
            "  2. âœ… 90/10åˆ’åˆ†ï¼ˆæŒ‰é¡ºåºï¼‰\n",
            "  3. âœ… ç‰¹å¾è¯†åˆ«\n",
            "  4. âœ… è¿žç»­æ€§éªŒè¯\n",
            "  5. â­ï¸  å¯ä»¥å¼€å§‹è®­ç»ƒSSTæ¨¡åž‹\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "LEAPæ•°æ®åŠ è½½ä¸ŽæŽ¢ç´¢\n",
        "åŠ è½½å®Œæ•´æ•°æ®å¹¶æŒ‰90/10åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# é…ç½®ï¼šæ•°æ®è·¯å¾„\n",
        "# ============================================================================\n",
        "\n",
        "# æ•°æ®é›†è·¯å¾„\n",
        "DATASET_PATHS = [\n",
        "    '/content',\n",
        "]\n",
        "\n",
        "TRAIN_SPLIT = 0.5  # å‰90%ç”¨äºŽè®­ç»ƒ\n",
        "\n",
        "# ============================================================================\n",
        "# åŠ è½½æ•°æ® - å®Œæ•´åŠ è½½å¹¶æŒ‰é¡ºåºåˆ’åˆ†\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"ðŸ” LEAPæ•°æ®åŠ è½½ - 90/10é¡ºåºåˆ’åˆ†\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "all_data = []\n",
        "total_samples = 0\n",
        "\n",
        "for dataset_path in DATASET_PATHS:\n",
        "    path = Path(dataset_path)\n",
        "    if not path.exists():\n",
        "        print(f\"âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {dataset_path}\")\n",
        "        continue\n",
        "\n",
        "    # èŽ·å–æ‰€æœ‰parquetæ–‡ä»¶\n",
        "    parquet_files = sorted(path.glob('*.parquet'))\n",
        "    print(f\"\\nðŸ“‚ {path.name}: æ‰¾åˆ° {len(parquet_files)} ä¸ªæ–‡ä»¶\")\n",
        "\n",
        "    for file in tqdm(parquet_files, desc=f\"  åŠ è½½{path.name}\"):\n",
        "        # è¯»å–å®Œæ•´æ–‡ä»¶\n",
        "        df_full = pd.read_parquet(file)\n",
        "        total_samples += len(df_full)\n",
        "\n",
        "        all_data.append(df_full)\n",
        "\n",
        "        print(f\"    {file.name}: {len(df_full):,} æ ·æœ¬\")\n",
        "\n",
        "# åˆå¹¶æ‰€æœ‰æ•°æ®ï¼ˆä¿æŒé¡ºåºï¼‰\n",
        "full_df = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "print(f\"\\nâœ… æ•°æ®åŠ è½½å®Œæˆ!\")\n",
        "print(f\"  æ€»æ ·æœ¬æ•°: {total_samples:,}\")\n",
        "print(f\"  åˆå¹¶åŽæ•°æ®å½¢çŠ¶: {full_df.shape}\")\n",
        "\n",
        "# ============================================================================\n",
        "# æŒ‰é¡ºåºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆ90/10ï¼‰\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"âœ‚ï¸  æ•°æ®åˆ’åˆ† (90% Train / 10% Test)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# æŒ‰é¡ºåºåˆ’åˆ†\n",
        "split_idx = int(len(full_df) * TRAIN_SPLIT)\n",
        "\n",
        "train_df = full_df.iloc[:split_idx].copy()\n",
        "test_df = full_df.iloc[split_idx:].copy()\n",
        "\n",
        "print(f\"\\nã€åˆ’åˆ†ç»“æžœã€‘\")\n",
        "print(f\"  è®­ç»ƒé›† (å‰90%): {len(train_df):,} æ ·æœ¬\")\n",
        "print(f\"  æµ‹è¯•é›† (åŽ10%): {len(test_df):,} æ ·æœ¬\")\n",
        "print(f\"  åˆ’åˆ†æ¯”ä¾‹: {len(train_df)/len(full_df)*100:.1f}% / {len(test_df)/len(full_df)*100:.1f}%\")\n",
        "\n",
        "# æ£€æŸ¥indexè¿žç»­æ€§\n",
        "print(f\"\\nã€Indexè¿žç»­æ€§æ£€æŸ¥ã€‘\")\n",
        "if hasattr(train_df.index, 'is_monotonic_increasing'):\n",
        "    train_continuous = train_df.index.is_monotonic_increasing\n",
        "    test_continuous = test_df.index.is_monotonic_increasing\n",
        "    print(f\"  è®­ç»ƒé›†indexè¿žç»­: {'âœ…' if train_continuous else 'âŒ'}\")\n",
        "    print(f\"  æµ‹è¯•é›†indexè¿žç»­: {'âœ…' if test_continuous else 'âŒ'}\")\n",
        "\n",
        "print(f\"  è®­ç»ƒé›†indexèŒƒå›´: [{train_df.index.min()}, {train_df.index.max()}]\")\n",
        "print(f\"  æµ‹è¯•é›†indexèŒƒå›´: [{test_df.index.min()}, {test_df.index.max()}]\")\n",
        "\n",
        "# é‡Šæ”¾å†…å­˜\n",
        "del full_df\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# ============================================================================\n",
        "# æ•°æ®æŽ¢ç´¢ - æŸ¥çœ‹è®­ç»ƒé›†æƒ…å†µ\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ðŸ“Š è®­ç»ƒé›†æ•°æ®åŸºæœ¬ä¿¡æ¯\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1. åŸºæœ¬ä¿¡æ¯\n",
        "print(f\"\\nã€æ•°æ®ç»´åº¦ã€‘\")\n",
        "print(f\"  è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_df):,}\")\n",
        "print(f\"  æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_df):,}\")\n",
        "print(f\"  ç‰¹å¾æ•°: {len(train_df.columns)}\")\n",
        "print(f\"  è®­ç»ƒé›†å†…å­˜: {train_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "print(f\"  æµ‹è¯•é›†å†…å­˜: {test_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# 2. åˆ—ååˆ†ç±»\n",
        "print(f\"\\nã€ç‰¹å¾åˆ†ç±»ã€‘\")\n",
        "all_cols = train_df.columns.tolist()\n",
        "\n",
        "# è¾“å…¥ç‰¹å¾\n",
        "input_patterns = ['state_', 'pbuf_', 'cam_in_']\n",
        "input_cols = [col for col in all_cols if any(col.startswith(p) for p in input_patterns)]\n",
        "\n",
        "# è¾“å‡ºç‰¹å¾\n",
        "output_patterns = ['ptend_', 'cam_out_']\n",
        "output_cols = [col for col in all_cols if any(col.startswith(p) for p in output_patterns)]\n",
        "\n",
        "print(f\"  è¾“å…¥ç‰¹å¾ (INPUT):  {len(input_cols)} ä¸ª\")\n",
        "for pattern in input_patterns:\n",
        "    count = len([c for c in input_cols if c.startswith(pattern)])\n",
        "    if count > 0:\n",
        "        print(f\"    - {pattern}*: {count} ä¸ª\")\n",
        "\n",
        "print(f\"\\n  è¾“å‡ºç‰¹å¾ (OUTPUT): {len(output_cols)} ä¸ª\")\n",
        "for pattern in output_patterns:\n",
        "    count = len([c for c in output_cols if c.startswith(pattern)])\n",
        "    if count > 0:\n",
        "        print(f\"    - {pattern}*: {count} ä¸ª\")\n",
        "\n",
        "other_cols = [c for c in all_cols if c not in input_cols and c not in output_cols]\n",
        "if other_cols:\n",
        "    print(f\"\\n  å…¶ä»–åˆ—: {len(other_cols)} ä¸ª\")\n",
        "    print(f\"    {other_cols[:5]}\")\n",
        "\n",
        "# 3. æ•°æ®ç±»åž‹\n",
        "print(f\"\\nã€æ•°æ®ç±»åž‹ã€‘\")\n",
        "print(train_df.dtypes.value_counts().to_dict())\n",
        "\n",
        "# 4. ç¼ºå¤±å€¼æ£€æŸ¥\n",
        "print(f\"\\nã€ç¼ºå¤±å€¼ã€‘\")\n",
        "missing_train = train_df.isnull().sum()\n",
        "missing_test = test_df.isnull().sum()\n",
        "\n",
        "if missing_train.sum() == 0:\n",
        "    print(\"  è®­ç»ƒé›†: âœ… æ— ç¼ºå¤±å€¼\")\n",
        "else:\n",
        "    print(f\"  è®­ç»ƒé›†: âš ï¸  å‘çŽ°ç¼ºå¤±å€¼:\")\n",
        "    print(missing_train[missing_train > 0].head(10))\n",
        "\n",
        "if missing_test.sum() == 0:\n",
        "    print(\"  æµ‹è¯•é›†: âœ… æ— ç¼ºå¤±å€¼\")\n",
        "else:\n",
        "    print(f\"  æµ‹è¯•é›†: âš ï¸  å‘çŽ°ç¼ºå¤±å€¼:\")\n",
        "    print(missing_test[missing_test > 0].head(10))\n",
        "\n",
        "# 5. è¾“å…¥ç‰¹å¾ç»Ÿè®¡ï¼ˆè®­ç»ƒé›†ï¼‰\n",
        "print(f\"\\nã€è¾“å…¥ç‰¹å¾ç»Ÿè®¡ - è®­ç»ƒé›†ã€‘\")\n",
        "input_stats = train_df[input_cols].describe()\n",
        "print(f\"  å‡å€¼èŒƒå›´: [{input_stats.loc['mean'].min():.2e}, {input_stats.loc['mean'].max():.2e}]\")\n",
        "print(f\"  æ ‡å‡†å·®èŒƒå›´: [{input_stats.loc['std'].min():.2e}, {input_stats.loc['std'].max():.2e}]\")\n",
        "print(f\"  æœ€å°å€¼èŒƒå›´: [{input_stats.loc['min'].min():.2e}, {input_stats.loc['min'].max():.2e}]\")\n",
        "print(f\"  æœ€å¤§å€¼èŒƒå›´: [{input_stats.loc['max'].min():.2e}, {input_stats.loc['max'].max():.2e}]\")\n",
        "\n",
        "# 6. è¾“å‡ºç‰¹å¾ç»Ÿè®¡ï¼ˆè®­ç»ƒé›†ï¼‰\n",
        "print(f\"\\nã€è¾“å‡ºç‰¹å¾ç»Ÿè®¡ - è®­ç»ƒé›†ã€‘\")\n",
        "output_stats = train_df[output_cols].describe()\n",
        "print(f\"  å‡å€¼èŒƒå›´: [{output_stats.loc['mean'].min():.2e}, {output_stats.loc['mean'].max():.2e}]\")\n",
        "print(f\"  æ ‡å‡†å·®èŒƒå›´: [{output_stats.loc['std'].min():.2e}, {output_stats.loc['std'].max():.2e}]\")\n",
        "print(f\"  æœ€å°å€¼èŒƒå›´: [{output_stats.loc['min'].min():.2e}, {output_stats.loc['min'].max():.2e}]\")\n",
        "print(f\"  æœ€å¤§å€¼èŒƒå›´: [{output_stats.loc['max'].min():.2e}, {output_stats.loc['max'].max():.2e}]\")\n",
        "\n",
        "# 7. ç¤ºä¾‹æ•°æ®\n",
        "print(f\"\\nã€è®­ç»ƒé›†æ•°æ®é¢„è§ˆã€‘å‰5ä¸ªè¾“å…¥ç‰¹å¾ + å‰5ä¸ªè¾“å‡ºç‰¹å¾\")\n",
        "preview_cols = input_cols[:5] + output_cols[:5]\n",
        "print(train_df[preview_cols].head())\n",
        "\n",
        "print(f\"\\nã€æµ‹è¯•é›†æ•°æ®é¢„è§ˆã€‘\")\n",
        "print(test_df[preview_cols].head())\n",
        "\n",
        "# 8. è¯¦ç»†åˆ—ååˆ—è¡¨\n",
        "print(f\"\\nã€å®Œæ•´åˆ—ååˆ—è¡¨ã€‘\")\n",
        "print(f\"\\nè¾“å…¥ç‰¹å¾ ({len(input_cols)}ä¸ª):\")\n",
        "for i, col in enumerate(input_cols, 1):\n",
        "    print(f\"  {i:3d}. {col}\")\n",
        "\n",
        "print(f\"\\nè¾“å‡ºç‰¹å¾ ({len(output_cols)}ä¸ª):\")\n",
        "for i, col in enumerate(output_cols, 1):\n",
        "    print(f\"  {i:3d}. {col}\")\n",
        "\n",
        "# ============================================================================\n",
        "# æ—¶é—´è¿žç»­æ€§éªŒè¯ï¼ˆé‡è¦ï¼ï¼‰\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"â° æ—¶é—´è¿žç»­æ€§éªŒè¯\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# æ£€æŸ¥ç›¸é‚»æ ·æœ¬çš„å˜åŒ–å¹…åº¦ï¼ˆåˆ¤æ–­æ˜¯å¦æ—¶é—´è¿žç»­ï¼‰\n",
        "print(\"\\nã€ç›¸é‚»æ ·æœ¬å˜åŒ–æ£€æŸ¥ã€‘\")\n",
        "sample_feature = input_cols[0]  # ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾æ£€æŸ¥\n",
        "\n",
        "train_diff = train_df[sample_feature].diff().abs()\n",
        "test_diff = test_df[sample_feature].diff().abs()\n",
        "\n",
        "print(f\"  ç‰¹å¾: {sample_feature}\")\n",
        "print(f\"  è®­ç»ƒé›†ç›¸é‚»æ ·æœ¬å¹³å‡å˜åŒ–: {train_diff.mean():.6e}\")\n",
        "print(f\"  è®­ç»ƒé›†ç›¸é‚»æ ·æœ¬æœ€å¤§å˜åŒ–: {train_diff.max():.6e}\")\n",
        "print(f\"  æµ‹è¯•é›†ç›¸é‚»æ ·æœ¬å¹³å‡å˜åŒ–: {test_diff.mean():.6e}\")\n",
        "print(f\"  æµ‹è¯•é›†ç›¸é‚»æ ·æœ¬æœ€å¤§å˜åŒ–: {test_diff.max():.6e}\")\n",
        "\n",
        "# æ£€æŸ¥trainå’Œtestäº¤ç•Œå¤„çš„è·³è·ƒ\n",
        "boundary_jump = abs(test_df[sample_feature].iloc[0] - train_df[sample_feature].iloc[-1])\n",
        "print(f\"\\n  è®­ç»ƒ/æµ‹è¯•è¾¹ç•Œè·³è·ƒ: {boundary_jump:.6e}\")\n",
        "\n",
        "if boundary_jump > train_diff.quantile(0.99):\n",
        "    print(f\"  âš ï¸  è¾¹ç•Œè·³è·ƒè¾ƒå¤§ï¼Œå¯èƒ½æ•°æ®ä¸å®Œå…¨è¿žç»­\")\n",
        "else:\n",
        "    print(f\"  âœ… è¾¹ç•Œè·³è·ƒæ­£å¸¸ï¼Œæ•°æ®åŸºæœ¬è¿žç»­\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"âœ… æ•°æ®æŽ¢ç´¢å®Œæˆï¼train_df å’Œ test_df å·²å‡†å¤‡å¥½\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# ============================================================================\n",
        "# ä¿å­˜å˜é‡ä¾›åŽç»­ä½¿ç”¨\n",
        "# ============================================================================\n",
        "\n",
        "# å°†å…³é”®å˜é‡å¯¼å‡º\n",
        "INPUT_FEATURES = input_cols\n",
        "OUTPUT_FEATURES = output_cols\n",
        "\n",
        "print(f\"\\nðŸ’¾ å·²åˆ›å»ºå…¨å±€å˜é‡:\")\n",
        "print(f\"  - train_df: è®­ç»ƒæ•°æ® {train_df.shape}\")\n",
        "print(f\"  - test_df: æµ‹è¯•æ•°æ® {test_df.shape}\")\n",
        "print(f\"  - INPUT_FEATURES: è¾“å…¥ç‰¹å¾åˆ—è¡¨ (é•¿åº¦: {len(INPUT_FEATURES)})\")\n",
        "print(f\"  - OUTPUT_FEATURES: è¾“å‡ºç‰¹å¾åˆ—è¡¨ (é•¿åº¦: {len(OUTPUT_FEATURES)})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ðŸŽ¯ æ•°æ®å‡†å¤‡æµç¨‹:\")\n",
        "print(\"  1. âœ… æ•°æ®åŠ è½½\")\n",
        "print(\"  2. âœ… 90/10åˆ’åˆ†ï¼ˆæŒ‰é¡ºåºï¼‰\")\n",
        "print(\"  3. âœ… ç‰¹å¾è¯†åˆ«\")\n",
        "print(\"  4. âœ… è¿žç»­æ€§éªŒè¯\")\n",
        "print(\"  5. â­ï¸  å¯ä»¥å¼€å§‹è®­ç»ƒSSTæ¨¡åž‹\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# æ–¹å¼1: æ‰‹åŠ¨åˆ—å‡ºè¦åˆ é™¤çš„ç‰¹å¾åç§°\n",
        "FEATURES_TO_REMOVE = [\n",
        "    # âŒ 100%é›¶å€¼çš„è¾“å‡ºç‰¹å¾ï¼ˆå¿…åˆ ï¼ï¼‰\n",
        "    'ptend_q0003_0',\n",
        "    'ptend_u_0',\n",
        "    'ptend_q0002_0',\n",
        "    'ptend_v_0',\n",
        "    'ptend_q0001_0',\n",
        "\n",
        "    # ðŸš¨ æ–°å¢žï¼šåˆ é™¤æ‰€æœ‰ptend_qç›¸å…³ä¿¡å·ï¼ˆåŸºäºŽæ‚¨çš„è¯Šæ–­æŠ¥å‘Šï¼‰\n",
        "    # ptend_q0001 ç³»åˆ—\n",
        "    'ptend_q0001_12', 'ptend_q0001_13', 'ptend_q0001_14', 'ptend_q0001_15', 'ptend_q0001_16',\n",
        "    'ptend_q0001_17', 'ptend_q0001_18', 'ptend_q0001_19', 'ptend_q0001_20', 'ptend_q0001_21',\n",
        "    'ptend_q0001_22', 'ptend_q0001_23', 'ptend_q0001_24', 'ptend_q0001_25', 'ptend_q0001_26',\n",
        "    'ptend_q0001_27', 'ptend_q0001_28', 'ptend_q0001_29', 'ptend_q0001_30', 'ptend_q0001_31',\n",
        "    'ptend_q0001_32', 'ptend_q0001_33', 'ptend_q0001_34', 'ptend_q0001_35', 'ptend_q0001_36',\n",
        "    'ptend_q0001_37', 'ptend_q0001_38', 'ptend_q0001_39', 'ptend_q0001_40', 'ptend_q0001_41',\n",
        "    'ptend_q0001_42', 'ptend_q0001_43', 'ptend_q0001_44', 'ptend_q0001_45', 'ptend_q0001_46',\n",
        "    'ptend_q0001_47', 'ptend_q0001_48', 'ptend_q0001_49', 'ptend_q0001_50', 'ptend_q0001_51',\n",
        "    'ptend_q0001_52', 'ptend_q0001_53', 'ptend_q0001_54', 'ptend_q0001_55', 'ptend_q0001_56',\n",
        "    'ptend_q0001_57', 'ptend_q0001_58', 'ptend_q0001_59',\n",
        "\n",
        "    # ptend_q0002 ç³»åˆ—\n",
        "    'ptend_q0002_23', 'ptend_q0002_24', 'ptend_q0002_25', 'ptend_q0002_26', 'ptend_q0002_27',\n",
        "    'ptend_q0002_28', 'ptend_q0002_29', 'ptend_q0002_30', 'ptend_q0002_31', 'ptend_q0002_32',\n",
        "    'ptend_q0002_33', 'ptend_q0002_34', 'ptend_q0002_35', 'ptend_q0002_36', 'ptend_q0002_37',\n",
        "    'ptend_q0002_38', 'ptend_q0002_39', 'ptend_q0002_40', 'ptend_q0002_41', 'ptend_q0002_42',\n",
        "    'ptend_q0002_43', 'ptend_q0002_44', 'ptend_q0002_45', 'ptend_q0002_46', 'ptend_q0002_47',\n",
        "    'ptend_q0002_48', 'ptend_q0002_49', 'ptend_q0002_50', 'ptend_q0002_51', 'ptend_q0002_52',\n",
        "    'ptend_q0002_53', 'ptend_q0002_54', 'ptend_q0002_55', 'ptend_q0002_56', 'ptend_q0002_57',\n",
        "    'ptend_q0002_58', 'ptend_q0002_59',\n",
        "\n",
        "    # ptend_q0003 ç³»åˆ—\n",
        "    'ptend_q0003_12', 'ptend_q0003_13', 'ptend_q0003_14', 'ptend_q0003_15', 'ptend_q0003_16',\n",
        "    'ptend_q0003_17', 'ptend_q0003_18', 'ptend_q0003_19', 'ptend_q0003_20', 'ptend_q0003_21',\n",
        "    'ptend_q0003_22', 'ptend_q0003_23', 'ptend_q0003_24', 'ptend_q0003_25', 'ptend_q0003_26',\n",
        "    'ptend_q0003_27', 'ptend_q0003_28', 'ptend_q0003_29', 'ptend_q0003_30', 'ptend_q0003_31',\n",
        "    'ptend_q0003_32', 'ptend_q0003_33', 'ptend_q0003_34', 'ptend_q0003_35', 'ptend_q0003_36',\n",
        "    'ptend_q0003_37', 'ptend_q0003_38', 'ptend_q0003_39', 'ptend_q0003_40', 'ptend_q0003_41',\n",
        "    'ptend_q0003_42', 'ptend_q0003_43', 'ptend_q0003_44', 'ptend_q0003_45', 'ptend_q0003_46',\n",
        "    'ptend_q0003_47', 'ptend_q0003_48', 'ptend_q0003_49', 'ptend_q0003_50', 'ptend_q0003_51',\n",
        "    'ptend_q0003_52', 'ptend_q0003_53', 'ptend_q0003_54', 'ptend_q0003_55', 'ptend_q0003_56',\n",
        "    'ptend_q0003_57', 'ptend_q0003_58', 'ptend_q0003_59',\n",
        "\n",
        "    # âš ï¸ å¯é€‰ï¼šæ·»åŠ å…¶ä»–ä½ æƒ³åˆ é™¤çš„ç‰¹å¾\n",
        "    # 'state_q0002_16',  # ä¾‹å¦‚ï¼šé«˜é›¶å€¼çš„è¾“å…¥ç‰¹å¾\n",
        "    # 'state_q0002_15',\n",
        "\n",
        "    # ðŸ’¡ æç¤ºï¼š\n",
        "    # 1. æŸ¥çœ‹ä¸Šé¢Cell 1ç”Ÿæˆçš„CSVæ–‡ä»¶\n",
        "    # 2. å¤åˆ¶è¦åˆ é™¤çš„column_nameåˆ°è¿™é‡Œ\n",
        "    # 3. ä¸€è¡Œä¸€ä¸ªï¼Œç”¨é€—å·åˆ†éš”\n",
        "]\n",
        "\n",
        "# æ–¹å¼2: è‡ªåŠ¨æ ¹æ®é˜ˆå€¼åˆ é™¤ï¼ˆå¯é€‰ï¼Œå–æ¶ˆæ³¨é‡Šä½¿ç”¨ï¼‰\n",
        "# AUTO_REMOVE_CONFIG = {\n",
        "#     'output_zero_threshold': 0.90,  # è¾“å‡ºç‰¹å¾ï¼šé›¶å€¼â‰¥90%åˆ é™¤\n",
        "#     'input_zero_threshold': 0.95,   # è¾“å…¥ç‰¹å¾ï¼šé›¶å€¼â‰¥95%åˆ é™¤\n",
        "#     'all_zero_threshold': 1.0,      # æ‰€æœ‰ç‰¹å¾ï¼šé›¶å€¼=100%åˆ é™¤\n",
        "# }\n",
        "\n",
        "# ============================================================================\n",
        "# åº”ç”¨åˆ é™¤æ“ä½œ\n",
        "# ============================================================================\n",
        "\n",
        "def apply_feature_removal(df, features_to_remove, input_features, output_features, save_dir='/content/'):\n",
        "    \"\"\"\n",
        "    åº”ç”¨ç‰¹å¾åˆ é™¤æ“ä½œ\n",
        "\n",
        "    Args:\n",
        "        df: åŽŸå§‹DataFrame (df_train)\n",
        "        features_to_remove: è¦åˆ é™¤çš„ç‰¹å¾åˆ—è¡¨\n",
        "        input_features: åŽŸå§‹è¾“å…¥ç‰¹å¾åˆ—è¡¨\n",
        "        output_features: åŽŸå§‹è¾“å‡ºç‰¹å¾åˆ—è¡¨\n",
        "        save_dir: ä¿å­˜ç›®å½•\n",
        "\n",
        "    Returns:\n",
        "        df_clean: æ¸…æ´—åŽçš„DataFrame\n",
        "        input_features_clean: æ¸…æ´—åŽçš„è¾“å…¥ç‰¹å¾åˆ—è¡¨\n",
        "        output_features_clean: æ¸…æ´—åŽçš„è¾“å‡ºç‰¹å¾åˆ—è¡¨\n",
        "        removal_report: åˆ é™¤æŠ¥å‘Š\n",
        "    \"\"\"\n",
        "    print(\"=\"*80)\n",
        "    print(\"ðŸ“ Cell 2: åº”ç”¨ç‰¹å¾åˆ é™¤\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # éªŒè¯ç‰¹å¾æ˜¯å¦å­˜åœ¨\n",
        "    features_to_remove_valid = []\n",
        "    features_not_found = []\n",
        "\n",
        "    for feature in features_to_remove:\n",
        "        if feature in df.columns:\n",
        "            features_to_remove_valid.append(feature)\n",
        "        else:\n",
        "            features_not_found.append(feature)\n",
        "\n",
        "    if features_not_found:\n",
        "        print(f\"\\nâš ï¸  è­¦å‘Šï¼šä»¥ä¸‹ç‰¹å¾ä¸åœ¨DataFrameä¸­ï¼Œå°†è¢«å¿½ç•¥:\")\n",
        "        for f in features_not_found:\n",
        "            print(f\"   - {f}\")\n",
        "\n",
        "    # åŒºåˆ†è¾“å…¥å’Œè¾“å‡º\n",
        "    input_to_remove = [f for f in features_to_remove_valid if f in input_features]\n",
        "    output_to_remove = [f for f in features_to_remove_valid if f in output_features]\n",
        "\n",
        "    print(f\"\\nðŸ“Š åˆ é™¤ç»Ÿè®¡:\")\n",
        "    print(f\"   æ€»åˆ é™¤: {len(features_to_remove_valid)} ä¸ªç‰¹å¾\")\n",
        "    print(f\"   - è¾“å…¥ç‰¹å¾: {len(input_to_remove)} ä¸ª\")\n",
        "    print(f\"   - è¾“å‡ºç‰¹å¾: {len(output_to_remove)} ä¸ª\")\n",
        "\n",
        "    # # æ˜¾ç¤ºè¦åˆ é™¤çš„ç‰¹å¾\n",
        "    # if output_to_remove:\n",
        "    #     print(f\"\\nâŒ åˆ é™¤çš„è¾“å‡ºç‰¹å¾ ({len(output_to_remove)}ä¸ª):\")\n",
        "    #     for i, f in enumerate(output_to_remove, 1):\n",
        "    #         if f in zero_stats_df['column_name'].values:\n",
        "    #             zero_pct = zero_stats_df[zero_stats_df['column_name']==f]['zero_percentage'].values[0]\n",
        "    #             print(f\"   {i:2d}. {f:40s} (é›¶å€¼: {zero_pct:.1f}%)\")\n",
        "    #         else:\n",
        "    #             print(f\"   {i:2d}. {f}\")\n",
        "\n",
        "    # if input_to_remove:\n",
        "    #     print(f\"\\nâš ï¸  åˆ é™¤çš„è¾“å…¥ç‰¹å¾ ({len(input_to_remove)}ä¸ª):\")\n",
        "    #     for i, f in enumerate(input_to_remove, 1):\n",
        "    #         if f in zero_stats_df['column_name'].values:\n",
        "    #             zero_pct = zero_stats_df[zero_stats_df['column_name']==f]['zero_percentage'].values[0]\n",
        "    #             print(f\"   {i:2d}. {f:40s} (é›¶å€¼: {zero_pct:.1f}%)\")\n",
        "    #         else:\n",
        "    #             print(f\"   {i:2d}. {f}\")\n",
        "\n",
        "    # æ‰§è¡Œåˆ é™¤\n",
        "    print(f\"\\nâ³ æ­£åœ¨åˆ é™¤ç‰¹å¾...\")\n",
        "    df_clean = df.drop(columns=features_to_remove_valid)\n",
        "\n",
        "    # æ›´æ–°ç‰¹å¾åˆ—è¡¨\n",
        "    input_features_clean = [f for f in input_features if f not in features_to_remove_valid]\n",
        "    output_features_clean = [f for f in output_features if f not in features_to_remove_valid]\n",
        "\n",
        "    # ç»Ÿè®¡æŠ¥å‘Š\n",
        "    print(f\"\\nâœ… åˆ é™¤å®Œæˆï¼\")\n",
        "    print(f\"\\nðŸ“Š æ•°æ®å¯¹æ¯”:\")\n",
        "    print(f\"   {'':20s} {'åˆ é™¤å‰':>10s} {'åˆ é™¤åŽ':>10s} {'å˜åŒ–':>10s}\")\n",
        "    print(f\"   {'-'*50}\")\n",
        "    print(f\"   {'æ€»åˆ—æ•°':20s} {len(df.columns):>10d} {len(df_clean.columns):>10d} {len(df_clean.columns)-len(df.columns):>10d}\")\n",
        "    print(f\"   {'è¾“å…¥ç‰¹å¾':20s} {len(input_features):>10d} {len(input_features_clean):>10d} {len(input_features_clean)-len(input_features):>10d}\")\n",
        "    print(f\"   {'è¾“å‡ºç‰¹å¾':20s} {len(output_features):>10d} {len(output_features_clean):>10d} {len(output_features_clean)-len(output_features):>10d}\")\n",
        "    print(f\"   {'æ ·æœ¬æ•°':20s} {len(df):>10d} {len(df_clean):>10d} {0:>10d}\")\n",
        "\n",
        "    # ä¿å­˜æ¸…æ´—åŽçš„ç‰¹å¾åˆ—è¡¨\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "\n",
        "    # ä¿å­˜ä¸ºJSON\n",
        "    import json\n",
        "\n",
        "    feature_config = {\n",
        "        'timestamp': timestamp,\n",
        "        'original_counts': {\n",
        "            'total_features': len(df.columns),\n",
        "            'input_features': len(input_features),\n",
        "            'output_features': len(output_features),\n",
        "        },\n",
        "        'cleaned_counts': {\n",
        "            'total_features': len(df_clean.columns),\n",
        "            'input_features': len(input_features_clean),\n",
        "            'output_features': len(output_features_clean),\n",
        "        },\n",
        "        'removed_features': {\n",
        "            'input': input_to_remove,\n",
        "            'output': output_to_remove,\n",
        "            'total': features_to_remove_valid,\n",
        "        },\n",
        "        'cleaned_features': {\n",
        "            'input': input_features_clean,\n",
        "            'output': output_features_clean,\n",
        "        }\n",
        "    }\n",
        "\n",
        "    json_path = f'{save_dir}cleaned_features_{timestamp}.json'\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(feature_config, f, indent=2)\n",
        "\n",
        "    print(f\"\\nðŸ’¾ å·²ä¿å­˜ç‰¹å¾é…ç½®: {json_path}\")\n",
        "\n",
        "    # ä¿å­˜ä¸ºTXTï¼ˆæ–¹ä¾¿å¤åˆ¶ï¼‰\n",
        "    txt_path = f'{save_dir}cleaned_features_{timestamp}.txt'\n",
        "    with open(txt_path, 'w') as f:\n",
        "        f.write(f\"=== æ¸…æ´—åŽçš„ç‰¹å¾åˆ—è¡¨ ===\\n\")\n",
        "        f.write(f\"æ—¶é—´: {timestamp}\\n\\n\")\n",
        "\n",
        "        f.write(f\"è¾“å…¥ç‰¹å¾ ({len(input_features_clean)}ä¸ª):\\n\")\n",
        "        for feat in input_features_clean:\n",
        "            f.write(f\"  {feat}\\n\")\n",
        "\n",
        "        f.write(f\"\\nè¾“å‡ºç‰¹å¾ ({len(output_features_clean)}ä¸ª):\\n\")\n",
        "        for feat in output_features_clean:\n",
        "            f.write(f\"  {feat}\\n\")\n",
        "\n",
        "        f.write(f\"\\nåˆ é™¤çš„ç‰¹å¾ ({len(features_to_remove_valid)}ä¸ª):\\n\")\n",
        "        for feat in features_to_remove_valid:\n",
        "            f.write(f\"  {feat}\\n\")\n",
        "\n",
        "    print(f\"ðŸ’¾ å·²ä¿å­˜ç‰¹å¾åˆ—è¡¨: {txt_path}\")\n",
        "\n",
        "    # ç”Ÿæˆåˆ é™¤æŠ¥å‘Š\n",
        "    removal_report = {\n",
        "        'df_original_shape': df.shape,\n",
        "        'df_clean_shape': df_clean.shape,\n",
        "        'features_removed': len(features_to_remove_valid),\n",
        "        'input_removed': len(input_to_remove),\n",
        "        'output_removed': len(output_to_remove),\n",
        "        'input_features_clean': input_features_clean,\n",
        "        'output_features_clean': output_features_clean,\n",
        "    }\n",
        "\n",
        "    return df_clean, input_features_clean, output_features_clean, removal_report\n"
      ],
      "metadata": {
        "id": "svo7Eli9rbkp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuNhbivCd2vF",
        "outputId": "7013299e-c95a-454a-8976-9635ede8d834"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸ“ Cell 2: åº”ç”¨ç‰¹å¾åˆ é™¤\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š åˆ é™¤ç»Ÿè®¡:\n",
            "   æ€»åˆ é™¤: 138 ä¸ªç‰¹å¾\n",
            "   - è¾“å…¥ç‰¹å¾: 0 ä¸ª\n",
            "   - è¾“å‡ºç‰¹å¾: 138 ä¸ª\n",
            "\n",
            "â³ æ­£åœ¨åˆ é™¤ç‰¹å¾...\n",
            "\n",
            "âœ… åˆ é™¤å®Œæˆï¼\n",
            "\n",
            "ðŸ“Š æ•°æ®å¯¹æ¯”:\n",
            "                               åˆ é™¤å‰        åˆ é™¤åŽ         å˜åŒ–\n",
            "   --------------------------------------------------\n",
            "   æ€»åˆ—æ•°                         793        655       -138\n",
            "   è¾“å…¥ç‰¹å¾                        490        490          0\n",
            "   è¾“å‡ºç‰¹å¾                        302        164       -138\n",
            "   æ ·æœ¬æ•°                      625000     625000          0\n",
            "\n",
            "ðŸ’¾ å·²ä¿å­˜ç‰¹å¾é…ç½®: /content/cleaned_features_20251028_030207.json\n",
            "ðŸ’¾ å·²ä¿å­˜ç‰¹å¾åˆ—è¡¨: /content/cleaned_features_20251028_030207.txt\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ‰ ç‰¹å¾æ¸…æ´—å®Œæˆï¼\n",
            "================================================================================\n",
            "\n",
            "ðŸ“¦ æ¸…æ´—åŽçš„æ•°æ®:\n",
            "   å˜é‡å: df_train_clean\n",
            "   å½¢çŠ¶: (625000, 655)\n",
            "   è¾“å…¥ç‰¹å¾: 490 ä¸ª (INPUT_FEATURES_CLEAN)\n",
            "   è¾“å‡ºç‰¹å¾: 164 ä¸ª (OUTPUT_FEATURES_CLEAN)\n",
            "\n",
            "ðŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼\n",
            "\n",
            "ä½¿ç”¨æ–¹æ³•:\n",
            "   model, history = main_training(\n",
            "       df_train_clean,\n",
            "       INPUT_FEATURES_CLEAN,\n",
            "       OUTPUT_FEATURES_CLEAN\n",
            "   )\n",
            "\n",
            "ðŸ” æœ€ç»ˆéªŒè¯:\n",
            "   âœ… æ²¡æœ‰å…¨é›¶è¾“å‡ºç‰¹å¾\n",
            "   âœ… æ‰€æœ‰è¾“å‡ºç‰¹å¾é›¶å€¼<90%\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# è¿è¡ŒCell 2\n",
        "# ============================================================================\n",
        "\n",
        "# ç¡®ä¿INPUT_FEATURESå’ŒOUTPUT_FEATURESå·²å®šä¹‰\n",
        "# INPUT_FEATURES = [col for col in df_train.columns if col not in OUTPUT_FEATURES]\n",
        "\n",
        "# åº”ç”¨åˆ é™¤\n",
        "df_train_clean, INPUT_FEATURES_CLEAN, OUTPUT_FEATURES_CLEAN, report = apply_feature_removal(\n",
        "    train_df,\n",
        "    FEATURES_TO_REMOVE,\n",
        "    INPUT_FEATURES,\n",
        "    OUTPUT_FEATURES,\n",
        "    save_dir='/content/'\n",
        ")\n",
        "\n",
        "# æ˜¾ç¤ºæœ€ç»ˆç»“æžœ\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸŽ‰ ç‰¹å¾æ¸…æ´—å®Œæˆï¼\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nðŸ“¦ æ¸…æ´—åŽçš„æ•°æ®:\")\n",
        "print(f\"   å˜é‡å: df_train_clean\")\n",
        "print(f\"   å½¢çŠ¶: {df_train_clean.shape}\")\n",
        "print(f\"   è¾“å…¥ç‰¹å¾: {len(INPUT_FEATURES_CLEAN)} ä¸ª (INPUT_FEATURES_CLEAN)\")\n",
        "print(f\"   è¾“å‡ºç‰¹å¾: {len(OUTPUT_FEATURES_CLEAN)} ä¸ª (OUTPUT_FEATURES_CLEAN)\")\n",
        "\n",
        "print(f\"\\nðŸš€ å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼\")\n",
        "print(f\"\\nä½¿ç”¨æ–¹æ³•:\")\n",
        "print(f\"   model, history = main_training(\")\n",
        "print(f\"       df_train_clean,\")\n",
        "print(f\"       INPUT_FEATURES_CLEAN,\")\n",
        "print(f\"       OUTPUT_FEATURES_CLEAN\")\n",
        "print(f\"   )\")\n",
        "\n",
        "# å¯é€‰ï¼šéªŒè¯æ²¡æœ‰å…¨é›¶åˆ—\n",
        "print(f\"\\nðŸ” æœ€ç»ˆéªŒè¯:\")\n",
        "all_zero_outputs = []\n",
        "for col in OUTPUT_FEATURES_CLEAN:\n",
        "    if (df_train_clean[col] == 0).all():\n",
        "        all_zero_outputs.append(col)\n",
        "\n",
        "if all_zero_outputs:\n",
        "    print(f\"   âš ï¸  è­¦å‘Šï¼šä»æœ‰ {len(all_zero_outputs)} ä¸ªå…¨é›¶è¾“å‡ºç‰¹å¾ï¼\")\n",
        "    print(f\"   {all_zero_outputs}\")\n",
        "else:\n",
        "    print(f\"   âœ… æ²¡æœ‰å…¨é›¶è¾“å‡ºç‰¹å¾\")\n",
        "\n",
        "# éªŒè¯é›¶å€¼é«˜çš„è¾“å‡ºç‰¹å¾\n",
        "high_zero_outputs = []\n",
        "for col in OUTPUT_FEATURES_CLEAN:\n",
        "    zero_ratio = (df_train_clean[col] == 0).sum() / len(df_train_clean)\n",
        "    if zero_ratio > 0.90:\n",
        "        high_zero_outputs.append((col, zero_ratio))\n",
        "\n",
        "if high_zero_outputs:\n",
        "    print(f\"   âš ï¸  æ³¨æ„ï¼šæœ‰ {len(high_zero_outputs)} ä¸ªè¾“å‡ºç‰¹å¾é›¶å€¼>90%\")\n",
        "    for col, ratio in high_zero_outputs[:5]:\n",
        "        print(f\"      - {col}: {ratio*100:.1f}%\")\n",
        "else:\n",
        "    print(f\"   âœ… æ‰€æœ‰è¾“å‡ºç‰¹å¾é›¶å€¼<90%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GGZgvH79wBL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7y9yU-VbkTD",
        "outputId": "8e837dd5-2b56-43cc-c090-5958964a2be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸš€ Two-Stage Boost Transformer - ç»ˆæžä¿®å¤ç‰ˆ + RÂ²è¯Šæ–­\n",
            "================================================================================\n",
            "PyTorchç‰ˆæœ¬: 2.8.0+cu126\n",
            "CUDAå¯ç”¨: True\n",
            "================================================================================\n",
            "\n",
            "âš™ï¸  é…ç½®: è®¾å¤‡=cuda\n",
            "Stage 1: 50 epochs, lr=0.0001\n",
            "Stage 2: 80 epochs, lr=0.0001\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "âœ… ä»£ç åŠ è½½å®Œæˆï¼\n",
            "================================================================================\n",
            "\n",
            "â­â­â­ æœ¬ç‰ˆæœ¬ç‰¹è‰²ï¼š\n",
            "  âœ“ å®‰å…¨çš„RÂ²è®¡ç®—ï¼ˆé€è¾“å‡ºå¹³å‡ï¼Œé¿å…å¼‚å¸¸å€¼ï¼‰\n",
            "  âœ“ RÂ²è¯Šæ–­å‡½æ•°ï¼ˆæ£€æµ‹æ•°æ®å’Œè®¡ç®—é—®é¢˜ï¼‰\n",
            "  âœ“ evaluateå‡½æ•°åœ¨åŽŸå§‹ç©ºé—´è¯„ä¼°\n",
            "  âœ“ Stage 2æ®‹å·®æ­£ç¡®åæ ‡å‡†åŒ–\n",
            "\n",
            "ðŸ“‹ ä¸»è¦å‡½æ•°:\n",
            "  â€¢ diagnose_r2_computation() - RÂ²è¯Šæ–­\n",
            "  â€¢ compute_r2_safe() - å®‰å…¨RÂ²è®¡ç®—\n",
            "  â€¢ boost_training_pipeline() - å®Œæ•´è®­ç»ƒ\n",
            "  â€¢ boost_inference() - æŽ¨ç†\n",
            "================================================================================\n",
            "\n",
            "ðŸŽ‰ å‡†å¤‡å°±ç»ªï¼RÂ²è®¡ç®—å·²å®Œå…¨ä¿®å¤ï¼\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "Two-Stage Boost Transformer - ç»ˆæžä¿®å¤ç‰ˆ + RÂ²è¯Šæ–­\n",
        "================================================================================\n",
        "â­â­â­ æ–°å¢žå†…å®¹ï¼š\n",
        "1. å¤šè¾“å‡ºRÂ²æ­£ç¡®è®¡ç®—ï¼ˆé€ä¿¡å·è®¡ç®—åŽå¹³å‡ï¼‰\n",
        "2. æ·»åŠ RÂ²è¯Šæ–­å‡½æ•°ï¼Œæ£€æµ‹å¼‚å¸¸æƒ…å†µ\n",
        "3. åœ¨æ‰€æœ‰RÂ²è®¡ç®—å¤„ä½¿ç”¨ä¿®å¤åŽçš„å‡½æ•°\n",
        "\n",
        "é—®é¢˜åˆ†æžï¼š\n",
        "- sklearnçš„r2_scoreå¯¹å¤šè¾“å‡ºé»˜è®¤è¡Œä¸ºå¯èƒ½å¯¼è‡´å¼‚å¸¸\n",
        "- å¦‚æžœæŸäº›è¾“å‡ºæ–¹å·®æžå°ï¼Œä¼šå¯¼è‡´RÂ²å¼‚å¸¸\n",
        "- è§£å†³æ–¹æ¡ˆï¼šé€ä¿¡å·è®¡ç®—RÂ²ï¼Œç„¶åŽå–å¹³å‡æˆ–ä¸­ä½æ•°\n",
        "\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import pickle\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ðŸš€ Two-Stage Boost Transformer - ç»ˆæžä¿®å¤ç‰ˆ + RÂ²è¯Šæ–­\")\n",
        "print(\"=\"*80)\n",
        "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# é…ç½®ç±»\n",
        "# ============================================================================\n",
        "class Config:\n",
        "    \"\"\"å…¨å±€é…ç½®ç±»\"\"\"\n",
        "    TRAIN_TEST_SPLIT = 0.15\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # Stage 1é…ç½®\n",
        "    STAGE1_D_MODEL = 256\n",
        "    STAGE1_NHEAD = 16\n",
        "    STAGE1_NUM_LAYERS = 6\n",
        "    STAGE1_DROPOUT = 0.1\n",
        "    STAGE1_EPOCHS = 50\n",
        "    STAGE1_LR = 0.0001\n",
        "    STAGE1_BATCH_SIZE = 512\n",
        "    STAGE1_WEIGHT_DECAY = 1e-5\n",
        "    STAGE1_SCHEDULER_PATIENCE = 3\n",
        "    STAGE1_SCHEDULER_FACTOR = 0.5\n",
        "    STAGE1_GRAD_CLIP_NORM = 1.0\n",
        "\n",
        "    # Stage 2é…ç½®\n",
        "    # STAGE2_D_MODEL = 128\n",
        "    # STAGE2_NHEAD = 8\n",
        "    # STAGE2_NUM_LAYERS = 4\n",
        "    STAGE2_D_MODEL = 256\n",
        "    STAGE2_NHEAD = 16\n",
        "    STAGE2_NUM_LAYERS = 6\n",
        "    STAGE2_DROPOUT = 0.15\n",
        "    STAGE2_EPOCHS = 80\n",
        "    STAGE2_LR = 0.0001\n",
        "    STAGE2_BATCH_SIZE = 512\n",
        "    STAGE2_WEIGHT_DECAY = 5e-6\n",
        "    STAGE2_SCHEDULER_PATIENCE = 15\n",
        "    STAGE2_SCHEDULER_FACTOR = 0.7\n",
        "    STAGE2_GRAD_CLIP_NORM = 0.5\n",
        "\n",
        "    # Boostingé…ç½®\n",
        "    R2_THRESHOLD = 0.4\n",
        "    USE_SELECTIVE_BOOSTING = True\n",
        "\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    NUM_WORKERS = 0\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(f\"\\nâš™ï¸  é…ç½®: è®¾å¤‡={config.DEVICE}\")\n",
        "print(f\"Stage 1: {config.STAGE1_EPOCHS} epochs, lr={config.STAGE1_LR}\")\n",
        "print(f\"Stage 2: {config.STAGE2_EPOCHS} epochs, lr={config.STAGE2_LR}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# â­â­â­ RÂ²è®¡ç®—ä¿®å¤å‡½æ•° â­â­â­\n",
        "# ============================================================================\n",
        "def compute_r2_safe(y_true, y_pred, method='per_output_mean'):\n",
        "    \"\"\"\n",
        "    å®‰å…¨çš„RÂ²è®¡ç®—å‡½æ•° - é¿å…å¤šè¾“å‡ºæ—¶çš„å¼‚å¸¸å€¼\n",
        "\n",
        "    Args:\n",
        "        y_true: çœŸå®žå€¼ (n_samples, n_outputs)\n",
        "        y_pred: é¢„æµ‹å€¼ (n_samples, n_outputs)\n",
        "        method: è®¡ç®—æ–¹æ³•\n",
        "            - 'per_output_mean': é€è¾“å‡ºè®¡ç®—RÂ²ç„¶åŽå–å¹³å‡ï¼ˆæŽ¨èï¼‰\n",
        "            - 'per_output_median': é€è¾“å‡ºè®¡ç®—RÂ²ç„¶åŽå–ä¸­ä½æ•°\n",
        "            - 'sklearn_default': ä½¿ç”¨sklearné»˜è®¤æ–¹æ³•\n",
        "            - 'global': å…¨å±€RÂ²ï¼ˆå°†æ‰€æœ‰è¾“å‡ºflattenï¼‰\n",
        "\n",
        "    Returns:\n",
        "        r2: RÂ²å€¼\n",
        "        per_output_r2: æ¯ä¸ªè¾“å‡ºçš„RÂ²æ•°ç»„ï¼ˆç”¨äºŽè¯Šæ–­ï¼‰\n",
        "    \"\"\"\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true.reshape(-1, 1)\n",
        "        y_pred = y_pred.reshape(-1, 1)\n",
        "\n",
        "    n_outputs = y_true.shape[1]\n",
        "    per_output_r2 = np.zeros(n_outputs)\n",
        "\n",
        "    # é€è¾“å‡ºè®¡ç®—RÂ²\n",
        "    for i in range(n_outputs):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        # æ£€æŸ¥æ–¹å·®\n",
        "        var_true = np.var(y_t)\n",
        "        if var_true < 1e-10:\n",
        "            print(f\"  âš ï¸  è¾“å‡º {i}: æ–¹å·®è¿‡å° ({var_true:.2e})ï¼ŒRÂ²è®¾ä¸º0\")\n",
        "            per_output_r2[i] = 0.0\n",
        "        else:\n",
        "            try:\n",
        "                per_output_r2[i] = r2_score(y_t, y_p)\n",
        "            except Exception as e:\n",
        "                print(f\"  âš ï¸  è¾“å‡º {i}: RÂ²è®¡ç®—å¤±è´¥ ({e})ï¼Œè®¾ä¸º-1\")\n",
        "                per_output_r2[i] = -1.0\n",
        "\n",
        "    # æ ¹æ®methodæ±‡æ€»\n",
        "    if method == 'per_output_mean':\n",
        "        # è¿‡æ»¤å¼‚å¸¸å€¼åŽå–å¹³å‡\n",
        "        valid_r2 = per_output_r2[np.isfinite(per_output_r2) & (per_output_r2 > -10)]\n",
        "        if len(valid_r2) == 0:\n",
        "            r2 = -1.0\n",
        "        else:\n",
        "            r2 = np.mean(valid_r2)\n",
        "    elif method == 'per_output_median':\n",
        "        valid_r2 = per_output_r2[np.isfinite(per_output_r2) & (per_output_r2 > -10)]\n",
        "        if len(valid_r2) == 0:\n",
        "            r2 = -1.0\n",
        "        else:\n",
        "            r2 = np.median(valid_r2)\n",
        "    elif method == 'sklearn_default':\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "    elif method == 'global':\n",
        "        r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "    return r2, per_output_r2\n",
        "\n",
        "\n",
        "def diagnose_r2_computation(y_true, y_pred, name=\"\"):\n",
        "    \"\"\"\n",
        "    è¯Šæ–­RÂ²è®¡ç®— - æ£€æµ‹å¼‚å¸¸æƒ…å†µ\n",
        "\n",
        "    Args:\n",
        "        y_true: çœŸå®žå€¼\n",
        "        y_pred: é¢„æµ‹å€¼\n",
        "        name: æ•°æ®åç§°\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ðŸ” RÂ²è®¡ç®—è¯Šæ–­ - {name}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nðŸ“Š æ•°æ®ç»Ÿè®¡:\")\n",
        "    print(f\"  å½¢çŠ¶: {y_true.shape}\")\n",
        "    print(f\"  y_trueèŒƒå›´: [{np.min(y_true):.4f}, {np.max(y_true):.4f}]\")\n",
        "    print(f\"  y_predèŒƒå›´: [{np.min(y_pred):.4f}, {np.max(y_pred):.4f}]\")\n",
        "    print(f\"  y_trueå‡å€¼: {np.mean(y_true):.4f}, æ ‡å‡†å·®: {np.std(y_true):.4f}\")\n",
        "    print(f\"  y_predå‡å€¼: {np.mean(y_pred):.4f}, æ ‡å‡†å·®: {np.std(y_pred):.4f}\")\n",
        "\n",
        "    # æ£€æŸ¥æ–¹å·®\n",
        "    per_output_var = np.var(y_true, axis=0)\n",
        "    low_var_outputs = np.where(per_output_var < 1e-6)[0]\n",
        "    if len(low_var_outputs) > 0:\n",
        "        print(f\"\\n  âš ï¸  å‘çŽ°{len(low_var_outputs)}ä¸ªä½Žæ–¹å·®è¾“å‡ºï¼ˆæ–¹å·®<1e-6ï¼‰\")\n",
        "        print(f\"     ç´¢å¼•: {low_var_outputs[:10]}...\")\n",
        "\n",
        "    # è®¡ç®—ä¸åŒæ–¹æ³•çš„RÂ²\n",
        "    print(f\"\\nðŸ“Š ä¸åŒæ–¹æ³•çš„RÂ²:\")\n",
        "    r2_mean, per_r2 = compute_r2_safe(y_true, y_pred, 'per_output_mean')\n",
        "    print(f\"  é€è¾“å‡ºå¹³å‡: {r2_mean:.6f}\")\n",
        "\n",
        "    r2_median, _ = compute_r2_safe(y_true, y_pred, 'per_output_median')\n",
        "    print(f\"  é€è¾“å‡ºä¸­ä½æ•°: {r2_median:.6f}\")\n",
        "\n",
        "    try:\n",
        "        r2_sklearn = r2_score(y_true, y_pred)\n",
        "        print(f\"  sklearné»˜è®¤: {r2_sklearn:.6f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  sklearné»˜è®¤: è®¡ç®—å¤±è´¥ ({e})\")\n",
        "\n",
        "    r2_global, _ = compute_r2_safe(y_true, y_pred, 'global')\n",
        "    print(f\"  å…¨å±€RÂ²: {r2_global:.6f}\")\n",
        "\n",
        "    # æ˜¾ç¤ºå¼‚å¸¸çš„è¾“å‡º\n",
        "    abnormal_r2 = np.where((per_r2 < -10) | (per_r2 > 2))[0]\n",
        "    if len(abnormal_r2) > 0:\n",
        "        print(f\"\\n  ðŸš¨ å‘çŽ°{len(abnormal_r2)}ä¸ªå¼‚å¸¸RÂ²ï¼ˆ<-10æˆ–>2ï¼‰\")\n",
        "        print(f\"     ç´¢å¼•: {abnormal_r2[:10]}...\")\n",
        "        print(f\"     RÂ²å€¼: {per_r2[abnormal_r2[:10]]}\")\n",
        "\n",
        "    # RÂ²åˆ†å¸ƒ\n",
        "    print(f\"\\nðŸ“Š RÂ²åˆ†å¸ƒ:\")\n",
        "    print(f\"  æœ€å°: {np.min(per_r2):.4f}\")\n",
        "    print(f\"  Q1: {np.percentile(per_r2, 25):.4f}\")\n",
        "    print(f\"  ä¸­ä½æ•°: {np.median(per_r2):.4f}\")\n",
        "    print(f\"  Q3: {np.percentile(per_r2, 75):.4f}\")\n",
        "    print(f\"  æœ€å¤§: {np.max(per_r2):.4f}\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return r2_mean, per_r2\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# æ¨¡åž‹å®šä¹‰\n",
        "# ============================================================================\n",
        "class CompactSensorTransformer(nn.Module):\n",
        "    \"\"\"ç´§å‡‘åž‹ä¼ æ„Ÿå™¨Transformer\"\"\"\n",
        "    def __init__(self, num_inputs, num_outputs, d_model=128, nhead=8,\n",
        "                 num_layers=3, dropout=0.1, model_name=\"SST\"):\n",
        "        super().__init__()\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.d_model = d_model\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.input_embedding = nn.Linear(1, d_model)\n",
        "        self.position_encoding = nn.Parameter(torch.randn(num_inputs, d_model))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*2,\n",
        "            dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.output_projection = nn.Linear(d_model, num_outputs)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.input_embedding(x) + self.position_encoding.unsqueeze(0)\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        return self.output_projection(x)\n",
        "\n",
        "# ============================================================================\n",
        "# è®­ç»ƒå‡½æ•° - ä½¿ç”¨ä¿®å¤çš„RÂ²è®¡ç®—\n",
        "# ============================================================================\n",
        "def train_epoch(model, loader, criterion, optimizer, scaler, device, grad_clip_norm):\n",
        "    \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    pbar = tqdm(loader, desc='Training', leave=False)\n",
        "\n",
        "    for X_batch, y_batch in pbar:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with autocast():\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, device, scaler_y=None, use_safe_r2=True):\n",
        "    \"\"\"\n",
        "    è¯„ä¼°æ¨¡åž‹ - â­ ä½¿ç”¨å®‰å…¨çš„RÂ²è®¡ç®— â­\n",
        "\n",
        "    Args:\n",
        "        use_safe_r2: æ˜¯å¦ä½¿ç”¨å®‰å…¨çš„RÂ²è®¡ç®—ï¼ˆæŽ¨èTrueï¼‰\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    y_true_scaled_all, y_pred_scaled_all = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in tqdm(loader, desc='Evaluating', leave=False):\n",
        "            X_batch = X_batch.to(device)\n",
        "\n",
        "            with autocast():\n",
        "                y_pred = model(X_batch).cpu().numpy()\n",
        "\n",
        "            y_true_scaled_all.append(y_batch.numpy())\n",
        "            y_pred_scaled_all.append(y_pred)\n",
        "\n",
        "    y_true_scaled = np.vstack(y_true_scaled_all)\n",
        "    y_pred_scaled = np.vstack(y_pred_scaled_all)\n",
        "\n",
        "    # åæ ‡å‡†åŒ–åˆ°åŽŸå§‹ç©ºé—´\n",
        "    if scaler_y is not None:\n",
        "        y_true = scaler_y.inverse_transform(y_true_scaled)\n",
        "        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "    else:\n",
        "        y_true = y_true_scaled\n",
        "        y_pred = y_pred_scaled\n",
        "\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "    # â­â­â­ ä½¿ç”¨å®‰å…¨çš„RÂ²è®¡ç®— â­â­â­\n",
        "    if use_safe_r2:\n",
        "        r2, _ = compute_r2_safe(y_true, y_pred, method='per_output_mean')\n",
        "    else:\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    return {'mae': mae, 'rmse': rmse, 'r2': r2}, y_true, y_pred\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config_dict, scaler_y=None, stage_name=\"Stage\"):\n",
        "    \"\"\"é€šç”¨è®­ç»ƒæµç¨‹\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ðŸš€ å¼€å§‹è®­ç»ƒ - {stage_name}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    lr = config_dict['lr']\n",
        "    epochs = config_dict['epochs']\n",
        "    weight_decay = config_dict.get('weight_decay', 1e-5)\n",
        "    scheduler_patience = config_dict.get('scheduler_patience', 3)\n",
        "    scheduler_factor = config_dict.get('scheduler_factor', 0.5)\n",
        "    grad_clip_norm = config_dict.get('grad_clip_norm', 1.0)\n",
        "\n",
        "    print(f\"\\nðŸ“‹ è®­ç»ƒé…ç½®:\")\n",
        "    print(f\"  å­¦ä¹ çŽ‡: {lr}, æƒé‡è¡°å‡: {weight_decay}\")\n",
        "    print(f\"  è®­ç»ƒè½®æ•°: {epochs}, æ¢¯åº¦è£å‰ª: {grad_clip_norm}\")\n",
        "    print(f\"  è¯„ä¼°ç©ºé—´: {'åŽŸå§‹ç©ºé—´' if scaler_y is not None else 'æ ‡å‡†åŒ–ç©ºé—´'}\")\n",
        "    print(f\"  RÂ²è®¡ç®—: å®‰å…¨æ¨¡å¼ï¼ˆé€è¾“å‡ºå¹³å‡ï¼‰\")\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=scheduler_patience, factor=scheduler_factor\n",
        "    )\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'val_mae': [], 'val_rmse': [], 'val_r2': [], 'lr': []\n",
        "    }\n",
        "\n",
        "    best_mae = float('inf')\n",
        "    best_r2 = -float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nðŸ“ Epoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler,\n",
        "            config.DEVICE, grad_clip_norm\n",
        "        )\n",
        "\n",
        "        # â­ ä½¿ç”¨å®‰å…¨çš„RÂ²è®¡ç®—\n",
        "        val_metrics, _, _ = evaluate(model, val_loader, config.DEVICE, scaler_y=scaler_y, use_safe_r2=True)\n",
        "\n",
        "        scheduler.step(val_metrics['mae'])\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_mae'].append(val_metrics['mae'])\n",
        "        history['val_rmse'].append(val_metrics['rmse'])\n",
        "        history['val_r2'].append(val_metrics['r2'])\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        print(f\"  è®­ç»ƒæŸå¤±: {train_loss:.6f}\")\n",
        "        print(f\"  éªŒè¯MAE:  {val_metrics['mae']:.6f}\")\n",
        "        print(f\"  éªŒè¯RMSE: {val_metrics['rmse']:.6f}\")\n",
        "        print(f\"  éªŒè¯RÂ²:   {val_metrics['r2']:.6f}\")\n",
        "        print(f\"  å­¦ä¹ çŽ‡:   {current_lr:.8f}\")\n",
        "\n",
        "        if val_metrics['r2'] < -10:\n",
        "            print(f\"  ðŸš¨ è­¦å‘Šï¼šRÂ²å¼‚å¸¸ä½Ž ({val_metrics['r2']:.2f})ï¼\")\n",
        "\n",
        "        if val_metrics['mae'] < best_mae:\n",
        "            best_mae = val_metrics['mae']\n",
        "            best_r2 = val_metrics['r2']\n",
        "            best_epoch = epoch + 1\n",
        "            print(f\"  âœ… æœ€ä½³æ¨¡åž‹å·²æ›´æ–°ï¼\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"âœ… {stage_name} è®­ç»ƒå®Œæˆï¼\")\n",
        "    print(f\"   æœ€ä½³éªŒè¯MAE: {best_mae:.6f} | RÂ²: {best_r2:.6f} (Epoch {best_epoch})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return model, history, best_mae, best_r2\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# æ•°æ®å‡†å¤‡\n",
        "# ============================================================================\n",
        "def prepare_data(X, y, batch_size, standardize_y=True):\n",
        "    \"\"\"å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯æ•°æ®\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    print(f\"\\nâœ… æ•°æ®å½¢çŠ¶: X={X.shape}, y={y.shape}\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=config.TRAIN_TEST_SPLIT, random_state=config.RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… æ•°æ®åˆ’åˆ†: è®­ç»ƒ{X_train.shape[0]:,}, éªŒè¯{X_val.shape[0]:,}\")\n",
        "\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler() if standardize_y else None\n",
        "\n",
        "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "    X_val_scaled = scaler_X.transform(X_val)\n",
        "\n",
        "    if standardize_y:\n",
        "        y_train_scaled = scaler_y.fit_transform(y_train)\n",
        "        y_val_scaled = scaler_y.transform(y_val)\n",
        "        print(f\"  âœ“ yæ ‡å‡†åŒ–å®Œæˆ\")\n",
        "    else:\n",
        "        y_train_scaled = y_train\n",
        "        y_val_scaled = y_val\n",
        "        print(\"  âš ï¸  è·³è¿‡yæ ‡å‡†åŒ–ï¼ˆæ®‹å·®æ¨¡å¼ï¼‰\")\n",
        "\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.FloatTensor(X_train_scaled),\n",
        "        torch.FloatTensor(y_train_scaled)\n",
        "    )\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.FloatTensor(X_val_scaled),\n",
        "        torch.FloatTensor(y_val_scaled)\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=config.NUM_WORKERS, pin_memory=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=config.NUM_WORKERS, pin_memory=True\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader, scaler_X, scaler_y, X_train, X_val, y_train, y_val\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# è¾…åŠ©å‡½æ•°\n",
        "# ============================================================================\n",
        "def create_stage_config(stage=1):\n",
        "    \"\"\"åˆ›å»ºStageé…ç½®å­—å…¸\"\"\"\n",
        "    if stage == 1:\n",
        "        return {\n",
        "            'epochs': config.STAGE1_EPOCHS,\n",
        "            'lr': config.STAGE1_LR,\n",
        "            'weight_decay': config.STAGE1_WEIGHT_DECAY,\n",
        "            'scheduler_patience': config.STAGE1_SCHEDULER_PATIENCE,\n",
        "            'scheduler_factor': config.STAGE1_SCHEDULER_FACTOR,\n",
        "            'grad_clip_norm': config.STAGE1_GRAD_CLIP_NORM\n",
        "        }\n",
        "    elif stage == 2:\n",
        "        return {\n",
        "            'epochs': config.STAGE2_EPOCHS,\n",
        "            'lr': config.STAGE2_LR,\n",
        "            'weight_decay': config.STAGE2_WEIGHT_DECAY,\n",
        "            'scheduler_patience': config.STAGE2_SCHEDULER_PATIENCE,\n",
        "            'scheduler_factor': config.STAGE2_SCHEDULER_FACTOR,\n",
        "            'grad_clip_norm': config.STAGE2_GRAD_CLIP_NORM\n",
        "        }\n",
        "    else:\n",
        "        raise ValueError(f\"stage must be 1 or 2, got {stage}\")\n",
        "\n",
        "\n",
        "def print_training_config_comparison():\n",
        "    \"\"\"æ‰“å°é…ç½®å¯¹æ¯”\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š Stage 1 vs Stage 2 é…ç½®å¯¹æ¯”\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    stage1 = create_stage_config(1)\n",
        "    stage2 = create_stage_config(2)\n",
        "\n",
        "    print(f\"\\n{'å‚æ•°':<25} {'Stage 1':<20} {'Stage 2':<20}\")\n",
        "    print(\"-\" * 80)\n",
        "    for key in stage1.keys():\n",
        "        print(f\"{key:<25} {stage1[key]:<20} {stage2[key]:<20}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# å¯è§†åŒ–ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
        "# ============================================================================\n",
        "def plot_training_history(history_stage1, history_stage2):\n",
        "    \"\"\"ç»˜åˆ¶è®­ç»ƒåŽ†å²\"\"\"\n",
        "    metrics = ['train_loss', 'val_mae', 'val_r2']\n",
        "    titles = ['Training Loss', 'Validation MAE', 'Validation RÂ²']\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
        "        ax = axes[idx]\n",
        "\n",
        "        if metric in history_stage1:\n",
        "            ax.plot(history_stage1[metric], label='Stage 1', linewidth=2)\n",
        "\n",
        "        if metric in history_stage2:\n",
        "            stage2_x = np.arange(len(history_stage1[metric]),\n",
        "                                len(history_stage1[metric]) + len(history_stage2[metric]))\n",
        "            ax.plot(stage2_x, history_stage2[metric], label='Stage 2', linewidth=2, color='orange')\n",
        "\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel(title)\n",
        "        ax.set_title(title)\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"\\nðŸ“Š è®­ç»ƒåŽ†å²å·²ä¿å­˜: training_history.png\")\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Boostè®­ç»ƒæµç¨‹ - ä½¿ç”¨ä¿®å¤çš„RÂ²è®¡ç®—\n",
        "# ============================================================================\n",
        "def boost_training_pipeline(X, y, input_features, output_features, enable_r2_diagnosis=True):\n",
        "    \"\"\"\n",
        "    Two-Stage Boostingå®Œæ•´è®­ç»ƒæµç¨‹\n",
        "\n",
        "    Args:\n",
        "        enable_r2_diagnosis: æ˜¯å¦å¯ç”¨RÂ²è¯Šæ–­ï¼ˆé»˜è®¤Trueï¼‰\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ—ï¸  Two-Stage Boosting Training Pipeline\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Stage 1\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š STAGE 1: Base Model Training\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    train_loader_s1, val_loader_s1, scaler_X_s1, scaler_y_s1, X_train_s1, X_val_s1, y_train_s1, y_val_s1 = \\\n",
        "        prepare_data(X, y, config.STAGE1_BATCH_SIZE, standardize_y=True)\n",
        "\n",
        "    base_model = CompactSensorTransformer(\n",
        "        num_inputs=X.shape[1],\n",
        "        num_outputs=y.shape[1],\n",
        "        d_model=config.STAGE1_D_MODEL,\n",
        "        nhead=config.STAGE1_NHEAD,\n",
        "        num_layers=config.STAGE1_NUM_LAYERS,\n",
        "        dropout=config.STAGE1_DROPOUT,\n",
        "        model_name=\"Stage1_Base\"\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    print(f\"\\nðŸ“Š Base Model: {sum(p.numel() for p in base_model.parameters()):,} å‚æ•°\")\n",
        "\n",
        "    stage1_config = create_stage_config(stage=1)\n",
        "\n",
        "    base_model, history_s1, best_mae_s1, best_r2_s1 = train_model(\n",
        "        base_model, train_loader_s1, val_loader_s1, stage1_config,\n",
        "        scaler_y=scaler_y_s1,\n",
        "        stage_name=\"Stage 1: Base Model\"\n",
        "    )\n",
        "\n",
        "    torch.save(base_model.state_dict(), 'boost_stage1_best.pth')\n",
        "    with open('stage1_scalers.pkl', 'wb') as f:\n",
        "        pickle.dump({'scaler_X': scaler_X_s1, 'scaler_y': scaler_y_s1}, f)\n",
        "    print(f\"\\nðŸ’¾ Stage 1æ¨¡åž‹å’Œscalerså·²ä¿å­˜\")\n",
        "\n",
        "    # è®¡ç®—æ®‹å·®\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š è®¡ç®—Stage 1æ®‹å·®\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    base_model.eval()\n",
        "\n",
        "    X_train_s1_scaled = scaler_X_s1.transform(X_train_s1)\n",
        "    X_train_s1_tensor = torch.FloatTensor(X_train_s1_scaled).to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_train_s1_pred_scaled = base_model(X_train_s1_tensor).cpu().numpy()\n",
        "\n",
        "    y_train_s1_pred = scaler_y_s1.inverse_transform(y_train_s1_pred_scaled)\n",
        "    residual_after_stage1 = y_train_s1 - y_train_s1_pred\n",
        "\n",
        "    print(f\"âœ… æ®‹å·®ç»Ÿè®¡:\")\n",
        "    print(f\"  å‡å€¼: {np.mean(residual_after_stage1):.6f}\")\n",
        "    print(f\"  æ ‡å‡†å·®: {np.std(residual_after_stage1):.6f}\")\n",
        "\n",
        "    # Stage 2\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š STAGE 2: Residual Model Training\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    train_loader_s2, val_loader_s2, scaler_X_s2, scaler_residual, _, _, _, _ = \\\n",
        "        prepare_data(\n",
        "            X[:len(X_train_s1)],\n",
        "            residual_after_stage1,\n",
        "            config.STAGE2_BATCH_SIZE,\n",
        "            standardize_y=True\n",
        "        )\n",
        "\n",
        "    residual_model = CompactSensorTransformer(\n",
        "        num_inputs=X.shape[1],\n",
        "        num_outputs=y.shape[1],\n",
        "        d_model=config.STAGE2_D_MODEL,\n",
        "        nhead=config.STAGE2_NHEAD,\n",
        "        num_layers=config.STAGE2_NUM_LAYERS,\n",
        "        dropout=config.STAGE2_DROPOUT,\n",
        "        model_name=\"Stage2_Residual\"\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    print(f\"\\nðŸ“Š Residual Model: {sum(p.numel() for p in residual_model.parameters()):,} å‚æ•°\")\n",
        "\n",
        "    stage2_config = create_stage_config(stage=2)\n",
        "\n",
        "    residual_model, history_s2, best_mae_s2, best_r2_s2 = train_model(\n",
        "        residual_model, train_loader_s2, val_loader_s2, stage2_config,\n",
        "        scaler_y=scaler_residual,\n",
        "        stage_name=\"Stage 2: Residual Model\"\n",
        "    )\n",
        "\n",
        "    torch.save(residual_model.state_dict(), 'boost_stage2_best.pth')\n",
        "    with open('stage2_scalers.pkl', 'wb') as f:\n",
        "        pickle.dump({'scaler_X': scaler_X_s2, 'scaler_residual': scaler_residual}, f)\n",
        "    print(f\"\\nðŸ’¾ Stage 2æ¨¡åž‹å’Œscalerså·²ä¿å­˜\")\n",
        "\n",
        "    # éªŒè¯è¯„ä¼°\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š éªŒè¯é›†è¯„ä¼°\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    base_model.eval()\n",
        "    residual_model.eval()\n",
        "\n",
        "    X_val_s1_scaled = scaler_X_s1.transform(X_val_s1)\n",
        "    X_val_s1_tensor = torch.FloatTensor(X_val_s1_scaled).to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_val_s1_pred_scaled = base_model(X_val_s1_tensor).cpu().numpy()\n",
        "\n",
        "    y_val_s1_pred = scaler_y_s1.inverse_transform(y_val_s1_pred_scaled)\n",
        "\n",
        "    # â­ RÂ²è¯Šæ–­\n",
        "    if enable_r2_diagnosis:\n",
        "        stage1_r2, signal_r2_scores = diagnose_r2_computation(y_val_s1, y_val_s1_pred, \"Stage 1éªŒè¯é›†\")\n",
        "    else:\n",
        "        stage1_r2, signal_r2_scores = compute_r2_safe(y_val_s1, y_val_s1_pred)\n",
        "\n",
        "    X_val_s2_scaled = scaler_X_s2.transform(X_val_s1)\n",
        "    X_val_s2_tensor = torch.FloatTensor(X_val_s2_scaled).to(config.DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        residual_val_pred_scaled = residual_model(X_val_s2_tensor).cpu().numpy()\n",
        "\n",
        "    residual_val_pred = scaler_residual.inverse_transform(residual_val_pred_scaled)\n",
        "\n",
        "    y_val_boosted_all = y_val_s1_pred + residual_val_pred\n",
        "\n",
        "    if config.USE_SELECTIVE_BOOSTING:\n",
        "        weak_signals_mask = signal_r2_scores < config.R2_THRESHOLD\n",
        "        num_weak = np.sum(weak_signals_mask)\n",
        "        print(f\"\\nâ­ é€‰æ‹©æ€§Boosting: {num_weak}/{len(signal_r2_scores)} ä¿¡å·éœ€è¦Boosting\")\n",
        "\n",
        "        y_val_selective_boosted = y_val_s1_pred.copy()\n",
        "        y_val_selective_boosted[:, weak_signals_mask] = y_val_boosted_all[:, weak_signals_mask]\n",
        "    else:\n",
        "        y_val_selective_boosted = y_val_boosted_all\n",
        "        weak_signals_mask = np.ones(len(signal_r2_scores), dtype=bool)\n",
        "\n",
        "    # æœ€ç»ˆè¯„ä¼°\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š æœ€ç»ˆè¯„ä¼°\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    stage1_mae = mean_absolute_error(y_val_s1, y_val_s1_pred)\n",
        "\n",
        "    selective_boosted_mae = mean_absolute_error(y_val_s1, y_val_selective_boosted)\n",
        "    selective_boosted_r2, _ = compute_r2_safe(y_val_s1, y_val_selective_boosted)\n",
        "\n",
        "    improvement = (stage1_mae - selective_boosted_mae) / stage1_mae * 100\n",
        "\n",
        "    print(f\"\\n{'æŒ‡æ ‡':<20} {'Stage 1':<18} {'Selective Boost':<18}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'MAE':<20} {stage1_mae:<18.6f} {selective_boosted_mae:<18.6f}\")\n",
        "    print(f\"{'RÂ²':<20} {stage1_r2:<18.6f} {selective_boosted_r2:<18.6f}\")\n",
        "    print(f\"{'MAEæ”¹è¿›':<20} {'Baseline':<18} {improvement:>+16.2f}%\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    if improvement > 0:\n",
        "        print(f\"\\nâœ… Boostingæœ‰æ•ˆï¼MAEæ”¹è¿› {improvement:.2f}%\")\n",
        "\n",
        "    plot_training_history(history_s1, history_s2)\n",
        "\n",
        "    scalers = {\n",
        "        'stage1_scaler_X': scaler_X_s1,\n",
        "        'stage1_scaler_y': scaler_y_s1,\n",
        "        'stage2_scaler_X': scaler_X_s2,\n",
        "        'stage2_scaler_residual': scaler_residual\n",
        "    }\n",
        "\n",
        "    history = {'stage1': history_s1, 'stage2': history_s2}\n",
        "\n",
        "    results = {\n",
        "        'stage1_mae': stage1_mae,\n",
        "        'stage1_r2': stage1_r2,\n",
        "        'selective_boosted_mae': selective_boosted_mae,\n",
        "        'selective_boosted_r2': selective_boosted_r2,\n",
        "        'improvement_selective': improvement,\n",
        "        'signal_r2_scores': signal_r2_scores,\n",
        "        'weak_signals_mask': weak_signals_mask\n",
        "    }\n",
        "\n",
        "    with open('boost_results.pkl', 'wb') as f:\n",
        "        pickle.dump({'scalers': scalers, 'history': history, 'results': results}, f)\n",
        "    print(f\"\\nðŸ’¾ ç»“æžœå·²ä¿å­˜: boost_results.pkl\")\n",
        "\n",
        "    return base_model, residual_model, scalers, history, results, None\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# BoostæŽ¨ç† - ä½¿ç”¨ä¿®å¤çš„RÂ²\n",
        "# ============================================================================\n",
        "def boost_inference(X_new, base_model, residual_model, scalers,\n",
        "                   signal_r2_scores=None, r2_threshold=None, device=None):\n",
        "    \"\"\"BoostæŽ¨ç†\"\"\"\n",
        "    if device is None:\n",
        "        device = config.DEVICE\n",
        "\n",
        "    if r2_threshold is None:\n",
        "        r2_threshold = config.R2_THRESHOLD\n",
        "\n",
        "    base_model.eval()\n",
        "    residual_model.eval()\n",
        "\n",
        "    scaler_X_s1 = scalers['stage1_scaler_X']\n",
        "    scaler_y_s1 = scalers['stage1_scaler_y']\n",
        "\n",
        "    X_scaled_s1 = scaler_X_s1.transform(X_new)\n",
        "    X_tensor_s1 = torch.FloatTensor(X_scaled_s1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with autocast():\n",
        "            y_pred_s1_scaled = base_model(X_tensor_s1).cpu().numpy()\n",
        "\n",
        "    y_pred_s1 = scaler_y_s1.inverse_transform(y_pred_s1_scaled)\n",
        "\n",
        "    scaler_X_s2 = scalers['stage2_scaler_X']\n",
        "    scaler_residual = scalers['stage2_scaler_residual']\n",
        "\n",
        "    X_scaled_s2 = scaler_X_s2.transform(X_new)\n",
        "    X_tensor_s2 = torch.FloatTensor(X_scaled_s2).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with autocast():\n",
        "            residual_pred_scaled = residual_model(X_tensor_s2).cpu().numpy()\n",
        "\n",
        "    residual_pred = scaler_residual.inverse_transform(residual_pred_scaled)\n",
        "\n",
        "    y_pred_full = y_pred_s1 + residual_pred\n",
        "\n",
        "    if config.USE_SELECTIVE_BOOSTING and signal_r2_scores is not None:\n",
        "        mask = signal_r2_scores < r2_threshold\n",
        "        y_pred = y_pred_s1.copy()\n",
        "        y_pred[:, mask] = y_pred_full[:, mask]\n",
        "    else:\n",
        "        y_pred = y_pred_full\n",
        "        mask = np.ones(y_pred_s1.shape[1], dtype=bool)\n",
        "\n",
        "    return y_pred, mask\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ä½¿ç”¨æç¤º\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… ä»£ç åŠ è½½å®Œæˆï¼\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nâ­â­â­ æœ¬ç‰ˆæœ¬ç‰¹è‰²ï¼š\")\n",
        "print(\"  âœ“ å®‰å…¨çš„RÂ²è®¡ç®—ï¼ˆé€è¾“å‡ºå¹³å‡ï¼Œé¿å…å¼‚å¸¸å€¼ï¼‰\")\n",
        "print(\"  âœ“ RÂ²è¯Šæ–­å‡½æ•°ï¼ˆæ£€æµ‹æ•°æ®å’Œè®¡ç®—é—®é¢˜ï¼‰\")\n",
        "print(\"  âœ“ evaluateå‡½æ•°åœ¨åŽŸå§‹ç©ºé—´è¯„ä¼°\")\n",
        "print(\"  âœ“ Stage 2æ®‹å·®æ­£ç¡®åæ ‡å‡†åŒ–\")\n",
        "print(\"\\nðŸ“‹ ä¸»è¦å‡½æ•°:\")\n",
        "print(\"  â€¢ diagnose_r2_computation() - RÂ²è¯Šæ–­\")\n",
        "print(\"  â€¢ compute_r2_safe() - å®‰å…¨RÂ²è®¡ç®—\")\n",
        "print(\"  â€¢ boost_training_pipeline() - å®Œæ•´è®­ç»ƒ\")\n",
        "print(\"  â€¢ boost_inference() - æŽ¨ç†\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nðŸŽ‰ å‡†å¤‡å°±ç»ªï¼RÂ²è®¡ç®—å·²å®Œå…¨ä¿®å¤ï¼\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942,
          "referenced_widgets": [
            "692ad2ccfdfd414290db8155a4f21580",
            "e782761cb5d64552812c86140d314d1a",
            "1186f261d691415180e4fdcf01dddbb9",
            "124b304b6f384e2e935856b63bdf98b5",
            "4093e971c482470e9857abc71684a1a9",
            "2a0120c24d3640df8d0de137ca608157",
            "959e370fde414001b619cf20e97a7ad5",
            "4b841efe18f54619acb915686d5e5b05",
            "ff2087ca53164542861abedcbae21687",
            "15c2ff3dc38d4b0d92c6853189b2f0a3",
            "0c256bf755d249f680c73d624bd994af"
          ]
        },
        "id": "M8PNpA3e6PzQ",
        "outputId": "d01990b6-5565-4a04-b302-b9d4dc5cb345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸ—ï¸  Two-Stage Boosting Training Pipeline\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š STAGE 1: Base Model Training\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š å‡†å¤‡è®­ç»ƒæ•°æ®\n",
            "================================================================================\n",
            "\n",
            "âœ… æ•°æ®å½¢çŠ¶: X=(312500, 490), y=(312500, 164)\n",
            "âœ… æ•°æ®åˆ’åˆ†: è®­ç»ƒ265,625, éªŒè¯46,875\n",
            "  âœ“ yæ ‡å‡†åŒ–å®Œæˆ\n",
            "\n",
            "ðŸ“Š Base Model: 3,330,724 å‚æ•°\n",
            "\n",
            "================================================================================\n",
            "ðŸš€ å¼€å§‹è®­ç»ƒ - Stage 1: Base Model\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‹ è®­ç»ƒé…ç½®:\n",
            "  å­¦ä¹ çŽ‡: 0.0001, æƒé‡è¡°å‡: 1e-05\n",
            "  è®­ç»ƒè½®æ•°: 50, æ¢¯åº¦è£å‰ª: 1.0\n",
            "  è¯„ä¼°ç©ºé—´: åŽŸå§‹ç©ºé—´\n",
            "  RÂ²è®¡ç®—: å®‰å…¨æ¨¡å¼ï¼ˆé€è¾“å‡ºå¹³å‡ï¼‰\n",
            "\n",
            "ðŸ“ Epoch 1/50\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/519 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "692ad2ccfdfd414290db8155a4f21580"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2710405760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_FEATURES_CLEAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mboost_training_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-225813038.py\u001b[0m in \u001b[0;36mboost_training_pipeline\u001b[0;34m(X, y, input_features, output_features, enable_r2_diagnosis)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mstage1_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_stage_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     base_model, history_s1, best_mae_s1, best_r2_s1 = train_model(\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage1_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mscaler_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaler_y_s1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-225813038.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, config_dict, scaler_y, stage_name)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         train_loss = train_epoch(\n\u001b[0m\u001b[1;32m    376\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-225813038.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, criterion, optimizer, scaler, device, grad_clip_norm)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_clip_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X = df_train_clean[INPUT_FEATURES_CLEAN].values\n",
        "y = df_train_clean[OUTPUT_FEATURES_CLEAN].values\n",
        "input_features = INPUT_FEATURES_CLEAN\n",
        "output_features = OUTPUT_FEATURES_CLEAN\n",
        "base_model, residual_model, scalers, history, results, _ = \\\n",
        "    boost_training_pipeline(X, y, input_features, output_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "557a03be3c184baea6c8e5007c04a77d",
            "bf107bccd5484d8d8880d3c1355b431a",
            "b0c021863bbc4d34b2859b80357238b3",
            "2c74ccd047814aa4a753813636ea2a39",
            "6cd24b2857394d0486d70bbf2cfdf41a",
            "837cb76581274086aedca5f187d1e9ab",
            "b3d9b9c494164e72884b21c34e2f7456",
            "34295e3b28834fd09b37d4b803bc1c79",
            "35d5b0567b3f4a9abb7e6057e2ca94ef",
            "773054585dc449b38fb4e5790cc87a2d",
            "b92a150c4b7643ee85b57f80d177e775",
            "5519a38cafff4e228866d57456c56c5b",
            "dd82bac6f90e4dc7b50c59337bd7efc0",
            "ba247ef920cc4262bd4dbba2d75fff96",
            "fdc948d7ee1b463ca0a6320884121188",
            "46b798e7f63745eaa371e13a45a10c64",
            "3de8ae244c0f42569763a284c8965790",
            "03207e57101e4b389baad8b84e0e4d57",
            "f5ef9ef8390548bbbc0a2bee9b958847",
            "ecd0541d181041b7b0f45c8092ec8232",
            "44b5360bab7a48f68cd6c002b3ce858c",
            "ee77291a4f354f6e8af2cd4f5a115f65"
          ]
        },
        "id": "_Qy-6VLz5Y9s",
        "outputId": "7b07e6f7-5d3b-4c8e-e5e8-2aaa04d7c022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸš€ Stage 2 è®­ç»ƒ (åŸºäºŽå·²ä¿å­˜çš„Stage 1)\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“¥ åŠ è½½å·²ä¿å­˜çš„Base Modelå’ŒScalers\n",
            "================================================================================\n",
            "âœ… Stage 1 Model State DictåŠ è½½æˆåŠŸ\n",
            "âœ… Stage 1 ScalersåŠ è½½æˆåŠŸ\n",
            "   æœ€ä½³MAE (from scalers): inf\n",
            "   æœ€ä½³RÂ² (from scalers): -inf\n",
            "âœ… Base Modelå·²é‡å»ºå¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
            "\n",
            "================================================================================\n",
            "ðŸ“¥ åŠ è½½åŽŸå§‹è®­ç»ƒæ•°æ®\n",
            "================================================================================\n",
            "âœ… æ•°æ®åŠ è½½æˆåŠŸ (from environment):\n",
            "   è¾“å…¥å½¢çŠ¶: (312500, 490)\n",
            "   è¾“å‡ºå½¢çŠ¶: (312500, 164)\n",
            "âœ… åŽŸå§‹æ•°æ®åˆ’åˆ†: è®­ç»ƒé›† 265,625, éªŒè¯é›† 46,875\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š è®¡ç®—Stage 1æ®‹å·®\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ”§ è®¡ç®—Stage 2æ®‹å·®ï¼ˆæ­£ç¡®æ–¹æ³•ï¼‰\n",
            "================================================================================\n",
            "\n",
            "æ­¥éª¤1: æ ‡å‡†åŒ–è¾“å…¥\n",
            "\n",
            "æ­¥éª¤2: Baseæ¨¡åž‹é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–ç©ºé—´ï¼‰\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting Base Model Residuals:   0%|          | 0/260 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "557a03be3c184baea6c8e5007c04a77d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  é¢„æµ‹å½¢çŠ¶: (265625, 164)\n",
            "  é¢„æµ‹èŒƒå›´: [-32.593750, 25.265625]\n",
            "\n",
            "æ­¥éª¤3: åæ ‡å‡†åŒ–åˆ°åŽŸå§‹ç©ºé—´\n",
            "  åæ ‡å‡†åŒ–åŽèŒƒå›´: [-30.921875, 28.000000]\n",
            "  çœŸå®žå€¼èŒƒå›´: [-122.974739, 132.202042]\n",
            "\n",
            "æ­¥éª¤4: è®¡ç®—æ®‹å·®ï¼ˆåŽŸå§‹ç©ºé—´ï¼‰\n",
            "  æ®‹å·®å½¢çŠ¶: (265625, 164)\n",
            "  æ®‹å·®èŒƒå›´: [-122.390755, 133.116104]\n",
            "  æ®‹å·®å‡å€¼: -0.004257 (åº”æŽ¥è¿‘0)\n",
            "  æ®‹å·®æ ‡å‡†å·®: 0.744185\n",
            "\n",
            "éªŒè¯:\n",
            "  æ®‹å·®æ ‡å‡†å·®/ç›®æ ‡æ ‡å‡†å·® = 0.7351\n",
            "  âœ“ Base model performed moderately.\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š STEP 4: å‡†å¤‡Stage 2è®­ç»ƒæ•°æ®\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ”§ è®¡ç®—Stage 2æ®‹å·®ï¼ˆæ­£ç¡®æ–¹æ³•ï¼‰\n",
            "================================================================================\n",
            "\n",
            "æ­¥éª¤1: æ ‡å‡†åŒ–è¾“å…¥\n",
            "\n",
            "æ­¥éª¤2: Baseæ¨¡åž‹é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–ç©ºé—´ï¼‰\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting Base Model Residuals:   0%|          | 0/46 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5519a38cafff4e228866d57456c56c5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-315417915.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;31m# Need to calculate residuals_val first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m residuals_val = compute_residuals_correctly(\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0mX_val_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_X_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler_y_s1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m )\n",
            "\u001b[0;32m/tmp/ipython-input-315417915.py\u001b[0m in \u001b[0;36mcompute_residuals_correctly\u001b[0;34m(X_orig, y_orig, base_model, scaler_X, scaler_y, device)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# Ensure model forward pass uses autocast if needed and is compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Assuming autocast is available and needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                  \u001b[0my_pred_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0my_pred_scaled_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0my_pred_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_scaled_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "ä»Žå·²ä¿å­˜çš„Base Modelç»§ç»­å®ŒæˆStage 2è®­ç»ƒ\n",
        "å‰æï¼šboost_stage1_best.pth å’Œ stage1_scalers.pkl å·²å­˜åœ¨\n",
        "\"\"\"\n",
        "\n",
        "# Ensure necessary functions and Config are defined (assuming they are in W7y9yU-VbkTD)\n",
        "# from W7y9yU-VbkTD import CompactSensorTransformer, train_model, prepare_data, compute_residuals_correctly, create_stage_config, config, diagnose_r2_computation, compute_r2_safe, plot_training_history\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸš€ Stage 2 è®­ç»ƒ (åŸºäºŽå·²ä¿å­˜çš„Stage 1)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 1: åŠ è½½Base Modelå’ŒScalers\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“¥ åŠ è½½å·²ä¿å­˜çš„Base Modelå’ŒScalers\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load Stage 1 model state dict\n",
        "try:\n",
        "    base_model_state_dict = torch.load('/content/boost_stage1_best.pth', map_location=config.DEVICE)\n",
        "    print(\"âœ… Stage 1 Model State DictåŠ è½½æˆåŠŸ\")\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ é”™è¯¯: /content/boost_stage1_best.pth æ–‡ä»¶æœªæ‰¾åˆ°ï¼\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"âŒ é”™è¯¯: åŠ è½½ /content/boost_stage1_best.pth æ—¶å‘ç”Ÿå¼‚å¸¸: {e}\")\n",
        "    raise\n",
        "\n",
        "\n",
        "# Load Stage 1 Scalers and metrics\n",
        "try:\n",
        "    with open('/content/stage1_scalers.pkl', 'rb') as f:\n",
        "        scalers_s1_info = pickle.load(f)\n",
        "    scaler_X_s1 = scalers_s1_info['scaler_X']\n",
        "    scaler_y_s1 = scalers_s1_info['scaler_y']\n",
        "    # Assume num_inputs and num_outputs were saved with scalers or can be inferred\n",
        "    # If not saved, you might need to load training_info.pkl or infer from data\n",
        "    num_inputs = X.shape[1] # Infer from data if not in scaler file\n",
        "    num_outputs = y.shape[1] # Infer from data if not in scaler file\n",
        "\n",
        "    # Try loading best_mae and best_r2 if they were saved with scalers\n",
        "    best_mae_s1 = scalers_s1_info.get('best_mae', float('inf'))\n",
        "    best_r2_s1 = scalers_s1_info.get('best_r2', -float('inf'))\n",
        "\n",
        "    print(\"âœ… Stage 1 ScalersåŠ è½½æˆåŠŸ\")\n",
        "    print(f\"   æœ€ä½³MAE (from scalers): {best_mae_s1:.6f}\")\n",
        "    print(f\"   æœ€ä½³RÂ² (from scalers): {best_r2_s1:.6f}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ é”™è¯¯: /content/stage1_scalers.pkl æ–‡ä»¶æœªæ‰¾åˆ°ï¼\")\n",
        "    raise\n",
        "except Exception as e:\n",
        "    print(f\"âŒ é”™è¯¯: åŠ è½½ /content/stage1_scalers.pkl æ—¶å‘ç”Ÿå¼‚å¸¸: {e}\")\n",
        "    raise\n",
        "\n",
        "# Reconstruct Base Model\n",
        "# Ensure CompactSensorTransformer class is defined (e.g., in cell W7y9yU-VbkTD)\n",
        "base_model = CompactSensorTransformer(\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    d_model=config.STAGE1_D_MODEL,\n",
        "    nhead=config.STAGE1_NHEAD,\n",
        "    num_layers=config.STAGE1_NUM_LAYERS,\n",
        "    dropout=config.STAGE1_DROPOUT,\n",
        "    model_name=\"BaseModel\"\n",
        ").to(config.DEVICE)\n",
        "\n",
        "base_model.load_state_dict(base_model_state_dict)\n",
        "base_model.eval()\n",
        "\n",
        "print(\"âœ… Base Modelå·²é‡å»ºå¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 2: å‡†å¤‡åŽŸå§‹æ•°æ®ï¼ˆä»Žcell5åŠ è½½ï¼‰\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“¥ åŠ è½½åŽŸå§‹è®­ç»ƒæ•°æ®\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# â­ ä»Žcell5ä¸­åŠ è½½åŽŸå§‹æ•°æ® (Assuming these variables are available in the environment)\n",
        "try:\n",
        "    # Check if df_train_clean, INPUT_FEATURES_CLEAN, OUTPUT_FEATURES_CLEAN are defined\n",
        "    _ = df_train_clean\n",
        "    _ = INPUT_FEATURES_CLEAN\n",
        "    _ = OUTPUT_FEATURES_CLEAN\n",
        "\n",
        "    X = df_train_clean[INPUT_FEATURES_CLEAN].values\n",
        "    y = df_train_clean[OUTPUT_FEATURES_CLEAN].values\n",
        "\n",
        "\n",
        "    print(f\"âœ… æ•°æ®åŠ è½½æˆåŠŸ (from environment):\")\n",
        "    print(f\"   è¾“å…¥å½¢çŠ¶: {X.shape}\")\n",
        "    print(f\"   è¾“å‡ºå½¢çŠ¶: {y.shape}\")\n",
        "\n",
        "except NameError:\n",
        "    print(\"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°åŽŸå§‹æ•°æ®å˜é‡ (df_train_clean, INPUT_FEATURES_CLEAN, OUTPUT_FEATURES_CLEAN)\")\n",
        "    print(\"   è¯·ç¡®ä¿cell5å·²è¿è¡Œå¹¶å®šä¹‰äº†è¿™äº›å˜é‡ã€‚\")\n",
        "    raise\n",
        "\n",
        "# Split data into train and validation sets using the same seed as Stage 1\n",
        "# This split will be used to calculate residuals on the training portion\n",
        "# and evaluate Stage 2 on the validation portion.\n",
        "X_train_orig, X_val_orig, y_train_orig, y_val_orig = train_test_split(\n",
        "    X, y, test_size=config.TRAIN_TEST_SPLIT, random_state=config.RANDOM_SEED\n",
        ")\n",
        "print(f\"âœ… åŽŸå§‹æ•°æ®åˆ’åˆ†: è®­ç»ƒé›† {X_train_orig.shape[0]:,}, éªŒè¯é›† {X_val_orig.shape[0]:,}\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 3: è®¡ç®—Stage 1æ®‹å·®\n",
        "# ============================================================================\n",
        "\n",
        "# Ensure compute_residuals_correctly is defined (e.g., in cell W7y9yU-VbkTD)\n",
        "# If not defined, manually implement the logic here:\n",
        "def compute_residuals_correctly(X_orig, y_orig, base_model, scaler_X, scaler_y, device):\n",
        "    \"\"\"\n",
        "    Correctly compute residuals in original scale.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ”§ è®¡ç®—Stage 2æ®‹å·®ï¼ˆæ­£ç¡®æ–¹æ³•ï¼‰\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    base_model.eval()\n",
        "\n",
        "    print(f\"\\næ­¥éª¤1: æ ‡å‡†åŒ–è¾“å…¥\")\n",
        "    X_scaled = scaler_X.transform(X_orig)\n",
        "\n",
        "    print(f\"\\næ­¥éª¤2: Baseæ¨¡åž‹é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–ç©ºé—´ï¼‰\")\n",
        "    with torch.no_grad():\n",
        "        X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
        "        # â­ Batch processing to avoid OOM\n",
        "        batch_size = 1024 # Can adjust this batch size\n",
        "        y_pred_scaled_list = []\n",
        "        for i in tqdm(range(0, len(X_tensor), batch_size), desc=\"Predicting Base Model Residuals\"):\n",
        "            batch = X_tensor[i:i+batch_size]\n",
        "            # Ensure model forward pass uses autocast if needed and is compatible\n",
        "            with autocast(): # Assuming autocast is available and needed\n",
        "                 y_pred_batch = base_model(batch).cpu().numpy()\n",
        "            y_pred_scaled_list.append(y_pred_batch)\n",
        "        y_pred_scaled = np.vstack(y_pred_scaled_list)\n",
        "\n",
        "\n",
        "    print(f\"  é¢„æµ‹å½¢çŠ¶: {y_pred_scaled.shape}\")\n",
        "    print(f\"  é¢„æµ‹èŒƒå›´: [{np.min(y_pred_scaled):.6f}, {np.max(y_pred_scaled):.6f}]\")\n",
        "\n",
        "    print(f\"\\næ­¥éª¤3: åæ ‡å‡†åŒ–åˆ°åŽŸå§‹ç©ºé—´\")\n",
        "    y_pred_original = scaler_y.inverse_transform(y_pred_scaled)\n",
        "    print(f\"  åæ ‡å‡†åŒ–åŽèŒƒå›´: [{np.min(y_pred_original):.6f}, {np.max(y_pred_original):.6f}]\")\n",
        "    print(f\"  çœŸå®žå€¼èŒƒå›´: [{np.min(y_orig):.6f}, {np.max(y_orig):.6f}]\")\n",
        "\n",
        "\n",
        "    print(f\"\\næ­¥éª¤4: è®¡ç®—æ®‹å·®ï¼ˆåŽŸå§‹ç©ºé—´ï¼‰\")\n",
        "    residuals = y_orig - y_pred_original\n",
        "    print(f\"  æ®‹å·®å½¢çŠ¶: {residuals.shape}\")\n",
        "    print(f\"  æ®‹å·®èŒƒå›´: [{np.min(residuals):.6f}, {np.max(residuals):.6f}]\")\n",
        "    print(f\"  æ®‹å·®å‡å€¼: {np.mean(residuals):.6f} (åº”æŽ¥è¿‘0)\")\n",
        "    print(f\"  æ®‹å·®æ ‡å‡†å·®: {np.std(residuals):.6f}\")\n",
        "\n",
        "    # Verification\n",
        "    residual_ratio = np.std(residuals) / np.std(y_orig)\n",
        "    print(f\"\\néªŒè¯:\")\n",
        "    print(f\"  æ®‹å·®æ ‡å‡†å·®/ç›®æ ‡æ ‡å‡†å·® = {residual_ratio:.4f}\")\n",
        "    if residual_ratio < 0.3:\n",
        "        print(f\"  âœ… Base model performed well, residuals are small.\")\n",
        "    elif residual_ratio > 0.8:\n",
        "         print(f\"  âš ï¸  Base model performed poorly, residuals are large.\")\n",
        "    else:\n",
        "        print(f\"  âœ“ Base model performed moderately.\")\n",
        "\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return residuals\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š è®¡ç®—Stage 1æ®‹å·®\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Compute residuals on the training data subset\n",
        "residuals_train = compute_residuals_correctly(\n",
        "    X_train_orig, y_train_orig, base_model, scaler_X_s1, scaler_y_s1, config.DEVICE\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 4: å‡†å¤‡Stage 2è®­ç»ƒæ•°æ®\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š STEP 4: å‡†å¤‡Stage 2è®­ç»ƒæ•°æ®\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Stage 2 input is the same as Stage 1 input (standardized by a new scaler)\n",
        "# Stage 2 target is the residual from Stage 1 (not standardized initially, but will be by Stage 2 scaler)\n",
        "\n",
        "# Prepare data for Stage 2 training (X_train_orig -> residuals_train)\n",
        "# We need a new scaler for X for Stage 2, even if it's the same original data\n",
        "# We also need a scaler for the residuals\n",
        "scaler_X_s2 = StandardScaler()\n",
        "scaler_residual = StandardScaler()\n",
        "\n",
        "# Standardize X_train_orig and residuals_train for Stage 2 training\n",
        "X_train_s2_scaled = scaler_X_s2.fit_transform(X_train_orig)\n",
        "residual_train_scaled = scaler_residual.fit_transform(residuals_train)\n",
        "\n",
        "\n",
        "# Standardize X_val_orig and residuals_val for Stage 2 validation\n",
        "# Need to calculate residuals_val first\n",
        "base_model.eval()\n",
        "residuals_val = compute_residuals_correctly(\n",
        "    X_val_orig, y_val_orig, base_model, scaler_X_s1, scaler_y_s1, config.DEVICE\n",
        ")\n",
        "\n",
        "X_val_s2_scaled = scaler_X_s2.transform(X_val_orig)\n",
        "residual_val_scaled = scaler_residual.transform(residuals_val)\n",
        "\n",
        "\n",
        "print(f\"âœ… Stage 2è®­ç»ƒæ•°æ®å½¢çŠ¶: X={X_train_s2_scaled.shape}, Residual={residual_train_scaled.shape}\")\n",
        "print(f\"âœ… Stage 2éªŒè¯æ•°æ®å½¢çŠ¶: X={X_val_s2_scaled.shape}, Residual={residual_val_scaled.shape}\")\n",
        "\n",
        "# Create Stage 2 DataLoaders\n",
        "train_dataset_s2 = TensorDataset(\n",
        "    torch.FloatTensor(X_train_s2_scaled),\n",
        "    torch.FloatTensor(residual_train_scaled)\n",
        ")\n",
        "val_dataset_s2 = TensorDataset(\n",
        "    torch.FloatTensor(X_val_s2_scaled),\n",
        "    torch.FloatTensor(residual_val_scaled)\n",
        ")\n",
        "\n",
        "train_loader_s2 = DataLoader(\n",
        "    train_dataset_s2,\n",
        "    batch_size=config.STAGE2_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader_s2 = DataLoader(\n",
        "    val_dataset_s2,\n",
        "    batch_size=config.STAGE2_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=config.NUM_WORKERS,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"âœ… Stage 2 DataLoadersåˆ›å»ºå®Œæˆ\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 5: åˆå§‹åŒ–å¹¶è®­ç»ƒStage 2 Residual Model\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸš€ STEP 5: è®­ç»ƒStage 2 Residual Model\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Initialize Stage 2 model\n",
        "# Ensure CompactSensorTransformer class is defined (e.g., in cell W7y9yU-VbkTD)\n",
        "residual_model = CompactSensorTransformer(\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    d_model=config.STAGE2_D_MODEL,\n",
        "    nhead=config.STAGE2_NHEAD,\n",
        "    num_layers=config.STAGE2_NUM_LAYERS,\n",
        "    dropout=config.STAGE2_DROPOUT,\n",
        "    model_name=\"Stage2_Residual\"\n",
        ").to(config.DEVICE)\n",
        "\n",
        "print(f\"\\nðŸ“Š Residual Model: {sum(p.numel() for p in residual_model.parameters()):,} å‚æ•°\")\n",
        "\n",
        "# Train Stage 2 model\n",
        "stage2_config = create_stage_config(stage=2) # Ensure create_stage_config is defined\n",
        "\n",
        "# Ensure train_model function is defined (e.g., in cell W7y9yU-VbkTD)\n",
        "# If not defined, manually implement the training loop using the evaluate function with scaler_y=scaler_residual\n",
        "def train_model(model, train_loader, val_loader, config_dict, scaler_y=None, stage_name=\"Stage\"):\n",
        "    \"\"\"é€šç”¨è®­ç»ƒæµç¨‹ - Using corrected evaluate and train_epoch\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"ðŸš€ å¼€å§‹è®­ç»ƒ - {stage_name}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    lr = config_dict['lr']\n",
        "    epochs = config_dict['epochs']\n",
        "    weight_decay = config_dict.get('weight_decay', 1e-5)\n",
        "    scheduler_patience = config_dict.get('scheduler_patience', 3)\n",
        "    scheduler_factor = config_dict.get('scheduler_factor', 0.5)\n",
        "    grad_clip_norm = config_dict.get('grad_clip_norm', 1.0)\n",
        "\n",
        "    print(f\"\\nðŸ“‹ è®­ç»ƒé…ç½®:\")\n",
        "    print(f\"  å­¦ä¹ çŽ‡: {lr}, æƒé‡è¡°å‡: {weight_decay}\")\n",
        "    print(f\"  è®­ç»ƒè½®æ•°: {epochs}, æ¢¯åº¦è£å‰ª: {grad_clip_norm}\")\n",
        "    print(f\"  è¯„ä¼°ç©ºé—´: {'åŽŸå§‹ç©ºé—´' if scaler_y is not None else 'æ ‡å‡†åŒ–ç©ºé—´'}\")\n",
        "    print(f\"  RÂ²è®¡ç®—: å®‰å…¨æ¨¡å¼ï¼ˆé€è¾“å‡ºå¹³å‡ï¼‰\")\n",
        "\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', patience=scheduler_patience, factor=scheduler_factor\n",
        "    )\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'val_mae': [], 'val_rmse': [], 'val_r2': [], 'lr': []\n",
        "    }\n",
        "\n",
        "    best_mae = float('inf')\n",
        "    best_r2 = -float('inf')\n",
        "    best_epoch = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nðŸ“ Epoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        # Ensure train_epoch is defined and accepts scaler and grad_clip_norm\n",
        "        # train_epoch(model, loader, criterion, optimizer, scaler, device, grad_clip_norm)\n",
        "        def train_epoch(model, loader, criterion, optimizer, scaler, device, grad_clip_norm):\n",
        "            \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            pbar = tqdm(loader, desc='Training', leave=False)\n",
        "\n",
        "            for X_batch, y_batch in pbar:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with autocast():\n",
        "                    y_pred = model(X_batch)\n",
        "                    loss = criterion(y_pred, y_batch)\n",
        "\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "            return total_loss / len(loader)\n",
        "\n",
        "\n",
        "        train_loss = train_epoch(\n",
        "            model, train_loader, criterion, optimizer, scaler,\n",
        "            config.DEVICE, grad_clip_norm\n",
        "        )\n",
        "\n",
        "        # Ensure evaluate function is defined and accepts scaler_y and use_safe_r2\n",
        "        # evaluate(model, loader, device, scaler_y=None, use_safe_r2=True)\n",
        "        def evaluate(model, loader, device, scaler_y=None, use_safe_r2=True):\n",
        "            \"\"\"\n",
        "            è¯„ä¼°æ¨¡åž‹ - â­ ä½¿ç”¨å®‰å…¨çš„RÂ²è®¡ç®— â­\n",
        "            \"\"\"\n",
        "            model.eval()\n",
        "            y_true_scaled_all, y_pred_scaled_all = [], []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for X_batch, y_batch in tqdm(loader, desc='Evaluating', leave=False):\n",
        "                    X_batch = X_batch.to(device)\n",
        "\n",
        "                    with autocast():\n",
        "                        y_pred = model(X_batch).cpu().numpy()\n",
        "\n",
        "                    y_true_scaled_all.append(y_batch.numpy())\n",
        "                    y_pred_scaled_all.append(y_pred)\n",
        "\n",
        "            y_true_scaled = np.vstack(y_true_scaled_all)\n",
        "            y_pred_scaled = np.vstack(y_pred_scaled_all)\n",
        "\n",
        "            # Inverse transform to original scale\n",
        "            if scaler_y is not None:\n",
        "                y_true = scaler_y.inverse_transform(y_true_scaled)\n",
        "                y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "            else:\n",
        "                y_true = y_true_scaled\n",
        "                y_pred = y_pred_scaled\n",
        "\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "            # â­â­â­ Use safe RÂ² calculation â­â­â­\n",
        "            if use_safe_r2:\n",
        "                r2, _ = compute_r2_safe(y_true, y_pred, method='per_output_mean') # Ensure compute_r2_safe is defined\n",
        "            else:\n",
        "                r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "            return {'mae': mae, 'rmse': rmse, 'r2': r2}, y_true, y_pred\n",
        "\n",
        "        val_metrics, _, _ = evaluate(model, val_loader, config.DEVICE, scaler_y=scaler_y, use_safe_r2=True)\n",
        "\n",
        "\n",
        "        scheduler.step(val_metrics['mae'])\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_mae'].append(val_metrics['mae'])\n",
        "        history['val_rmse'].append(val_metrics['rmse'])\n",
        "        history['val_r2'].append(val_metrics['r2'])\n",
        "        history['lr'].append(current_lr)\n",
        "\n",
        "        print(f\"  è®­ç»ƒæŸå¤±: {train_loss:.6f}\")\n",
        "        print(f\"  éªŒè¯MAE:  {val_metrics['mae']:.6f}\")\n",
        "        print(f\"  éªŒè¯RMSE: {val_metrics['rmse']:.6f}\")\n",
        "        print(f\"  éªŒè¯RÂ²:   {val_metrics['r2']:.6f}\")\n",
        "        print(f\"  å­¦ä¹ çŽ‡:   {current_lr:.8f}\")\n",
        "\n",
        "        if val_metrics['r2'] < -10:\n",
        "            print(f\"  ðŸš¨ è­¦å‘Šï¼šRÂ²å¼‚å¸¸ä½Ž ({val_metrics['r2']:.2f})ï¼\")\n",
        "\n",
        "        if val_metrics['mae'] < best_mae:\n",
        "            best_mae = val_metrics['mae']\n",
        "            best_r2 = val_metrics['r2']\n",
        "            best_epoch = epoch + 1\n",
        "            print(f\"  âœ… æœ€ä½³æ¨¡åž‹å·²æ›´æ–°ï¼\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"âœ… {stage_name} è®­ç»ƒå®Œæˆï¼\")\n",
        "    print(f\"   æœ€ä½³éªŒè¯MAE: {best_mae:.6f} | RÂ²: {best_r2:.6f} (Epoch {best_epoch})\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    return model, history, best_mae, best_r2\n",
        "\n",
        "\n",
        "residual_model, history_s2, best_mae_s2, best_r2_s2 = train_model(\n",
        "    residual_model, train_loader_s2, val_loader_s2, stage2_config,\n",
        "    scaler_y=scaler_residual, # â­ Pass residual scaler for evaluation\n",
        "    stage_name=\"Stage 2: Residual Model\"\n",
        ")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 6: ä¿å­˜Stage 2 Model and Scalers\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ’¾ STEP 6: ä¿å­˜Stage 2 Model and Scalers\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "torch.save(residual_model.state_dict(), '/content/boost_stage2_best.pth')\n",
        "with open('/content/stage2_scalers.pkl', 'wb') as f:\n",
        "    pickle.dump({'scaler_X': scaler_X_s2, 'scaler_residual': scaler_residual,\n",
        "                 'best_mae_s2': best_mae_s2, 'best_r2_s2': best_r2_s2}, f)\n",
        "\n",
        "print(f\"\\nðŸ’¾ Stage 2æ¨¡åž‹å’Œscalerså·²ä¿å­˜\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 7: æœ€ç»ˆè¯„ä¼° - é€‰æ‹©æ€§Boosting\n",
        "# ============================================================================\n",
        "\n",
        "# Re-load Base Model for final evaluation (ensure it's on the correct device)\n",
        "# Ensure CompactSensorTransformer is defined\n",
        "base_model_eval = CompactSensorTransformer(\n",
        "    num_inputs=num_inputs,\n",
        "    num_outputs=num_outputs,\n",
        "    d_model=config.STAGE1_D_MODEL,\n",
        "    nhead=config.STAGE1_NHEAD,\n",
        "    num_layers=config.STAGE1_NUM_LAYERS,\n",
        "    dropout=config.STAGE1_DROPOUT\n",
        ").to(config.DEVICE)\n",
        "base_model_eval.load_state_dict(base_model_state_dict)\n",
        "base_model_eval.eval()\n",
        "\n",
        "residual_model.eval() # Residual model is already trained in this cell\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ“Š STEP 7: æœ€ç»ˆè¯„ä¼°ï¼ˆé€‰æ‹©æ€§Boostingï¼‰\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Prepare validation data for final evaluation (using Stage 1 scalers)\n",
        "X_val_s1_scaled_eval = scaler_X_s1.transform(X_val_orig)\n",
        "y_val_true_eval = y_val_orig # Use original true values for final evaluation\n",
        "\n",
        "\n",
        "# Predict using Stage 1 and Stage 2 models on validation set\n",
        "# Use batch processing for inference\n",
        "batch_size_inference = 1024 # Adjust as needed\n",
        "num_val_samples = len(X_val_s1_scaled_eval)\n",
        "num_val_batches = (num_val_samples + batch_size_inference - 1) // batch_size_inference\n",
        "\n",
        "y_val_s1_pred_list = []\n",
        "residual_val_pred_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(num_val_batches), desc=\"Final Evaluation Inference\"):\n",
        "        start_idx = i * batch_size_inference\n",
        "        end_idx = min((i + 1) * batch_size_inference, num_val_samples)\n",
        "\n",
        "        X_batch_s1 = torch.FloatTensor(X_val_s1_scaled_eval[start_idx:end_idx]).to(config.DEVICE)\n",
        "        X_batch_s2 = torch.FloatTensor(scaler_X_s2.transform(X_val_orig[start_idx:end_idx])).to(config.DEVICE) # Scale X again for Stage 2 model\n",
        "\n",
        "        with autocast():\n",
        "            y_pred_s1_scaled = base_model_eval(X_batch_s1).cpu().numpy()\n",
        "            residual_pred_scaled = residual_model(X_batch_s2).cpu().numpy()\n",
        "\n",
        "        y_val_s1_pred_list.append(scaler_y_s1.inverse_transform(y_pred_s1_scaled))\n",
        "        residual_val_pred_list.append(scaler_residual.inverse_transform(residual_pred_scaled))\n",
        "\n",
        "y_val_s1_pred = np.vstack(y_val_s1_pred_list)\n",
        "residual_val_pred = np.vstack(residual_val_pred_list)\n",
        "\n",
        "y_val_boosted_all = y_val_s1_pred + residual_val_pred\n",
        "\n",
        "# Calculate RÂ² for each signal from Stage 1 on validation set\n",
        "# Ensure compute_r2_safe is defined\n",
        "_, signal_r2_scores_val = compute_r2_safe(y_val_true_eval, y_val_s1_pred, method='per_output_mean')\n",
        "\n",
        "\n",
        "if config.USE_SELECTIVE_BOOSTING:\n",
        "    weak_signals_mask_val = signal_r2_scores_val < config.R2_THRESHOLD\n",
        "    num_weak_val = np.sum(weak_signals_mask_val)\n",
        "    print(f\"\\nâ­ é€‰æ‹©æ€§Boosting (Validation Set, RÂ²é˜ˆå€¼ = {config.R2_THRESHOLD}):\")\n",
        "    print(f\"  éœ€è¦Boostingçš„ä¿¡å·: {num_weak_val}/{len(signal_r2_scores_val)} ({num_weak_val/len(signal_r2_scores_val)*100:.1f}%)\")\n",
        "\n",
        "    y_val_selective_boosted = y_val_s1_pred.copy()\n",
        "    y_val_selective_boosted[:, weak_signals_mask_val] = y_val_boosted_all[:, weak_signals_mask_val]\n",
        "else:\n",
        "    y_val_selective_boosted = y_val_boosted_all\n",
        "    weak_signals_mask_val = np.ones(len(signal_r2_scores_val), dtype=bool)\n",
        "\n",
        "\n",
        "# Final Metrics\n",
        "stage1_mae_final = mean_absolute_error(y_val_true_eval, y_val_s1_pred)\n",
        "stage1_r2_final, _ = compute_r2_safe(y_val_true_eval, y_val_s1_pred, method='per_output_mean')\n",
        "\n",
        "selective_boosted_mae_final = mean_absolute_error(y_val_true_eval, y_val_selective_boosted)\n",
        "selective_boosted_r2_final, _ = compute_r2_safe(y_val_true_eval, y_val_selective_boosted, method='per_output_mean')\n",
        "\n",
        "full_boosted_mae_final = mean_absolute_error(y_val_true_eval, y_val_boosted_all)\n",
        "full_boosted_r2_final, _ = compute_r2_safe(y_val_true_eval, y_val_boosted_all, method='per_output_mean')\n",
        "\n",
        "\n",
        "improvement_selective_final = (stage1_mae_final - selective_boosted_mae_final) / stage1_mae_final * 100\n",
        "improvement_full_final = (stage1_mae_final - full_boosted_mae_final) / stage1_mae_final * 100\n",
        "\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"{'æŒ‡æ ‡':<25} {'Stage 1':<18} {'Full Boosting':<18} {'Selective':<18}\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"{'MAE':<25} {stage1_mae_final:<18.6f} {full_boosted_mae_final:<18.6f} {selective_boosted_mae_final:<18.6f}\")\n",
        "print(f\"{'RÂ² Score':<25} {stage1_r2_final:<18.6f} {full_boosted_r2_final:<18.6f} {selective_boosted_r2_final:<18.6f}\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"{'MAEæå‡':<25} {'Baseline':<18} {improvement_full_final:>+16.2f}% {improvement_selective_final:>+16.2f}%\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "if improvement_selective_final > 0:\n",
        "    print(f\"\\nâœ… Boostingæœ‰æ•ˆï¼é€‰æ‹©æ€§ç­–ç•¥MAEæ”¹è¿› {improvement_selective_final:.2f}%\")\n",
        "\n",
        "# Plot training history (requires history_s1 from Stage 1 training)\n",
        "# If history_s1 is not available, you might need to load it from training_info.pkl\n",
        "# For now, assuming history_s1 is not available after kernel restart, skip plotting or load it\n",
        "# plot_training_history(history_s1 if 'history_s1' in locals() else {'val_mae': [], 'val_r2': [], 'train_loss': []}, history_s2)\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# STEP 8: Save Final Results and Info\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ðŸ’¾ STEP 8: ä¿å­˜æœ€ç»ˆç»“æžœ\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load previous training info if it exists, and update it\n",
        "training_info_path = '/content/boost_training_info.pkl'\n",
        "try:\n",
        "    with open(training_info_path, 'rb') as f:\n",
        "        training_info = pickle.load(f)\n",
        "    print(\"âœ… å·²åŠ è½½çŽ°æœ‰è®­ç»ƒä¿¡æ¯\")\n",
        "except FileNotFoundError:\n",
        "    training_info = {}\n",
        "    print(\"âš ï¸ æœªæ‰¾åˆ°çŽ°æœ‰è®­ç»ƒä¿¡æ¯ï¼Œåˆ›å»ºæ–°ä¿¡æ¯\")\n",
        "\n",
        "# Update results\n",
        "training_info['results'] = {\n",
        "    'stage1_mae': stage1_mae_final,\n",
        "    'stage1_r2': stage1_r2_final,\n",
        "    'full_boosted_mae': full_boosted_mae_final,\n",
        "    'full_boosted_r2': full_boosted_r2_final,\n",
        "    'selective_boosted_mae': selective_boosted_mae_final,\n",
        "    'selective_boosted_r2': selective_boosted_r2_final,\n",
        "    'improvement_full': improvement_full_final,\n",
        "    'improvement_selective': improvement_selective_final,\n",
        "    'signal_r2_scores': signal_r2_scores_val, # Use validation set R2 for boosting decision\n",
        "    'weak_signals_mask': weak_signals_mask_val,\n",
        "    'num_weak_signals': np.sum(weak_signals_mask_val),\n",
        "    'num_total_signals': num_outputs\n",
        "}\n",
        "\n",
        "# Update scalers\n",
        "training_info['scalers'] = {\n",
        "    'stage1_scaler_X': scaler_X_s1,\n",
        "    'stage1_scaler_y': scaler_y_s1,\n",
        "    'stage2_scaler_X': scaler_X_s2,\n",
        "    'stage2_scaler_residual': scaler_residual\n",
        "}\n",
        "\n",
        "# Update history (if history_s1 was loaded or generated)\n",
        "if 'history_s1' in locals():\n",
        "     training_info['history'] = {'stage1': history_s1, 'stage2': history_s2}\n",
        "elif 'history' in training_info and 'stage1' in training_info['history']:\n",
        "     training_info['history']['stage2'] = history_s2\n",
        "else:\n",
        "    training_info['history'] = {'stage2': history_s2}\n",
        "    print(\"âš ï¸ Stage 1 history not available for combined plot.\")\n",
        "\n",
        "\n",
        "# Save updated info\n",
        "with open(training_info_path, 'wb') as f:\n",
        "    pickle.dump(training_info, f)\n",
        "print(f\"âœ… å®Œæ•´è®­ç»ƒä¿¡æ¯å·²ä¿å­˜/æ›´æ–°: {training_info_path}\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ… Stage 2è®­ç»ƒå’Œè¯„ä¼°å®Œæˆï¼\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nðŸ“ ç”Ÿæˆ/æ›´æ–°çš„æ–‡ä»¶:\")\n",
        "print(\"   1. /content/boost_stage2_best.pth - Stage 2æœ€ä½³Checkpoint â­\")\n",
        "print(\"   2. /content/stage2_scalers.pkl - Stage 2 Scalers â­\")\n",
        "print(\"   3. /content/boost_training_info.pkl - å®Œæ•´è®­ç»ƒé…ç½®å’Œç»“æžœ â­\")\n",
        "\n",
        "print(\"\\nâ­ æ€§èƒ½æ€»ç»“ (Validation Set):\")\n",
        "print(f\"   Stage 1 MAE: {stage1_mae_final:.6f} | RÂ²: {stage1_r2_final:.6f}\")\n",
        "print(f\"   Selective Boosting MAE: {selective_boosted_mae_final:.6f} | RÂ²: {selective_boosted_r2_final:.6f}\")\n",
        "print(f\"   MAEæ”¹è¿›: {improvement_selective_final:+.2f}%\")\n",
        "print(f\"   å¼±ä¿¡å·æ•°é‡ (RÂ² < {config.R2_THRESHOLD}): {np.sum(weak_signals_mask_val)}/{num_outputs}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "Inference & Evaluation - å†…å­˜ä¼˜åŒ–ç‰ˆ (Memory Optimized)\n",
        "================================================================================\n",
        "ä¼˜åŒ–å†…å®¹ï¼š\n",
        "1. âœ… æ‰¹å¤„ç†æŽ¨ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰æ•°æ®åˆ°GPU\n",
        "2. âœ… åŠæ—¶é‡Šæ”¾GPUå†…å­˜\n",
        "3. âœ… åœ¨è®¡ç®—RÂ²æ—¶ä¹Ÿä½¿ç”¨æ‰¹å¤„ç†\n",
        "4. âœ… è‡ªåŠ¨æ ¹æ®GPUå†…å­˜è°ƒæ•´batch size\n",
        "\n",
        "é€‚ç”¨åœºæ™¯ï¼š\n",
        "- GPUå†…å­˜ä¸è¶³ï¼ˆCUDA OOMé”™è¯¯ï¼‰\n",
        "- å¤§è§„æ¨¡æµ‹è¯•é›†æŽ¨ç†\n",
        "- å¤šä¸ªæ¨¡åž‹åŒæ—¶å ç”¨GPU\n",
        "\n",
        "é»˜è®¤batch_size: 512ï¼ˆå¯ä»¥æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼‰\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from torch.cuda.amp import autocast\n",
        "import pickle\n",
        "import warnings\n",
        "import os\n",
        "from datetime import datetime\n",
        "import gc\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# âœ… è®¾ç½®çŽ¯å¢ƒå˜é‡é¿å…å†…å­˜ç¢Žç‰‡\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ðŸ“Š Inference & Evaluation - å†…å­˜ä¼˜åŒ–ç‰ˆ\")\n",
        "print(\"=\"*80)\n",
        "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
        "print(f\"CUDAå¯ç”¨: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# é…ç½®ç±»\n",
        "# ============================================================================\n",
        "class Config:\n",
        "    \"\"\"å…¨å±€é…ç½®ç±»\"\"\"\n",
        "    TRAIN_TEST_SPLIT = 0.15\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # Boostingé…ç½®\n",
        "    R2_THRESHOLD = 0.5\n",
        "    USE_SELECTIVE_BOOSTING = True\n",
        "\n",
        "    # âœ… å†…å­˜ä¼˜åŒ–é…ç½®\n",
        "    INFERENCE_BATCH_SIZE = 512  # æŽ¨ç†æ‰¹æ¬¡å¤§å°ï¼Œå¯ä»¥æ ¹æ®GPUå†…å­˜è°ƒæ•´ï¼ˆ256/512/1024ï¼‰\n",
        "\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(f\"\\nâš™ï¸  é…ç½®: è®¾å¤‡={config.DEVICE}\")\n",
        "print(f\"RÂ²é˜ˆå€¼: {config.R2_THRESHOLD}\")\n",
        "print(f\"æŽ¨ç†æ‰¹æ¬¡å¤§å°: {config.INFERENCE_BATCH_SIZE}\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# GPUå†…å­˜ç®¡ç†å‡½æ•°\n",
        "# ============================================================================\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"æ¸…ç†GPUå†…å­˜\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "def print_gpu_memory():\n",
        "    \"\"\"æ‰“å°GPUå†…å­˜ä½¿ç”¨æƒ…å†µ\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "        print(f\"  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… {allocated:.2f} GB | å·²ä¿ç•™ {reserved:.2f} GB\")\n",
        "\n",
        "# ============================================================================\n",
        "# RÂ²è®¡ç®—å‡½æ•°\n",
        "# ============================================================================\n",
        "def compute_r2_safe(y_true, y_pred, method='per_output_mean'):\n",
        "    \"\"\"å®‰å…¨çš„RÂ²è®¡ç®—å‡½æ•°\"\"\"\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true.reshape(-1, 1)\n",
        "        y_pred = y_pred.reshape(-1, 1)\n",
        "\n",
        "    n_outputs = y_true.shape[1]\n",
        "    per_output_r2 = np.zeros(n_outputs)\n",
        "\n",
        "    for i in range(n_outputs):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        var_true = np.var(y_t)\n",
        "        if var_true < 1e-10:\n",
        "            per_output_r2[i] = 0.0\n",
        "        else:\n",
        "            try:\n",
        "                per_output_r2[i] = r2_score(y_t, y_p)\n",
        "            except Exception as e:\n",
        "                per_output_r2[i] = -1.0\n",
        "\n",
        "    if method == 'per_output_mean':\n",
        "        valid_r2 = per_output_r2[np.isfinite(per_output_r2) & (per_output_r2 > -10)]\n",
        "        r2 = np.mean(valid_r2) if len(valid_r2) > 0 else -1.0\n",
        "    elif method == 'per_output_median':\n",
        "        valid_r2 = per_output_r2[np.isfinite(per_output_r2) & (per_output_r2 > -10)]\n",
        "        r2 = np.median(valid_r2) if len(valid_r2) > 0 else -1.0\n",
        "    elif method == 'sklearn_default':\n",
        "        r2 = r2_score(y_true, y_pred)\n",
        "    elif method == 'global':\n",
        "        r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown method: {method}\")\n",
        "\n",
        "    return r2, per_output_r2\n",
        "\n",
        "\n",
        "def compute_per_signal_metrics(y_true, y_pred):\n",
        "    \"\"\"è®¡ç®—æ¯ä¸ªä¿¡å·çš„è¯¦ç»†æŒ‡æ ‡\"\"\"\n",
        "    n_signals = y_true.shape[1]\n",
        "\n",
        "    metrics = {\n",
        "        'mae': np.zeros(n_signals),\n",
        "        'rmse': np.zeros(n_signals),\n",
        "        'r2': np.zeros(n_signals),\n",
        "        'mape': np.zeros(n_signals),\n",
        "        'true_mean': np.zeros(n_signals),\n",
        "        'true_std': np.zeros(n_signals),\n",
        "        'pred_mean': np.zeros(n_signals),\n",
        "        'pred_std': np.zeros(n_signals)\n",
        "    }\n",
        "\n",
        "    for i in range(n_signals):\n",
        "        y_t = y_true[:, i]\n",
        "        y_p = y_pred[:, i]\n",
        "\n",
        "        metrics['mae'][i] = mean_absolute_error(y_t, y_p)\n",
        "        metrics['rmse'][i] = np.sqrt(mean_squared_error(y_t, y_p))\n",
        "\n",
        "        var_true = np.var(y_t)\n",
        "        if var_true < 1e-10:\n",
        "            metrics['r2'][i] = 0.0\n",
        "        else:\n",
        "            try:\n",
        "                metrics['r2'][i] = r2_score(y_t, y_p)\n",
        "            except:\n",
        "                metrics['r2'][i] = -1.0\n",
        "\n",
        "        non_zero_mask = np.abs(y_t) > 1e-6\n",
        "        if np.sum(non_zero_mask) > 0:\n",
        "            mape = np.mean(np.abs((y_t[non_zero_mask] - y_p[non_zero_mask]) / y_t[non_zero_mask])) * 100\n",
        "            metrics['mape'][i] = mape\n",
        "        else:\n",
        "            metrics['mape'][i] = np.nan\n",
        "\n",
        "        metrics['true_mean'][i] = np.mean(y_t)\n",
        "        metrics['true_std'][i] = np.std(y_t)\n",
        "        metrics['pred_mean'][i] = np.mean(y_p)\n",
        "        metrics['pred_std'][i] = np.std(y_p)\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# æ¨¡åž‹å®šä¹‰\n",
        "# ============================================================================\n",
        "class CompactSensorTransformer(nn.Module):\n",
        "    \"\"\"ç´§å‡‘åž‹ä¼ æ„Ÿå™¨Transformer\"\"\"\n",
        "    def __init__(self, num_inputs, num_outputs, d_model=128, nhead=8,\n",
        "                 num_layers=3, dropout=0.1, model_name=\"SST\"):\n",
        "        super().__init__()\n",
        "        self.num_inputs = num_inputs\n",
        "        self.num_outputs = num_outputs\n",
        "        self.d_model = d_model\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.input_embedding = nn.Linear(1, d_model)\n",
        "        self.position_encoding = nn.Parameter(torch.randn(num_inputs, d_model))\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=d_model*2,\n",
        "            dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.output_projection = nn.Linear(d_model, num_outputs)\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        x = x.unsqueeze(-1)\n",
        "        x = self.input_embedding(x) + self.position_encoding.unsqueeze(0)\n",
        "        x = self.transformer(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.global_pool(x).squeeze(-1)\n",
        "        predictions = self.output_projection(x)\n",
        "        return predictions\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# åŠ è½½æ¨¡åž‹å’Œæ•°æ®\n",
        "# ============================================================================\n",
        "def load_models_and_scalers():\n",
        "    \"\"\"åŠ è½½æ‰€æœ‰å¿…éœ€çš„æ¨¡åž‹å’Œscalers\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“‚ åŠ è½½æ¨¡åž‹å’ŒScalers\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    required_files = [\n",
        "        'boost_stage1_best.pth',\n",
        "        'boost_stage2_best.pth',\n",
        "        'stage1_scalers.pkl',\n",
        "        'stage2_scalers.pkl'\n",
        "    ]\n",
        "\n",
        "    for file in required_files:\n",
        "        if not os.path.exists(file):\n",
        "            raise FileNotFoundError(f\"âŒ æœªæ‰¾åˆ° {file}ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡åž‹ï¼\")\n",
        "\n",
        "    results = None\n",
        "    input_features = None\n",
        "    output_features = None\n",
        "\n",
        "    if os.path.exists('boost_results.pkl'):\n",
        "        with open('boost_results.pkl', 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            results = data.get('results', {})\n",
        "            input_features = results.get('input_features')\n",
        "            output_features = results.get('output_features')\n",
        "        print(\"âœ… åŠ è½½ boost_results.pkl\")\n",
        "    elif os.path.exists('boost_results_stage2_only.pkl'):\n",
        "        with open('boost_results_stage2_only.pkl', 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            results = data.get('results', {})\n",
        "            input_features = results.get('input_features')\n",
        "            output_features = results.get('output_features')\n",
        "        print(\"âœ… åŠ è½½ boost_results_stage2_only.pkl\")\n",
        "    else:\n",
        "        print(\"âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒç»“æžœæ–‡ä»¶ï¼Œå°†åœ¨æŽ¨ç†åŽé‡æ–°è®¡ç®—ä¿¡å·RÂ²\")\n",
        "\n",
        "    with open('stage1_scalers.pkl', 'rb') as f:\n",
        "        stage1_data = pickle.load(f)\n",
        "\n",
        "    with open('stage2_scalers.pkl', 'rb') as f:\n",
        "        stage2_data = pickle.load(f)\n",
        "\n",
        "    scalers = {\n",
        "        'stage1_scaler_X': stage1_data['scaler_X'],\n",
        "        'stage1_scaler_y': stage1_data['scaler_y'],\n",
        "        'stage2_scaler_X': stage2_data['scaler_X'],\n",
        "        'stage2_scaler_residual': stage2_data['scaler_residual']\n",
        "    }\n",
        "\n",
        "    print(\"âœ… ScalersåŠ è½½æˆåŠŸ\")\n",
        "\n",
        "    num_inputs = scalers['stage1_scaler_X'].n_features_in_\n",
        "    num_outputs = scalers['stage1_scaler_y'].n_features_in_\n",
        "\n",
        "    print(f\"\\nðŸ“Š æ¨¡åž‹ç»´åº¦:\")\n",
        "    print(f\"  è¾“å…¥ç‰¹å¾æ•°: {num_inputs}\")\n",
        "    print(f\"  è¾“å‡ºç‰¹å¾æ•°: {num_outputs}\")\n",
        "\n",
        "    base_model = CompactSensorTransformer(\n",
        "        num_inputs=num_inputs, num_outputs=num_outputs,\n",
        "        d_model=256, nhead=16, num_layers=6, dropout=0.1,\n",
        "        model_name=\"Stage1_Base\"\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    base_model.load_state_dict(torch.load('boost_stage1_best.pth'))\n",
        "    base_model.eval()\n",
        "    print(f\"âœ… Stage 1æ¨¡åž‹åŠ è½½æˆåŠŸ: {sum(p.numel() for p in base_model.parameters()):,} å‚æ•°\")\n",
        "\n",
        "    residual_model = CompactSensorTransformer(\n",
        "        num_inputs=num_inputs, num_outputs=num_outputs,\n",
        "        d_model=256, nhead=16, num_layers=6, dropout=0.15,\n",
        "        model_name=\"Stage2_Residual\"\n",
        "    ).to(config.DEVICE)\n",
        "\n",
        "    residual_model.load_state_dict(torch.load('boost_stage2_best.pth'))\n",
        "    residual_model.eval()\n",
        "    print(f\"âœ… Stage 2æ¨¡åž‹åŠ è½½æˆåŠŸ: {sum(p.numel() for p in residual_model.parameters()):,} å‚æ•°\")\n",
        "\n",
        "    print_gpu_memory()\n",
        "\n",
        "    return base_model, residual_model, scalers, results, input_features, output_features\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# âœ… æ‰¹å¤„ç†æŽ¨ç†å‡½æ•° - å†…å­˜ä¼˜åŒ–\n",
        "# ============================================================================\n",
        "def batch_inference(model, X_data, scaler_X, scaler_y, batch_size, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    æ‰¹å¤„ç†æŽ¨ç†å‡½æ•° - é¿å…GPU OOM\n",
        "\n",
        "    Args:\n",
        "        model: PyTorchæ¨¡åž‹\n",
        "        X_data: è¾“å…¥æ•°æ® (n_samples, n_features)\n",
        "        scaler_X: è¾“å…¥æ ‡å‡†åŒ–å™¨\n",
        "        scaler_y: è¾“å‡ºæ ‡å‡†åŒ–å™¨\n",
        "        batch_size: æ‰¹æ¬¡å¤§å°\n",
        "        model_name: æ¨¡åž‹åç§°ï¼ˆç”¨äºŽæ˜¾ç¤ºï¼‰\n",
        "\n",
        "    Returns:\n",
        "        y_pred: é¢„æµ‹ç»“æžœï¼ˆå·²åæ ‡å‡†åŒ–ï¼‰\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    n_samples = X_data.shape[0]\n",
        "    predictions_list = []\n",
        "\n",
        "    print(f\"\\nðŸ”® {model_name} æ‰¹å¤„ç†æŽ¨ç†:\")\n",
        "    print(f\"  æ€»æ ·æœ¬æ•°: {n_samples:,}\")\n",
        "    print(f\"  æ‰¹æ¬¡å¤§å°: {batch_size}\")\n",
        "    print(f\"  æ‰¹æ¬¡æ•°é‡: {(n_samples + batch_size - 1) // batch_size}\")\n",
        "\n",
        "    for i in range(0, n_samples, batch_size):\n",
        "        # èŽ·å–æ‰¹æ¬¡æ•°æ®\n",
        "        end_idx = min(i + batch_size, n_samples)\n",
        "        batch_X = X_data[i:end_idx]\n",
        "\n",
        "        # æ ‡å‡†åŒ–\n",
        "        batch_X_scaled = scaler_X.transform(batch_X)\n",
        "        batch_X_tensor = torch.FloatTensor(batch_X_scaled).to(config.DEVICE)\n",
        "\n",
        "        # æŽ¨ç†\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                batch_pred_scaled = model(batch_X_tensor).cpu().numpy()\n",
        "\n",
        "        # åæ ‡å‡†åŒ–\n",
        "        batch_pred = scaler_y.inverse_transform(batch_pred_scaled)\n",
        "        predictions_list.append(batch_pred)\n",
        "\n",
        "        # âœ… ç«‹å³é‡Šæ”¾GPUå†…å­˜\n",
        "        del batch_X_tensor, batch_pred_scaled\n",
        "\n",
        "        # æ¯10ä¸ªbatchæ¸…ç†ä¸€æ¬¡\n",
        "        if (i // batch_size + 1) % 10 == 0:\n",
        "            clear_gpu_memory()\n",
        "\n",
        "        # æ˜¾ç¤ºè¿›åº¦\n",
        "        if (i // batch_size + 1) % 20 == 0 or end_idx == n_samples:\n",
        "            print(f\"  è¿›åº¦: {end_idx:,}/{n_samples:,} ({end_idx/n_samples*100:.1f}%)\")\n",
        "\n",
        "    # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡çš„é¢„æµ‹\n",
        "    y_pred = np.vstack(predictions_list)\n",
        "\n",
        "    # âœ… æœ€ç»ˆæ¸…ç†\n",
        "    clear_gpu_memory()\n",
        "\n",
        "    print(f\"  âœ… å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: {y_pred.shape}\")\n",
        "    print_gpu_memory()\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# æŽ¨ç†å‡½æ•° - ä½¿ç”¨æ‰¹å¤„ç†\n",
        "# ============================================================================\n",
        "def inference_with_boosting(X_test, base_model, residual_model, scalers,\n",
        "                           signal_r2_scores=None, r2_threshold=None):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨Boostingè¿›è¡ŒæŽ¨ç† - å†…å­˜ä¼˜åŒ–ç‰ˆ\n",
        "\n",
        "    Args:\n",
        "        X_test: æµ‹è¯•æ•°æ® (n_samples, n_features)\n",
        "        base_model: Stage 1æ¨¡åž‹\n",
        "        residual_model: Stage 2æ¨¡åž‹\n",
        "        scalers: æ ‡å‡†åŒ–å™¨å­—å…¸\n",
        "        signal_r2_scores: å„ä¿¡å·çš„RÂ²åˆ†æ•°ï¼ˆç”¨äºŽé€‰æ‹©æ€§Boostingï¼‰\n",
        "        r2_threshold: RÂ²é˜ˆå€¼\n",
        "\n",
        "    Returns:\n",
        "        y_pred_stage1: Stage 1çš„é¢„æµ‹ç»“æžœ\n",
        "        y_pred_boosted: BoostingåŽçš„é¢„æµ‹ç»“æžœ\n",
        "        boosting_mask: å“ªäº›ä¿¡å·è¢«Boostingäº†\n",
        "    \"\"\"\n",
        "    if r2_threshold is None:\n",
        "        r2_threshold = config.R2_THRESHOLD\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ”® æ‰§è¡ŒæŽ¨ç† - å†…å­˜ä¼˜åŒ–ç‰ˆ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # âœ… Stage 1æ‰¹å¤„ç†æŽ¨ç†\n",
        "    y_pred_stage1 = batch_inference(\n",
        "        base_model, X_test,\n",
        "        scalers['stage1_scaler_X'],\n",
        "        scalers['stage1_scaler_y'],\n",
        "        config.INFERENCE_BATCH_SIZE,\n",
        "        \"Stage 1\"\n",
        "    )\n",
        "\n",
        "    # âœ… Stage 2æ‰¹å¤„ç†æŽ¨ç†\n",
        "    residual_pred = batch_inference(\n",
        "        residual_model, X_test,\n",
        "        scalers['stage2_scaler_X'],\n",
        "        scalers['stage2_scaler_residual'],\n",
        "        config.INFERENCE_BATCH_SIZE,\n",
        "        \"Stage 2\"\n",
        "    )\n",
        "\n",
        "    # å…¨é‡Boosting\n",
        "    y_pred_full_boosted = y_pred_stage1 + residual_pred\n",
        "\n",
        "    # é€‰æ‹©æ€§Boosting\n",
        "    if config.USE_SELECTIVE_BOOSTING and signal_r2_scores is not None:\n",
        "        boosting_mask = signal_r2_scores < r2_threshold\n",
        "        num_boosted = np.sum(boosting_mask)\n",
        "        num_total = len(boosting_mask)\n",
        "\n",
        "        print(f\"\\nâ­ é€‰æ‹©æ€§Boosting:\")\n",
        "        print(f\"  RÂ²é˜ˆå€¼: {r2_threshold}\")\n",
        "        print(f\"  è¢«Boostingçš„ä¿¡å·: {num_boosted}/{num_total} ({num_boosted/num_total*100:.1f}%)\")\n",
        "        print(f\"  ä¿æŒStage 1çš„ä¿¡å·: {num_total-num_boosted}/{num_total} ({(num_total-num_boosted)/num_total*100:.1f}%)\")\n",
        "\n",
        "        y_pred_boosted = y_pred_stage1.copy()\n",
        "        y_pred_boosted[:, boosting_mask] = y_pred_full_boosted[:, boosting_mask]\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸  æœªä½¿ç”¨é€‰æ‹©æ€§Boostingï¼Œæ‰€æœ‰ä¿¡å·éƒ½åº”ç”¨æ®‹å·®\")\n",
        "        y_pred_boosted = y_pred_full_boosted\n",
        "        boosting_mask = np.ones(y_pred_stage1.shape[1], dtype=bool)\n",
        "\n",
        "    return y_pred_stage1, y_pred_boosted, boosting_mask\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\n",
        "# ============================================================================\n",
        "def generate_evaluation_report(y_test, y_pred_stage1, y_pred_boosted,\n",
        "                              boosting_mask, output_features=None):\n",
        "    \"\"\"ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘ŠCSV\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    n_signals = y_test.shape[1]\n",
        "\n",
        "    if output_features is None:\n",
        "        output_features = [f\"Signal_{i}\" for i in range(n_signals)]\n",
        "\n",
        "    # è®¡ç®—Stage 1æŒ‡æ ‡\n",
        "    print(\"\\nè®¡ç®—Stage 1æŒ‡æ ‡...\")\n",
        "    metrics_stage1 = compute_per_signal_metrics(y_test, y_pred_stage1)\n",
        "\n",
        "    # è®¡ç®—BoostingåŽæŒ‡æ ‡\n",
        "    print(\"è®¡ç®—BoostingåŽæŒ‡æ ‡...\")\n",
        "    metrics_boosted = compute_per_signal_metrics(y_test, y_pred_boosted)\n",
        "\n",
        "    # åˆ›å»ºè¯¦ç»†æŠ¥å‘ŠDataFrame\n",
        "    report_data = []\n",
        "\n",
        "    for i in range(n_signals):\n",
        "        row = {\n",
        "            'Signal_Index': i,\n",
        "            'Signal_Name': output_features[i] if i < len(output_features) else f\"Signal_{i}\",\n",
        "\n",
        "            # Stage 1æŒ‡æ ‡\n",
        "            'Stage1_R2': metrics_stage1['r2'][i],\n",
        "            'Stage1_MAE': metrics_stage1['mae'][i],\n",
        "            'Stage1_RMSE': metrics_stage1['rmse'][i],\n",
        "            'Stage1_MAPE': metrics_stage1['mape'][i],\n",
        "\n",
        "            # BoostingåŽæŒ‡æ ‡\n",
        "            'Boosted_R2': metrics_boosted['r2'][i],\n",
        "            'Boosted_MAE': metrics_boosted['mae'][i],\n",
        "            'Boosted_RMSE': metrics_boosted['rmse'][i],\n",
        "            'Boosted_MAPE': metrics_boosted['mape'][i],\n",
        "\n",
        "            # æ”¹è¿›é‡\n",
        "            'R2_Improvement': metrics_boosted['r2'][i] - metrics_stage1['r2'][i],\n",
        "            'MAE_Improvement': metrics_stage1['mae'][i] - metrics_boosted['mae'][i],\n",
        "            'RMSE_Improvement': metrics_stage1['rmse'][i] - metrics_boosted['rmse'][i],\n",
        "\n",
        "            # æ”¹è¿›ç™¾åˆ†æ¯”\n",
        "            'MAE_Improvement_Pct': ((metrics_stage1['mae'][i] - metrics_boosted['mae'][i]) /\n",
        "                                   (metrics_stage1['mae'][i] + 1e-10) * 100),\n",
        "            'RMSE_Improvement_Pct': ((metrics_stage1['rmse'][i] - metrics_boosted['rmse'][i]) /\n",
        "                                    (metrics_stage1['rmse'][i] + 1e-10) * 100),\n",
        "\n",
        "            # çœŸå®žå€¼ç»Ÿè®¡\n",
        "            'True_Mean': metrics_stage1['true_mean'][i],\n",
        "            'True_Std': metrics_stage1['true_std'][i],\n",
        "\n",
        "            # æ˜¯å¦è¢«Boosting\n",
        "            'Is_Boosted': boosting_mask[i],\n",
        "\n",
        "            # ä¿¡å·è´¨é‡åˆ†ç±»\n",
        "            'Stage1_Quality': 'Excellent' if metrics_stage1['r2'][i] >= 0.9\n",
        "                            else 'Good' if metrics_stage1['r2'][i] >= 0.7\n",
        "                            else 'Fair' if metrics_stage1['r2'][i] >= 0.5\n",
        "                            else 'Poor',\n",
        "            'Boosted_Quality': 'Excellent' if metrics_boosted['r2'][i] >= 0.9\n",
        "                             else 'Good' if metrics_boosted['r2'][i] >= 0.7\n",
        "                             else 'Fair' if metrics_boosted['r2'][i] >= 0.5\n",
        "                             else 'Poor'\n",
        "        }\n",
        "\n",
        "        report_data.append(row)\n",
        "\n",
        "    df_report = pd.DataFrame(report_data)\n",
        "\n",
        "    # åˆ›å»ºæ•´ä½“å¯¹æ¯”æ‘˜è¦\n",
        "    overall_stage1_r2, _ = compute_r2_safe(y_test, y_pred_stage1)\n",
        "    overall_boosted_r2, _ = compute_r2_safe(y_test, y_pred_boosted)\n",
        "\n",
        "    overall_stage1_mae = mean_absolute_error(y_test, y_pred_stage1)\n",
        "    overall_boosted_mae = mean_absolute_error(y_test, y_pred_boosted)\n",
        "\n",
        "    overall_stage1_rmse = np.sqrt(mean_squared_error(y_test, y_pred_stage1))\n",
        "    overall_boosted_rmse = np.sqrt(mean_squared_error(y_test, y_pred_boosted))\n",
        "\n",
        "    summary_data = {\n",
        "        'Metric': ['RÂ²', 'MAE', 'RMSE', 'Num_Signals_Boosted'],\n",
        "        'Stage1': [overall_stage1_r2, overall_stage1_mae, overall_stage1_rmse, 0],\n",
        "        'Boosted': [overall_boosted_r2, overall_boosted_mae, overall_boosted_rmse,\n",
        "                   np.sum(boosting_mask)],\n",
        "        'Improvement': [\n",
        "            overall_boosted_r2 - overall_stage1_r2,\n",
        "            overall_stage1_mae - overall_boosted_mae,\n",
        "            overall_stage1_rmse - overall_boosted_rmse,\n",
        "            np.sum(boosting_mask)\n",
        "        ],\n",
        "        'Improvement_Pct': [\n",
        "            (overall_boosted_r2 - overall_stage1_r2) / (abs(overall_stage1_r2) + 1e-10) * 100,\n",
        "            (overall_stage1_mae - overall_boosted_mae) / (overall_stage1_mae + 1e-10) * 100,\n",
        "            (overall_stage1_rmse - overall_boosted_rmse) / (overall_stage1_rmse + 1e-10) * 100,\n",
        "            np.sum(boosting_mask) / len(boosting_mask) * 100\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "\n",
        "    # ä¿å­˜CSV\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    report_filename = f\"signal_evaluation_report_{timestamp}.csv\"\n",
        "    df_report.to_csv(report_filename, index=False)\n",
        "    print(f\"\\nâœ… è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_filename}\")\n",
        "\n",
        "    summary_filename = f\"boost_comparison_summary_{timestamp}.csv\"\n",
        "    df_summary.to_csv(summary_filename, index=False)\n",
        "    print(f\"âœ… æ•´ä½“å¯¹æ¯”æ‘˜è¦å·²ä¿å­˜: {summary_filename}\")\n",
        "\n",
        "    # æ‰“å°æ‘˜è¦\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š è¯„ä¼°æ‘˜è¦\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"\\næ€»ä¿¡å·æ•°: {n_signals}\")\n",
        "    print(f\"è¢«Boostingçš„ä¿¡å·æ•°: {np.sum(boosting_mask)} ({np.sum(boosting_mask)/n_signals*100:.1f}%)\")\n",
        "    print(f\"\\n{'æŒ‡æ ‡':<15} {'Stage 1':<15} {'Boosted':<15} {'æ”¹è¿›':<15}\")\n",
        "    print(\"-\" * 60)\n",
        "    print(f\"{'RÂ²':<15} {overall_stage1_r2:<15.6f} {overall_boosted_r2:<15.6f} \"\n",
        "          f\"{overall_boosted_r2 - overall_stage1_r2:+<15.6f}\")\n",
        "    print(f\"{'MAE':<15} {overall_stage1_mae:<15.6f} {overall_boosted_mae:<15.6f} \"\n",
        "          f\"{overall_stage1_mae - overall_boosted_mae:+<15.6f}\")\n",
        "    print(f\"{'RMSE':<15} {overall_stage1_rmse:<15.6f} {overall_boosted_rmse:<15.6f} \"\n",
        "          f\"{overall_stage1_rmse - overall_boosted_rmse:+<15.6f}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Topæ”¹è¿›ä¿¡å·\n",
        "    print(\"\\nðŸ“ˆ Top 10 æ”¹è¿›æœ€å¤§çš„ä¿¡å· (æŒ‰RÂ²æ”¹è¿›æŽ’åº):\")\n",
        "    top_improved = df_report.nlargest(10, 'R2_Improvement')[\n",
        "        ['Signal_Name', 'Stage1_R2', 'Boosted_R2', 'R2_Improvement', 'Is_Boosted']\n",
        "    ]\n",
        "    print(top_improved.to_string(index=False))\n",
        "\n",
        "    return df_report, df_summary\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ä¸»æŽ¨ç†å’Œè¯„ä¼°æµç¨‹\n",
        "# ============================================================================\n",
        "def run_inference_and_evaluation(X, y, input_features=None, output_features=None):\n",
        "    \"\"\"è¿è¡Œå®Œæ•´çš„æŽ¨ç†å’Œè¯„ä¼°æµç¨‹ - å†…å­˜ä¼˜åŒ–ç‰ˆ\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸš€ å¼€å§‹æŽ¨ç†å’Œè¯„ä¼°æµç¨‹ - å†…å­˜ä¼˜åŒ–ç‰ˆ\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # 1. åŠ è½½æ¨¡åž‹\n",
        "    base_model, residual_model, scalers, train_results, \\\n",
        "        loaded_input_features, loaded_output_features = load_models_and_scalers()\n",
        "\n",
        "    if output_features is None and loaded_output_features is not None:\n",
        "        output_features = loaded_output_features\n",
        "    if input_features is None and loaded_input_features is not None:\n",
        "        input_features = loaded_input_features\n",
        "\n",
        "    # 2. åˆ’åˆ†æµ‹è¯•é›†\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“Š å‡†å¤‡æµ‹è¯•æ•°æ®\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    _, X_test, _, y_test = train_test_split(\n",
        "        X, y, test_size=config.TRAIN_TEST_SPLIT, random_state=config.RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    print(f\"æµ‹è¯•é›†å¤§å°: {len(X_test):,} æ ·æœ¬\")\n",
        "    print(f\"è¾“å…¥ç‰¹å¾æ•°: {X_test.shape[1]}\")\n",
        "    print(f\"è¾“å‡ºç‰¹å¾æ•°: {y_test.shape[1]}\")\n",
        "\n",
        "    # 3. èŽ·å–æˆ–è®¡ç®—ä¿¡å·RÂ²åˆ†æ•°\n",
        "    if train_results is not None and 'signal_r2_scores' in train_results:\n",
        "        signal_r2_scores = train_results['signal_r2_scores']\n",
        "        print(f\"\\nâœ… ä½¿ç”¨è®­ç»ƒæ—¶çš„ä¿¡å·RÂ²åˆ†æ•°\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæ—¶çš„ä¿¡å·RÂ²åˆ†æ•°ï¼Œå°†åŸºäºŽæµ‹è¯•é›†é‡æ–°è®¡ç®—...\")\n",
        "        print(f\"   ä½¿ç”¨æ‰¹å¤„ç†é¿å…GPU OOM...\")\n",
        "\n",
        "        # âœ… ä½¿ç”¨æ‰¹å¤„ç†è®¡ç®—RÂ²åˆ†æ•°\n",
        "        y_pred_stage1_temp = batch_inference(\n",
        "            base_model, X_test,\n",
        "            scalers['stage1_scaler_X'],\n",
        "            scalers['stage1_scaler_y'],\n",
        "            config.INFERENCE_BATCH_SIZE,\n",
        "            \"Stage 1 (RÂ²è®¡ç®—)\"\n",
        "        )\n",
        "\n",
        "        _, signal_r2_scores = compute_r2_safe(y_test, y_pred_stage1_temp)\n",
        "        print(f\"âœ… ä¿¡å·RÂ²åˆ†æ•°è®¡ç®—å®Œæˆ\")\n",
        "\n",
        "        # âœ… æ¸…ç†ä¸´æ—¶æ•°æ®\n",
        "        del y_pred_stage1_temp\n",
        "        clear_gpu_memory()\n",
        "\n",
        "    # 4. æŽ¨ç†\n",
        "    y_pred_stage1, y_pred_boosted, boosting_mask = inference_with_boosting(\n",
        "        X_test, base_model, residual_model, scalers,\n",
        "        signal_r2_scores, config.R2_THRESHOLD\n",
        "    )\n",
        "\n",
        "    # 5. ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\n",
        "    df_report, df_summary = generate_evaluation_report(\n",
        "        y_test, y_pred_stage1, y_pred_boosted,\n",
        "        boosting_mask, output_features\n",
        "    )\n",
        "\n",
        "    # 6. è¿”å›žç»“æžœ\n",
        "    results = {\n",
        "        'y_test': y_test,\n",
        "        'y_pred_stage1': y_pred_stage1,\n",
        "        'y_pred_boosted': y_pred_boosted,\n",
        "        'boosting_mask': boosting_mask,\n",
        "        'signal_r2_scores': signal_r2_scores,\n",
        "        'df_report': df_report,\n",
        "        'df_summary': df_summary\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"âœ… æŽ¨ç†å’Œè¯„ä¼°æµç¨‹å®Œæˆï¼\")\n",
        "    print(\"=\"*80)\n",
        "    print_gpu_memory()\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# ä½¿ç”¨è¯´æ˜Ž\n",
        "# ============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸ“‹ ä½¿ç”¨è¯´æ˜Ž - å†…å­˜ä¼˜åŒ–ç‰ˆ\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\"\"\n",
        "    æœ¬è„šæœ¬æ˜¯å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼Œè§£å†³GPU OOMé—®é¢˜ã€‚\n",
        "\n",
        "    ä¼˜åŒ–ç‰¹æ€§ï¼š\n",
        "    1. âœ… æ‰¹å¤„ç†æŽ¨ç†ï¼ˆé»˜è®¤batch_size=512ï¼‰\n",
        "    2. âœ… åŠæ—¶é‡Šæ”¾GPUå†…å­˜\n",
        "    3. âœ… è‡ªåŠ¨å†…å­˜ç¢Žç‰‡æ•´ç†\n",
        "    4. âœ… è¿›åº¦æ˜¾ç¤º\n",
        "\n",
        "    ä½¿ç”¨æ–¹æ³•ï¼š\n",
        "\n",
        "    from inference_and_evaluation_memory_optimized import run_inference_and_evaluation\n",
        "\n",
        "    # å¦‚æžœä»ç„¶OOMï¼Œå¯ä»¥è°ƒæ•´batch_size\n",
        "    # åœ¨å¯¼å…¥åŽä¿®æ”¹é…ç½®ï¼š\n",
        "    import inference_and_evaluation_memory_optimized as inf\n",
        "    inf.config.INFERENCE_BATCH_SIZE = 256  # å‡å°batch size\n",
        "\n",
        "    results = run_inference_and_evaluation(X, y, input_features, output_features)\n",
        "\n",
        "    è°ƒæ•´å»ºè®®ï¼š\n",
        "    - GPU 40GB: batch_size=1024\n",
        "    - GPU 24GB: batch_size=512 (é»˜è®¤)\n",
        "    - GPU 16GB: batch_size=256\n",
        "    - GPU 12GB: batch_size=128\n",
        "    \"\"\")\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIeJ1ZP5pGBw",
        "outputId": "37aa0a46-c102-4bae-8d4d-88e46b128784"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ðŸ“Š Inference & Evaluation - å†…å­˜ä¼˜åŒ–ç‰ˆ\n",
            "================================================================================\n",
            "PyTorchç‰ˆæœ¬: 2.8.0+cu126\n",
            "CUDAå¯ç”¨: True\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "GPUå†…å­˜: 39.56 GB\n",
            "================================================================================\n",
            "\n",
            "âš™ï¸  é…ç½®: è®¾å¤‡=cuda\n",
            "RÂ²é˜ˆå€¼: 0.5\n",
            "æŽ¨ç†æ‰¹æ¬¡å¤§å°: 512\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“‹ ä½¿ç”¨è¯´æ˜Ž - å†…å­˜ä¼˜åŒ–ç‰ˆ\n",
            "================================================================================\n",
            "\n",
            "    æœ¬è„šæœ¬æ˜¯å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬ï¼Œè§£å†³GPU OOMé—®é¢˜ã€‚\n",
            "\n",
            "    ä¼˜åŒ–ç‰¹æ€§ï¼š\n",
            "    1. âœ… æ‰¹å¤„ç†æŽ¨ç†ï¼ˆé»˜è®¤batch_size=512ï¼‰\n",
            "    2. âœ… åŠæ—¶é‡Šæ”¾GPUå†…å­˜\n",
            "    3. âœ… è‡ªåŠ¨å†…å­˜ç¢Žç‰‡æ•´ç†\n",
            "    4. âœ… è¿›åº¦æ˜¾ç¤º\n",
            "\n",
            "    ä½¿ç”¨æ–¹æ³•ï¼š\n",
            "\n",
            "    from inference_and_evaluation_memory_optimized import run_inference_and_evaluation\n",
            "\n",
            "    # å¦‚æžœä»ç„¶OOMï¼Œå¯ä»¥è°ƒæ•´batch_size\n",
            "    # åœ¨å¯¼å…¥åŽä¿®æ”¹é…ç½®ï¼š\n",
            "    import inference_and_evaluation_memory_optimized as inf\n",
            "    inf.config.INFERENCE_BATCH_SIZE = 256  # å‡å°batch size\n",
            "\n",
            "    results = run_inference_and_evaluation(X, y, input_features, output_features)\n",
            "\n",
            "    è°ƒæ•´å»ºè®®ï¼š\n",
            "    - GPU 40GB: batch_size=1024\n",
            "    - GPU 24GB: batch_size=512 (é»˜è®¤)\n",
            "    - GPU 16GB: batch_size=256\n",
            "    - GPU 12GB: batch_size=128\n",
            "    \n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_train_clean[INPUT_FEATURES_CLEAN].values\n",
        "y = df_train_clean[OUTPUT_FEATURES_CLEAN].values\n",
        "input_features = INPUT_FEATURES_CLEAN\n",
        "output_features = OUTPUT_FEATURES_CLEAN\n",
        "results = run_inference_and_evaluation(X, y, input_features, output_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGdncDCKpY2W",
        "outputId": "262ea586-b6f2-4e96-f0e6-056f67020afd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ðŸš€ å¼€å§‹æŽ¨ç†å’Œè¯„ä¼°æµç¨‹ - å†…å­˜ä¼˜åŒ–ç‰ˆ\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "ðŸ“‚ åŠ è½½æ¨¡åž‹å’ŒScalers\n",
            "================================================================================\n",
            "âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒç»“æžœæ–‡ä»¶ï¼Œå°†åœ¨æŽ¨ç†åŽé‡æ–°è®¡ç®—ä¿¡å·RÂ²\n",
            "âœ… ScalersåŠ è½½æˆåŠŸ\n",
            "\n",
            "ðŸ“Š æ¨¡åž‹ç»´åº¦:\n",
            "  è¾“å…¥ç‰¹å¾æ•°: 490\n",
            "  è¾“å‡ºç‰¹å¾æ•°: 164\n",
            "âœ… Stage 1æ¨¡åž‹åŠ è½½æˆåŠŸ: 3,330,724 å‚æ•°\n",
            "âœ… Stage 2æ¨¡åž‹åŠ è½½æˆåŠŸ: 3,330,724 å‚æ•°\n",
            "  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… 0.15 GB | å·²ä¿ç•™ 0.21 GB\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š å‡†å¤‡æµ‹è¯•æ•°æ®\n",
            "================================================================================\n",
            "æµ‹è¯•é›†å¤§å°: 93,750 æ ·æœ¬\n",
            "è¾“å…¥ç‰¹å¾æ•°: 490\n",
            "è¾“å‡ºç‰¹å¾æ•°: 164\n",
            "\n",
            "âš ï¸  æœªæ‰¾åˆ°è®­ç»ƒæ—¶çš„ä¿¡å·RÂ²åˆ†æ•°ï¼Œå°†åŸºäºŽæµ‹è¯•é›†é‡æ–°è®¡ç®—...\n",
            "   ä½¿ç”¨æ‰¹å¤„ç†é¿å…GPU OOM...\n",
            "\n",
            "ðŸ”® Stage 1 (RÂ²è®¡ç®—) æ‰¹å¤„ç†æŽ¨ç†:\n",
            "  æ€»æ ·æœ¬æ•°: 93,750\n",
            "  æ‰¹æ¬¡å¤§å°: 512\n",
            "  æ‰¹æ¬¡æ•°é‡: 184\n",
            "  è¿›åº¦: 10,240/93,750 (10.9%)\n",
            "  è¿›åº¦: 20,480/93,750 (21.8%)\n",
            "  è¿›åº¦: 30,720/93,750 (32.8%)\n",
            "  è¿›åº¦: 40,960/93,750 (43.7%)\n",
            "  è¿›åº¦: 51,200/93,750 (54.6%)\n",
            "  è¿›åº¦: 61,440/93,750 (65.5%)\n",
            "  è¿›åº¦: 71,680/93,750 (76.5%)\n",
            "  è¿›åº¦: 81,920/93,750 (87.4%)\n",
            "  è¿›åº¦: 92,160/93,750 (98.3%)\n",
            "  è¿›åº¦: 93,750/93,750 (100.0%)\n",
            "  âœ… å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: (93750, 164)\n",
            "  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… 0.15 GB | å·²ä¿ç•™ 0.19 GB\n",
            "âœ… ä¿¡å·RÂ²åˆ†æ•°è®¡ç®—å®Œæˆ\n",
            "\n",
            "================================================================================\n",
            "ðŸ”® æ‰§è¡ŒæŽ¨ç† - å†…å­˜ä¼˜åŒ–ç‰ˆ\n",
            "================================================================================\n",
            "\n",
            "ðŸ”® Stage 1 æ‰¹å¤„ç†æŽ¨ç†:\n",
            "  æ€»æ ·æœ¬æ•°: 93,750\n",
            "  æ‰¹æ¬¡å¤§å°: 512\n",
            "  æ‰¹æ¬¡æ•°é‡: 184\n",
            "  è¿›åº¦: 10,240/93,750 (10.9%)\n",
            "  è¿›åº¦: 20,480/93,750 (21.8%)\n",
            "  è¿›åº¦: 30,720/93,750 (32.8%)\n",
            "  è¿›åº¦: 40,960/93,750 (43.7%)\n",
            "  è¿›åº¦: 51,200/93,750 (54.6%)\n",
            "  è¿›åº¦: 61,440/93,750 (65.5%)\n",
            "  è¿›åº¦: 71,680/93,750 (76.5%)\n",
            "  è¿›åº¦: 81,920/93,750 (87.4%)\n",
            "  è¿›åº¦: 92,160/93,750 (98.3%)\n",
            "  è¿›åº¦: 93,750/93,750 (100.0%)\n",
            "  âœ… å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: (93750, 164)\n",
            "  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… 0.15 GB | å·²ä¿ç•™ 0.19 GB\n",
            "\n",
            "ðŸ”® Stage 2 æ‰¹å¤„ç†æŽ¨ç†:\n",
            "  æ€»æ ·æœ¬æ•°: 93,750\n",
            "  æ‰¹æ¬¡å¤§å°: 512\n",
            "  æ‰¹æ¬¡æ•°é‡: 184\n",
            "  è¿›åº¦: 10,240/93,750 (10.9%)\n",
            "  è¿›åº¦: 20,480/93,750 (21.8%)\n",
            "  è¿›åº¦: 30,720/93,750 (32.8%)\n",
            "  è¿›åº¦: 40,960/93,750 (43.7%)\n",
            "  è¿›åº¦: 51,200/93,750 (54.6%)\n",
            "  è¿›åº¦: 61,440/93,750 (65.5%)\n",
            "  è¿›åº¦: 71,680/93,750 (76.5%)\n",
            "  è¿›åº¦: 81,920/93,750 (87.4%)\n",
            "  è¿›åº¦: 92,160/93,750 (98.3%)\n",
            "  è¿›åº¦: 93,750/93,750 (100.0%)\n",
            "  âœ… å®Œæˆï¼è¾“å‡ºå½¢çŠ¶: (93750, 164)\n",
            "  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… 0.15 GB | å·²ä¿ç•™ 0.19 GB\n",
            "\n",
            "â­ é€‰æ‹©æ€§Boosting:\n",
            "  RÂ²é˜ˆå€¼: 0.5\n",
            "  è¢«Boostingçš„ä¿¡å·: 67/164 (40.9%)\n",
            "  ä¿æŒStage 1çš„ä¿¡å·: 97/164 (59.1%)\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\n",
            "================================================================================\n",
            "\n",
            "è®¡ç®—Stage 1æŒ‡æ ‡...\n",
            "è®¡ç®—BoostingåŽæŒ‡æ ‡...\n",
            "\n",
            "âœ… è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: signal_evaluation_report_20251028_030611.csv\n",
            "âœ… æ•´ä½“å¯¹æ¯”æ‘˜è¦å·²ä¿å­˜: boost_comparison_summary_20251028_030611.csv\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š è¯„ä¼°æ‘˜è¦\n",
            "================================================================================\n",
            "\n",
            "æ€»ä¿¡å·æ•°: 164\n",
            "è¢«Boostingçš„ä¿¡å·æ•°: 67 (40.9%)\n",
            "\n",
            "æŒ‡æ ‡              Stage 1         Boosted         æ”¹è¿›             \n",
            "------------------------------------------------------------\n",
            "RÂ²              0.585205        0.595210        0.010006+++++++\n",
            "MAE             0.319978        0.321833        -0.001855++++++\n",
            "RMSE            0.670700        0.662445        0.008256+++++++\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ˆ Top 10 æ”¹è¿›æœ€å¤§çš„ä¿¡å· (æŒ‰RÂ²æ”¹è¿›æŽ’åº):\n",
            "Signal_Name  Stage1_R2  Boosted_R2  R2_Improvement  Is_Boosted\n",
            " ptend_u_12   0.161295    0.319338        0.158043        True\n",
            " ptend_u_13   0.306260    0.432995        0.126735        True\n",
            " ptend_u_17   0.478893    0.570640        0.091747        True\n",
            " ptend_u_14   0.398057    0.485712        0.087655        True\n",
            " ptend_u_15   0.474799    0.561118        0.086319        True\n",
            " ptend_v_14   0.237793    0.290594        0.052801        True\n",
            " ptend_v_18   0.448122    0.497049        0.048927        True\n",
            " ptend_u_19   0.283881    0.332528        0.048647        True\n",
            " ptend_v_15   0.408385    0.454291        0.045906        True\n",
            " ptend_u_20   0.460146    0.502223        0.042077        True\n",
            "\n",
            "================================================================================\n",
            "âœ… æŽ¨ç†å’Œè¯„ä¼°æµç¨‹å®Œæˆï¼\n",
            "================================================================================\n",
            "  ðŸ’¾ GPUå†…å­˜: å·²åˆ†é… 0.15 GB | å·²ä¿ç•™ 0.19 GB\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5673d347808945dd804b4a6a5c166139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07352d31476b4f28b1216f34598d0713",
              "IPY_MODEL_a35cb4da9c1e4d569db9a9a2294309d8",
              "IPY_MODEL_27c01d7b17bd432b9b66e0e8c966d5f7"
            ],
            "layout": "IPY_MODEL_3f426f6dfc4049d080bc7612b1a1da06"
          }
        },
        "07352d31476b4f28b1216f34598d0713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffd67c32bc034e96b1d83f49a2c3da74",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f51e260d94e6400fbd8d0cc7663644c8",
            "value": "â€‡â€‡åŠ è½½content:â€‡100%"
          }
        },
        "a35cb4da9c1e4d569db9a9a2294309d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70da0f7911f45aa9d05ac82abbc1c95",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50cf4efde43f4b628549be8d715a4c8a",
            "value": 2
          }
        },
        "27c01d7b17bd432b9b66e0e8c966d5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5dbfa500d9e4bada083099c3c8a0eb9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f71c441d09464534b75ae2b1f79f0182",
            "value": "â€‡2/2â€‡[00:03&lt;00:00,â€‡â€‡1.47s/it]"
          }
        },
        "3f426f6dfc4049d080bc7612b1a1da06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd67c32bc034e96b1d83f49a2c3da74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51e260d94e6400fbd8d0cc7663644c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d70da0f7911f45aa9d05ac82abbc1c95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50cf4efde43f4b628549be8d715a4c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5dbfa500d9e4bada083099c3c8a0eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f71c441d09464534b75ae2b1f79f0182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "692ad2ccfdfd414290db8155a4f21580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e782761cb5d64552812c86140d314d1a",
              "IPY_MODEL_1186f261d691415180e4fdcf01dddbb9",
              "IPY_MODEL_124b304b6f384e2e935856b63bdf98b5"
            ],
            "layout": "IPY_MODEL_4093e971c482470e9857abc71684a1a9"
          }
        },
        "e782761cb5d64552812c86140d314d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a0120c24d3640df8d0de137ca608157",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_959e370fde414001b619cf20e97a7ad5",
            "value": "Training:â€‡â€‡â€‡3%"
          }
        },
        "1186f261d691415180e4fdcf01dddbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b841efe18f54619acb915686d5e5b05",
            "max": 519,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff2087ca53164542861abedcbae21687",
            "value": 15
          }
        },
        "124b304b6f384e2e935856b63bdf98b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c2ff3dc38d4b0d92c6853189b2f0a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0c256bf755d249f680c73d624bd994af",
            "value": "â€‡15/519â€‡[00:04&lt;01:54,â€‡â€‡4.40it/s,â€‡loss=1.0676]"
          }
        },
        "4093e971c482470e9857abc71684a1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a0120c24d3640df8d0de137ca608157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959e370fde414001b619cf20e97a7ad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b841efe18f54619acb915686d5e5b05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff2087ca53164542861abedcbae21687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15c2ff3dc38d4b0d92c6853189b2f0a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c256bf755d249f680c73d624bd994af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "557a03be3c184baea6c8e5007c04a77d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf107bccd5484d8d8880d3c1355b431a",
              "IPY_MODEL_b0c021863bbc4d34b2859b80357238b3",
              "IPY_MODEL_2c74ccd047814aa4a753813636ea2a39"
            ],
            "layout": "IPY_MODEL_6cd24b2857394d0486d70bbf2cfdf41a"
          }
        },
        "bf107bccd5484d8d8880d3c1355b431a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837cb76581274086aedca5f187d1e9ab",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b3d9b9c494164e72884b21c34e2f7456",
            "value": "Predictingâ€‡Baseâ€‡Modelâ€‡Residuals:â€‡100%"
          }
        },
        "b0c021863bbc4d34b2859b80357238b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34295e3b28834fd09b37d4b803bc1c79",
            "max": 260,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35d5b0567b3f4a9abb7e6057e2ca94ef",
            "value": 260
          }
        },
        "2c74ccd047814aa4a753813636ea2a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_773054585dc449b38fb4e5790cc87a2d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b92a150c4b7643ee85b57f80d177e775",
            "value": "â€‡260/260â€‡[00:32&lt;00:00,â€‡â€‡8.01it/s]"
          }
        },
        "6cd24b2857394d0486d70bbf2cfdf41a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "837cb76581274086aedca5f187d1e9ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d9b9c494164e72884b21c34e2f7456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34295e3b28834fd09b37d4b803bc1c79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d5b0567b3f4a9abb7e6057e2ca94ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "773054585dc449b38fb4e5790cc87a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92a150c4b7643ee85b57f80d177e775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5519a38cafff4e228866d57456c56c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd82bac6f90e4dc7b50c59337bd7efc0",
              "IPY_MODEL_ba247ef920cc4262bd4dbba2d75fff96",
              "IPY_MODEL_fdc948d7ee1b463ca0a6320884121188"
            ],
            "layout": "IPY_MODEL_46b798e7f63745eaa371e13a45a10c64"
          }
        },
        "dd82bac6f90e4dc7b50c59337bd7efc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3de8ae244c0f42569763a284c8965790",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_03207e57101e4b389baad8b84e0e4d57",
            "value": "Predictingâ€‡Baseâ€‡Modelâ€‡Residuals:â€‡â€‡67%"
          }
        },
        "ba247ef920cc4262bd4dbba2d75fff96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ef9ef8390548bbbc0a2bee9b958847",
            "max": 46,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ecd0541d181041b7b0f45c8092ec8232",
            "value": 31
          }
        },
        "fdc948d7ee1b463ca0a6320884121188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44b5360bab7a48f68cd6c002b3ce858c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ee77291a4f354f6e8af2cd4f5a115f65",
            "value": "â€‡31/46â€‡[00:04&lt;00:01,â€‡â€‡8.01it/s]"
          }
        },
        "46b798e7f63745eaa371e13a45a10c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de8ae244c0f42569763a284c8965790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03207e57101e4b389baad8b84e0e4d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5ef9ef8390548bbbc0a2bee9b958847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd0541d181041b7b0f45c8092ec8232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44b5360bab7a48f68cd6c002b3ce858c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee77291a4f354f6e8af2cd4f5a115f65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}