{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# å®Œæ•´Gradioç•Œé¢ - Industrial Digital Twin by Transformer\n\n## ğŸ“– ä½¿ç”¨è¯´æ˜\n\næœ¬Notebookæä¾›å®Œæ•´çš„Gradioç½‘é¡µç•Œé¢ï¼Œç”¨äºè®­ç»ƒå’Œæ¨ç†StaticTransformerå’ŒHybridSensorTransformeræ¨¡å‹ã€‚\n\n### ğŸ¯ ä¸¤ç§ä½¿ç”¨æ–¹å¼\n\n#### æ–¹å¼A: ä½¿ç”¨å·²æä¾›çš„å‡½æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰\n- è¿è¡Œä¸‹é¢æ‰€æœ‰cells\n- å¯åŠ¨Gradioç•Œé¢\n- é€‚åˆå¿«é€Ÿå¼€å§‹\n\n#### æ–¹å¼B: é›†æˆæ‚¨çš„å®Œæ•´Cell 3ä»£ç ï¼ˆå®Œæ•´åŠŸèƒ½ï¼‰\n- è¿è¡ŒCell 1å’ŒCell 2\n- åœ¨æ ‡è®°çš„ä½ç½®ç²˜è´´æ‚¨åŸå§‹çš„Cell 3ä»£ç \n- è·å¾—100%åŸå§‹åŠŸèƒ½\n\n### ğŸ“Œ Cell 3é›†æˆä½ç½®\n\nå¦‚æœæ‚¨æœ‰åŸå§‹çš„ `è¯´æ˜.txt` Cell 3ä»£ç ï¼š\n1. è¿è¡ŒCell 1å’ŒCell 2\n2. è·³è½¬åˆ°**\"ç²˜è´´æ‚¨çš„Cell 3ä»£ç \"**æ ‡è®°å¤„\n3. ç²˜è´´åŸå§‹Cell 3ä»£ç ï¼ˆä» `# å…¨å±€å˜é‡å­˜å‚¨` å¼€å§‹ï¼‰\n4. è¿è¡Œè¯¥Cellå¯åŠ¨ç•Œé¢"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æµ‹ç¯å¢ƒ\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸŒ åœ¨Google Colabä¸­è¿è¡Œ\")\n",
    "    print(\"ğŸ“¥ å…‹éš†ä»“åº“...\")\n",
    "    !git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git\n",
    "    %cd Industrial-digital-twin-by-transformer\n",
    "    print(\"ğŸ“¦ å®‰è£…ä¾èµ–...\")\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"âœ… å®‰è£…å®Œæˆï¼\")\n",
    "else:\n",
    "    print(\"ğŸ’» åœ¨æœ¬åœ°ç¯å¢ƒè¿è¡Œ\")\n",
    "    print(\"ç¡®ä¿å·²å®‰è£…ä¾èµ–: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“å’Œæ¨¡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# æ ‡å‡†åº“å¯¼å…¥\n# ============================================================================\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Gradioå’Œå…¶ä»–å·¥å…·\nimport gradio as gr\nimport json\nimport os\nfrom datetime import datetime\nimport traceback\n\n# Scipyï¼ˆç”¨äºHybridSensorTransformerçš„å¹³æ»‘åŠŸèƒ½ï¼‰\nfrom scipy.signal import savgol_filter\nfrom scipy.ndimage import maximum_filter1d\n\n# ============================================================================\n# ğŸ”¥ å…³é”®ï¼šå¯¼å…¥é¡¹ç›®æ¨¡å—ï¼ˆæ›¿ä»£åŸå§‹Cell 1å’ŒCell 2ï¼‰\n# ============================================================================\nfrom models.static_transformer import StaticSensorTransformer\nfrom models.hybrid_transformer import HybridSensorTransformer\nfrom models.utils import (\n    create_temporal_context_data,\n    apply_ifd_smoothing,\n    handle_duplicate_columns,\n    get_available_signals,\n    validate_signal_exclusivity_static,\n    validate_signal_exclusivity_hybrid\n)\n\n# ============================================================================\n# è®¾å¤‡é…ç½®\n# ============================================================================\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"StaticTransformeræ¨¡å‹ - ä½¿ç”¨è®¾å¤‡: {device}\")\nprint(f\"HybridSensorTransformeræ¨¡å‹ - ä½¿ç”¨è®¾å¤‡: {device}\")\nprint(\"âœ“ StaticTransformeræ¨¡å‹å®šä¹‰å®Œæˆ\")\nprint(\"âœ“ HybridSensorTransformeræ¨¡å‹å®šä¹‰å®Œæˆ\")\nprint(\"\\n\" + \"=\"*80)\nprint(\"âœ… æ‰€æœ‰æ¨¡å—å·²æˆåŠŸå¯¼å…¥ï¼\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ğŸ”´ é‡è¦æç¤ºï¼šé€‰æ‹©æ‚¨çš„ä½¿ç”¨æ–¹å¼\n\n### ğŸ“ é€‰é¡¹Aï¼šä½¿ç”¨ç®€åŒ–ç‰ˆç•Œé¢\n\nç»§ç»­è¿è¡Œä¸‹é¢çš„cellsï¼ˆCell 3-6ï¼‰\n\n### ğŸ“ é€‰é¡¹Bï¼šä½¿ç”¨æ‚¨çš„å®Œæ•´Cell 3ä»£ç ï¼ˆæ¨èï¼‰\n\n1. **è·³è¿‡**ä¸‹é¢çš„Cells 3-6\n2. **ç›´æ¥è·³åˆ°**æœ€åçš„ \"ç²˜è´´æ‚¨çš„Cell 3ä»£ç \" éƒ¨åˆ†\n3. åœ¨é‚£é‡Œç²˜è´´æ‚¨åŸå§‹ `è¯´æ˜.txt` çš„Cell 3å®Œæ•´ä»£ç \n\n---\n\nğŸ’¡ **æ¨¡å‹åç§°æ›´æ–°è¯´æ˜**ï¼š\n- V1 â†’ StaticTransformerï¼ˆé™æ€ä¼ æ„Ÿå™¨æ˜ å°„Transformerï¼‰\n- V4 â†’ HybridSensorTransformerï¼ˆæ··åˆæ—¶åº+é™æ€Transformerï¼‰\n\næ‰€æœ‰åŠŸèƒ½å’Œè®­ç»ƒæµç¨‹ä¿æŒä¸å˜ï¼Œä»…æ›´æ–°æ¨¡å‹åç§°ä»¥ä¿æŒä¸€è‡´æ€§ã€‚"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Cell 3: ç®€åŒ–ç‰ˆGradioç•Œé¢ï¼ˆé€‰é¡¹Aï¼‰\n\n**ğŸ”„ æ¨¡å‹å·²æ›´æ–°**: StaticTransformer (åŸV1) + HybridSensorTransformer (åŸV4)\n\nå¦‚æœæ‚¨é€‰æ‹©ä½¿ç”¨ç®€åŒ–ç‰ˆï¼Œè¿è¡Œæ­¤cellã€‚å¦åˆ™è·³åˆ°æœ€åã€‚"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# è¿™æ˜¯ç®€åŒ–ç‰ˆï¼Œå¦‚æœéœ€è¦å®Œæ•´åŠŸèƒ½ï¼Œè¯·ä½¿ç”¨é€‰é¡¹Bï¼ˆåœ¨æœ€åä¸€ä¸ªcellï¼‰\n\n# å…¨å±€çŠ¶æ€\nglobal_state = {\n    'df': None,\n    'trained_models': {},\n    'all_signals': []\n}\n\ndef load_data(file):\n    \"\"\"åŠ è½½æ•°æ®\"\"\"\n    try:\n        if file is None:\n            return \"âŒ è¯·ä¸Šä¼ CSVæ–‡ä»¶\", gr.update(choices=[])\n        \n        df = pd.read_csv(file.name)\n        global_state['df'] = df\n        \n        signals = get_available_signals(df)\n        global_state['all_signals'] = signals\n        \n        msg = f\"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼\\nå½¢çŠ¶: {df.shape}\\nå¯ç”¨ä¿¡å·: {len(signals)}ä¸ª\"\n        return msg, gr.update(choices=signals)\n    except Exception as e:\n        return f\"âŒ åŠ è½½å¤±è´¥: {str(e)}\", gr.update(choices=[])\n\n# åˆ›å»ºç®€åŒ–çš„Gradioç•Œé¢\nwith gr.Blocks(title=\"Industrial Digital Twin\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"# ğŸš€ Industrial Digital Twin by Transformer\")\n    gr.Markdown(\"### ç®€åŒ–ç‰ˆç•Œé¢ - ç”¨äºå¿«é€Ÿæµ‹è¯•\")\n    \n    gr.Markdown(\"\"\"\n    ğŸ’¡ **æç¤º**: è¿™æ˜¯ç®€åŒ–ç‰ˆç•Œé¢ã€‚å¦‚éœ€å®Œæ•´åŠŸèƒ½ï¼ˆStaticTransformer+HybridSensorTransformerè®­ç»ƒã€é…ç½®ç®¡ç†ã€å®Œæ•´æ¨ç†ï¼‰ï¼š\n    1. ä½¿ç”¨ `python gradio_app.py`\n    2. æˆ–åœ¨æœ¬notebookæœ€åç²˜è´´æ‚¨çš„å®Œæ•´Cell 3ä»£ç \n    \"\"\")\n    \n    with gr.Tab(\"ğŸ“Š æ•°æ®åŠ è½½\"):\n        file_input = gr.File(label=\"ä¸Šä¼ CSVæ–‡ä»¶\", file_types=[\".csv\"])\n        load_btn = gr.Button(\"åŠ è½½æ•°æ®\", variant=\"primary\")\n        status_text = gr.Textbox(label=\"çŠ¶æ€\", lines=5)\n        \n        signals_dropdown = gr.Dropdown(\n            choices=[],\n            multiselect=True,\n            label=\"å¯ç”¨ä¿¡å·\",\n            visible=False\n        )\n        \n        load_btn.click(\n            fn=load_data,\n            inputs=[file_input],\n            outputs=[status_text, signals_dropdown]\n        )\n    \n    gr.Markdown(\"\"\"\n    ---\n    ### ğŸ“– ä½¿ç”¨è¯´æ˜\n    \n    **å®Œæ•´åŠŸèƒ½è¯·ä½¿ç”¨**:\n    - `python gradio_app.py` - å‘½ä»¤è¡Œç‰ˆæœ¬\n    - æˆ–åœ¨æœ¬notebookæœ€åçš„cellç²˜è´´å®Œæ•´Cell 3ä»£ç \n    \n    **åŒ…å«çš„å®Œæ•´åŠŸèƒ½**:\n    - âœ… StaticTransformeré™æ€Transformerè®­ç»ƒ\n    - âœ… HybridSensorTransformeræ··åˆæ—¶åº+é™æ€è®­ç»ƒ\n    - âœ… å®æ—¶è®­ç»ƒè¿›åº¦\n    - âœ… é…ç½®å¯¼å…¥/å¯¼å‡º\n    - âœ… å®Œæ•´æ¨ç†å’Œå¯è§†åŒ–\n    \"\"\")\n\nprint(\"âœ… ç®€åŒ–ç‰ˆGradioç•Œé¢å·²å‡†å¤‡å°±ç»ª\")\nprint(\"\\nè¿è¡Œ demo.launch() å¯åŠ¨ç•Œé¢\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: å¯åŠ¨ç®€åŒ–ç‰ˆç•Œé¢ï¼ˆé€‰é¡¹Aï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯åŠ¨ç®€åŒ–ç‰ˆGradioç•Œé¢\n",
    "demo.launch(share=IN_COLAB, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# â­ å®Œæ•´Cell 3ä»£ç å·²é›†æˆ\n\n## ğŸ“‹ æ“ä½œæ­¥éª¤\n\n### âœ… ä»£ç å·²å®Œæ•´é›†æˆ\n\nå®Œæ•´çš„Cell 3ä»£ç å·²ç»ç›´æ¥é›†æˆåˆ°æœ€åçš„cellä¸­ï¼ŒåŒ…å«:\n\n- âœ… å…¨å±€å˜é‡å­˜å‚¨ (`global_state = {...}`)\n- âœ… æ‰€æœ‰è¾…åŠ©å‡½æ•°\n- âœ… æ‰€æœ‰éªŒè¯å‡½æ•° (StaticTransformer/HybridSensorTransformer)\n- âœ… è®­ç»ƒå‡½æ•° (`train_static_transformer_model_complete`, `train_hybrid_sensor_transformer_model_complete`)\n- âœ… é…ç½®å¯¼å…¥å¯¼å‡ºå‡½æ•°\n- âœ… å›è°ƒå‡½æ•°\n- âœ… Gradioç•Œé¢å®šä¹‰ (`with gr.Blocks(...) as demo:`)\n- âœ… äº‹ä»¶ç»‘å®š\n- âœ… `demo.launch()`\n\n### 3. ç›´æ¥è¿è¡Œæœ€åçš„cellå¯åŠ¨å®Œæ•´ç•Œé¢\n\n---\n\n## ğŸ’¡ é‡è¦æ›´æ–°\n\n**ğŸ”„ æ¨¡å‹åç§°å·²å®Œå…¨ç»Ÿä¸€**ï¼š\n- **V1** â†’ **StaticTransformer** (é™æ€ä¼ æ„Ÿå™¨æ˜ å°„Transformer)\n- **V4** â†’ **HybridSensorTransformer** (æ··åˆæ—¶åº+é™æ€Transformer)\n\n**âœ… åŠŸèƒ½å®Œå…¨ä¿æŒä¸å˜**ï¼Œä»…æ›´æ–°å‘½åä»¥ä¿æŒä¸€è‡´æ€§ã€‚\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸš€ è¿è¡Œå®Œæ•´Gradioç•Œé¢\n\n**ç›´æ¥è¿è¡Œä¸‹é¢çš„cellå¯åŠ¨å®Œæ•´çš„Gradioç•Œé¢**ï¼š\n\n### ğŸ¯ åŠŸèƒ½ç‰¹æ€§\n- âœ… **StaticTransformer**: é™æ€ä¼ æ„Ÿå™¨æ˜ å°„Transformerè®­ç»ƒ\n- âœ… **HybridSensorTransformer**: æ··åˆæ—¶åº+é™æ€Transformerè®­ç»ƒ  \n- âœ… **å®æ—¶è®­ç»ƒè¿›åº¦**: æ¯ä¸ªepochçš„è¯¦ç»†æ—¥å¿—æ˜¾ç¤º\n- âœ… **é…ç½®ç®¡ç†**: JSONå¯¼å…¥/å¯¼å‡ºåŠŸèƒ½\n- âœ… **å®Œæ•´æ¨ç†**: å¤šæ¨¡å‹æ¨ç†ã€å¯è§†åŒ–åˆ†æ\n- âœ… **ä¿¡å·éªŒè¯**: è‡ªåŠ¨æ£€æŸ¥ä¿¡å·é€‰æ‹©å†²çª\n- âœ… **é”™è¯¯å¤„ç†**: è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæç¤º\n\n### ğŸ”„ æ¨¡å‹æ›´æ–°\næ‰€æœ‰æ¨¡å‹åç§°å·²ç»Ÿä¸€æ›´æ–°ï¼Œä¸é¡¹ç›®æ–‡ä»¶ä¿æŒä¸€è‡´ï¼š\n- V1 â†’ StaticTransformer\n- V4 â†’ HybridSensorTransformer\n\n**æ— éœ€ä»»ä½•æ‰‹åŠ¨æ“ä½œï¼Œç›´æ¥è¿è¡Œå³å¯ï¼**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# ğŸš€ å®Œæ•´Gradioç•Œé¢ - StaticTransformer + HybridSensorTransformer\n# ============================================================================\n\n# ============================================================================\n# å¯¼å…¥éƒ¨åˆ† - Import Section\n# ============================================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport gradio as gr\nimport json\nimport os\nfrom datetime import datetime\nimport traceback\n\n# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—åŒ–æ¨¡å‹å’Œå·¥å…·\nfrom models.static_transformer import StaticSensorTransformer\nfrom models.hybrid_transformer import HybridSensorTransformer\nfrom models.utils import (\n    create_temporal_context_data,\n    apply_ifd_smoothing,\n    handle_duplicate_columns,\n    get_available_signals,\n    validate_signal_exclusivity_static,\n    validate_signal_exclusivity_hybrid\n)\n\n# è®¾ç½®è®¾å¤‡\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"StaticTransformer & HybridSensorTransformer æ¨¡å‹å·²åŠ è½½ - ä½¿ç”¨è®¾å¤‡: {device}\")\n\n# ============================================================================\n# å…¨å±€çŠ¶æ€å­˜å‚¨ - Global State Storage\n# ============================================================================\n\nglobal_state = {\n    'df': None,\n    'trained_models': {},\n    'scalers': {},\n    'training_history': {},\n    'all_signals': []\n}\n\n# ============================================================================\n# è®­ç»ƒå‡½æ•° - Training Functions\n# ============================================================================\n\ndef train_static_transformer_model_complete(X_train, y_train, X_val, y_val, num_boundary, num_target, config):\n    \"\"\"è®­ç»ƒStaticTransformeræ¨¡å‹ - å®Œæ•´ç‰ˆæœ¬ï¼ˆæ”¯æŒå®æ—¶æ—¥å¿—ï¼‰\"\"\"\n    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n\n    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n\n    model = StaticSensorTransformer(\n        num_boundary_sensors=num_boundary,\n        num_target_sensors=num_target,\n        d_model=config['d_model'],\n        nhead=config['nhead'],\n        num_layers=config['num_layers'],\n        dropout=config['dropout']\n    ).to(device)\n\n    optimizer = optim.AdamW(model.parameters(), lr=config['lr'],\n                           weight_decay=config['weight_decay'])\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        patience=config['scheduler_patience'],\n        factor=config['scheduler_factor']\n    )\n\n    criterion = nn.MSELoss()\n    train_losses = []\n    val_losses = []\n    best_val_loss = float('inf')\n    best_model_state = None\n    patience_counter = 0\n    logs = []\n\n    logs.append(f\"å¼€å§‹è®­ç»ƒStaticTransformeræ¨¡å‹... å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n    logs.append(f\"é…ç½®: LR={config['lr']}, WD={config['weight_decay']}, GradClip={config['grad_clip']}\\\\n\")\n\n    for epoch in range(config['epochs']):\n        # è®­ç»ƒ\n        model.train()\n        train_loss = 0\n        for batch_X, batch_y in train_loader:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['grad_clip'])\n            optimizer.step()\n            train_loss += loss.item()\n        train_loss /= len(train_loader)\n\n        # éªŒè¯\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_y in val_loader:\n                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                predictions = model(batch_X)\n                val_loss += criterion(predictions, batch_y).item()\n        val_loss /= len(val_loader)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n        current_lr = optimizer.param_groups[0]['lr']\n        scheduler.step(val_loss)\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n            status_marker = \"â­\"\n        else:\n            patience_counter += 1\n            status_marker = \"  \"\n\n        log_msg = f\"{status_marker} Epoch [{epoch+1:3d}/{config['epochs']:3d}] | Train: {train_loss:.6f} | Val: {val_loss:.6f} | Best: {best_val_loss:.6f} | LR: {current_lr:.2e} | Patience: {patience_counter}/{config['early_stop_patience']}\"\n        logs.append(log_msg)\n\n        # æ—©åœ\n        if patience_counter >= config['early_stop_patience']:\n            logs.append(f\"\\\\nğŸ›‘ æ—©åœäºç¬¬ {epoch+1} è½® (è€å¿ƒå€¼è¾¾åˆ° {config['early_stop_patience']})\")\n            break\n\n    model.load_state_dict(best_model_state)\n    logs.append(f\"\\\\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}\")\n\n    return model, train_losses, val_losses, logs\n\ndef train_hybrid_sensor_transformer_model_complete(X_train, y_train, X_val, y_val, num_boundary, num_target, config, use_temporal):\n    \"\"\"è®­ç»ƒHybridSensorTransformeræ¨¡å‹ - å®Œæ•´ç‰ˆæœ¬ï¼ˆæ”¯æŒå®æ—¶æ—¥å¿—ï¼‰\"\"\"\n    logs = []\n\n    # å‡†å¤‡æ•°æ®\n    if use_temporal:\n        logs.append(f\"â±ï¸ åˆ›å»ºæ—¶åºä¸Šä¸‹æ–‡æ•°æ® (çª—å£: Â±{config['context_window']})...\")\n        X_train_ctx, y_train_ctx, _ = create_temporal_context_data(X_train, y_train, config['context_window'])\n        X_val_ctx, y_val_ctx, _ = create_temporal_context_data(X_val, y_val, config['context_window'])\n        logs.append(f\"  â€¢ æ—¶åºæ•°æ®: è®­ç»ƒ{X_train_ctx.shape}, éªŒè¯{X_val_ctx.shape}\\\\n\")\n\n        train_dataset = TensorDataset(torch.FloatTensor(X_train_ctx), torch.FloatTensor(y_train_ctx))\n        val_dataset = TensorDataset(torch.FloatTensor(X_val_ctx), torch.FloatTensor(y_val_ctx))\n    else:\n        logs.append(\"ğŸ“ ä½¿ç”¨é™æ€æ˜ å°„æ¨¡å¼...\\\\n\")\n        train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n        val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n\n    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n\n    model = HybridSensorTransformer(\n        num_boundary_sensors=num_boundary,\n        num_target_sensors=num_target,\n        d_model=config['d_model'],\n        nhead=config['nhead'],\n        num_layers=config['num_layers'],\n        dropout=config['dropout'],\n        use_temporal=use_temporal,\n        context_window=config['context_window']\n    ).to(device)\n\n    # æ‰‹åŠ¨åº”ç”¨gainåˆå§‹åŒ–\n    gain_value = config.get('gain', 0.1)\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Linear):\n            if 'head' in name or 'fusion' in name:\n                nn.init.xavier_uniform_(module.weight, gain=gain_value)\n                if module.bias is not None:\n                    nn.init.zeros_(module.bias)\n\n    logs.append(f\"ğŸ—ï¸ HybridSensorTransformeræ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}\")\n    logs.append(f\"âš™ï¸ é…ç½®: Gain={gain_value}, LR={config['lr']}, WD={config['weight_decay']}, GradClip={config['grad_clip']}\\\\n\")\n\n    optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        patience=config['scheduler_patience'],\n        factor=config['scheduler_factor']\n    )\n\n    criterion = nn.MSELoss()\n    train_losses = []\n    val_losses = []\n    best_val_loss = float('inf')\n    best_model_state = None\n    patience_counter = 0\n\n    for epoch in range(config['epochs']):\n        # è®­ç»ƒ\n        model.train()\n        train_loss = 0\n        for batch_X, batch_y in train_loader:\n            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n            optimizer.zero_grad()\n            predictions = model(batch_X)\n            loss = criterion(predictions, batch_y)\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['grad_clip'])\n            optimizer.step()\n            train_loss += loss.item()\n        train_loss /= len(train_loader)\n\n        # éªŒè¯\n        model.eval()\n        val_loss = 0\n        with torch.no_grad():\n            for batch_X, batch_y in val_loader:\n                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n                predictions = model(batch_X)\n                val_loss += criterion(predictions, batch_y).item()\n        val_loss /= len(val_loader)\n\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n\n        current_lr = optimizer.param_groups[0]['lr']\n        scheduler.step(val_loss)\n\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = model.state_dict().copy()\n            patience_counter = 0\n            status_marker = \"â­\"\n        else:\n            patience_counter += 1\n            status_marker = \"  \"\n\n        log_msg = f\"{status_marker} Epoch [{epoch+1:3d}/{config['epochs']:3d}] | Train: {train_loss:.6f} | Val: {val_loss:.6f} | Best: {best_val_loss:.6f} | LR: {current_lr:.2e} | Patience: {patience_counter}/{config['early_stop_patience']}\"\n        logs.append(log_msg)\n\n        # æ—©åœ\n        if patience_counter >= config['early_stop_patience']:\n            logs.append(f\"\\\\nğŸ›‘ æ—©åœäºç¬¬ {epoch+1} è½® (è€å¿ƒå€¼è¾¾åˆ° {config['early_stop_patience']})\")\n            break\n\n    model.load_state_dict(best_model_state)\n    logs.append(f\"\\\\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}\")\n\n    return model, train_losses, val_losses, logs\n\n# ============================================================================\n# é…ç½®å¯¼å…¥å¯¼å‡ºå‡½æ•° - Configuration Import/Export Functions\n# ============================================================================\n\ndef export_config_static_transformer(boundary_signals, target_signals, test_size, val_size,\n                   epochs, batch_size, lr, d_model, nhead, num_layers, dropout,\n                   weight_decay, scheduler_patience, scheduler_factor,\n                   grad_clip, early_stop_patience):\n    \"\"\"å¯¼å‡ºStaticTransformeræ¨¡å‹é…ç½®ä¸ºJSON\"\"\"\n    config = {\n        \"model_type\": \"static_transformer\",\n        \"signals\": {\n            \"boundary\": boundary_signals,\n            \"target\": target_signals\n        },\n        \"data_split\": {\n            \"test_size\": test_size,\n            \"val_size\": val_size\n        },\n        \"training\": {\n            \"epochs\": int(epochs),\n            \"batch_size\": int(batch_size),\n            \"lr\": float(lr),\n            \"weight_decay\": float(weight_decay),\n            \"grad_clip\": float(grad_clip),\n            \"early_stop_patience\": int(early_stop_patience)\n        },\n        \"model_architecture\": {\n            \"d_model\": int(d_model),\n            \"nhead\": int(nhead),\n            \"num_layers\": int(num_layers),\n            \"dropout\": float(dropout)\n        },\n        \"scheduler\": {\n            \"patience\": int(scheduler_patience),\n            \"factor\": float(scheduler_factor)\n        }\n    }\n\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    filename = f\"config_static_transformer_{timestamp}.json\"\n    filepath = os.path.join('.', filename)\n\n    with open(filepath, 'w', encoding='utf-8') as f:\n        json.dump(config, f, indent=2, ensure_ascii=False)\n\n    return filepath, f\"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {filename}\"\n\ndef export_config_hybrid_sensor_transformer(boundary_signals, target_signals, temporal_signals,\n                   test_size, val_size, epochs, batch_size, lr, d_model, nhead,\n                   num_layers, dropout, context_window, apply_smoothing, gain,\n                   weight_decay, scheduler_patience, scheduler_factor,\n                   grad_clip, early_stop_patience):\n    \"\"\"å¯¼å‡ºHybridSensorTransformeræ¨¡å‹é…ç½®ä¸ºJSON\"\"\"\n    config = {\n        \"model_type\": \"HybridSensorTransformer\",\n        \"signals\": {\n            \"boundary\": boundary_signals,\n            \"target\": target_signals,\n            \"temporal\": temporal_signals\n        },\n        \"data_split\": {\n            \"test_size\": test_size,\n            \"val_size\": val_size\n        },\n        \"training\": {\n            \"epochs\": int(epochs),\n            \"batch_size\": int(batch_size),\n            \"lr\": float(lr),\n            \"weight_decay\": float(weight_decay),\n            \"grad_clip\": float(grad_clip),\n            \"early_stop_patience\": int(early_stop_patience)\n        },\n        \"model_architecture\": {\n            \"d_model\": int(d_model),\n            \"nhead\": int(nhead),\n            \"num_layers\": int(num_layers),\n            \"dropout\": float(dropout),\n            \"gain\": float(gain)\n        },\n        \"hybrid_specific\": {\n            \"context_window\": int(context_window),\n            \"apply_smoothing\": bool(apply_smoothing)\n        },\n        \"scheduler\": {\n            \"patience\": int(scheduler_patience),\n            \"factor\": float(scheduler_factor)\n        }\n    }\n\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    filename = f\"config_hybrid_transformer_{timestamp}.json\"\n    filepath = os.path.join('.', filename)\n\n    with open(filepath, 'w', encoding='utf-8') as f:\n        json.dump(config, f, indent=2, ensure_ascii=False)\n\n    return filepath, f\"âœ… é…ç½®å·²å¯¼å‡ºåˆ°: {filename}\"\n\ndef import_config(config_file):\n    \"\"\"å¯¼å…¥é…ç½®æ–‡ä»¶\"\"\"\n    try:\n        with open(config_file.name, 'r', encoding='utf-8') as f:\n            config = json.load(f)\n\n        model_type = config.get('model_type', 'static_transformer')\n\n        if model_type in ['static_transformer', 'StaticTransformer']:\n            return (\n                config['signals']['boundary'],\n                config['signals']['target'],\n                [],  # temporal_signals (StaticTransformerä¸éœ€è¦)\n                config['data_split']['test_size'],\n                config['data_split']['val_size'],\n                config['training']['epochs'],\n                config['training']['batch_size'],\n                config['training']['lr'],\n                config['model_architecture']['d_model'],\n                config['model_architecture']['nhead'],\n                config['model_architecture']['num_layers'],\n                config['model_architecture']['dropout'],\n                5,   # context_window (StaticTransformeré»˜è®¤å€¼)\n                True,  # apply_smoothing (StaticTransformeré»˜è®¤å€¼)\n                0.1,   # gain (StaticTransformeré»˜è®¤å€¼)\n                config['training']['weight_decay'],\n                config['scheduler']['patience'],\n                config['scheduler']['factor'],\n                config['training']['grad_clip'],\n                config['training']['early_stop_patience'],\n                f\"âœ… StaticTransformeré…ç½®åŠ è½½æˆåŠŸï¼\\\\nåŒ…å« {len(config['signals']['boundary'])} ä¸ªè¾¹ç•Œä¿¡å·å’Œ {len(config['signals']['target'])} ä¸ªç›®æ ‡ä¿¡å·\"\n            )\n        else:  # HybridSensorTransformer\n            return (\n                config['signals']['boundary'],\n                config['signals']['target'],\n                config['signals'].get('temporal', []),\n                config['data_split']['test_size'],\n                config['data_split']['val_size'],\n                config['training']['epochs'],\n                config['training']['batch_size'],\n                config['training']['lr'],\n                config['model_architecture']['d_model'],\n                config['model_architecture']['nhead'],\n                config['model_architecture']['num_layers'],\n                config['model_architecture']['dropout'],\n                config['hybrid_specific']['context_window'],\n                config['hybrid_specific']['apply_smoothing'],\n                config['model_architecture']['gain'],\n                config['training']['weight_decay'],\n                config['scheduler']['patience'],\n                config['scheduler']['factor'],\n                config['training']['grad_clip'],\n                config['training']['early_stop_patience'],\n                f\"âœ… HybridSensorTransformeré…ç½®åŠ è½½æˆåŠŸï¼\\\\nåŒ…å« {len(config['signals']['boundary'])} ä¸ªè¾¹ç•Œä¿¡å·, {len(config['signals']['target'])} ä¸ªç›®æ ‡ä¿¡å·, {len(config['signals'].get('temporal', []))} ä¸ªæ—¶åºä¿¡å·\"\n            )\n    except Exception as e:\n        return ([], [], [], 0.2, 0.2, 100, 64, 0.001, 128, 8, 3, 0.1, 5,\n                True, 0.1, 1e-5, 10, 0.5, 1.0, 25,\n                f\"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}\")\n\n# ============================================================================\n# è®­ç»ƒTabå›è°ƒå‡½æ•° - Training Tab Callback Functions\n# ============================================================================\n\ndef on_load_data(dataframe):\n    \"\"\"åŠ è½½æ•°æ®\"\"\"\n    try:\n        # ä¼˜å…ˆä½¿ç”¨å…¨å±€df\n        if 'df' in globals():\n            global_state['df'] = globals()['df'].copy()\n        elif dataframe is not None:\n            global_state['df'] = pd.read_csv(dataframe.name) if hasattr(dataframe, 'name') else dataframe\n        else:\n            return (\"âŒ è¯·ä¸Šä¼ CSVæ–‡ä»¶æˆ–ç¡®ä¿dfå˜é‡å·²åŠ è½½\", \"\",\n                   gr.update(choices=[]), gr.update(choices=[]),\n                   gr.update(choices=[]), gr.update(choices=[]))\n\n        # æ£€æŸ¥å¹¶å¤„ç†é‡å¤åˆ—å\n        original_shape = global_state['df'].shape\n        global_state['df'], duplicates = handle_duplicate_columns(global_state['df'])\n\n        signals = get_available_signals(global_state['df'])\n        global_state['all_signals'] = signals  # ä¿å­˜åˆ°å…¨å±€çŠ¶æ€\n\n        # æ„å»ºçŠ¶æ€æ¶ˆæ¯\n        status_msg = f\"âœ“ æ•°æ®åŠ è½½æˆåŠŸ!\\\\nå½¢çŠ¶: {global_state['df'].shape}\\\\nå¯ç”¨ä¿¡å·: {len(signals)}ä¸ª\"\n\n        if duplicates:\n            status_msg += f\"\\\\n\\\\nâš ï¸ æ£€æµ‹åˆ°é‡å¤åˆ—å (å·²è‡ªåŠ¨å¤„ç†):\"\n            for col, count in list(duplicates.items())[:5]:\n                status_msg += f\"\\\\n â€¢ {col}: å‡ºç° {count+1} æ¬¡\"\n                status_msg += f\" â†’ é‡å‘½åä¸º {col}, {col}_#2\"\n                if count > 1:\n                    status_msg += f\", {col}_#3...\"\n            if len(duplicates) > 5:\n                status_msg += f\"\\\\n   ... è¿˜æœ‰ {len(duplicates)-5} ä¸ªé‡å¤é¡¹\"\n            status_msg += \"\\\\n\\\\nğŸ’¡ æç¤º: å¯ä»¥åœ¨ä¸‹æ–¹ä¿¡å·åˆ—è¡¨ä¸­çœ‹åˆ°æ‰€æœ‰å¯ç”¨ä¿¡å·\"\n\n        # æ„å»ºä¿¡å·åˆ—è¡¨æ˜¾ç¤º\n        signals_display = \"=\" * 60 + \"\\\\n\"\n        signals_display += f\"å¯ç”¨ä¿¡å·æ€»æ•°: {len(signals)}\\\\n\"\n        signals_display += \"=\" * 60 + \"\\\\n\\\\n\"\n        for i, sig in enumerate(signals, 1):\n            signals_display += f\"{i:4d}. {sig}\\\\n\"\n        signals_display += \"\\\\n\" + \"=\" * 60\n\n        return (\n            status_msg,\n            signals_display,\n            gr.update(choices=signals, value=[]),\n            gr.update(choices=signals, value=[]),\n            gr.update(choices=signals, value=[]),\n            gr.update(choices=signals, value=[])\n        )\n    except Exception as e:\n        return (f\"âŒ åŠ è½½å¤±è´¥: {str(e)}\", \"\",\n               gr.update(choices=[]), gr.update(choices=[]),\n               gr.update(choices=[]), gr.update(choices=[]))\n\ndef start_training_static_transformer(boundary_signals, target_signals, test_size, val_size,\n                     epochs, batch_size, lr, d_model, nhead, num_layers, dropout,\n                     weight_decay, scheduler_patience, scheduler_factor,\n                     grad_clip, early_stop_patience):\n    \"\"\"å¼€å§‹è®­ç»ƒStaticTransformeræ¨¡å‹\"\"\"\n    if global_state['df'] is None:\n        yield \"âŒ è¯·å…ˆåŠ è½½æ•°æ®!\"\n        return\n\n    if not boundary_signals:\n        yield \"âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¾¹ç•Œæ¡ä»¶ä¿¡å·!\"\n        return\n\n    if not target_signals:\n        yield \"âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç›®æ ‡ä¿¡å·!\"\n        return\n\n    # éªŒè¯ä¿¡å·äº’æ–¥æ€§\n    is_valid, error_msg = validate_signal_exclusivity_static(boundary_signals, target_signals)\n    if not is_valid:\n        yield error_msg\n        return\n\n    try:\n        log_messages = []\n        log_messages.append(\"=\" * 80)\n        log_messages.append(f\"å¼€å§‹è®­ç»ƒ StaticTransformer æ¨¡å‹\")\n        log_messages.append(\"=\" * 80)\n\n        # å‡†å¤‡æ•°æ®\n        log_messages.append(\"\\\\nğŸ“Š å‡†å¤‡æ•°æ®...\")\n        df = global_state['df']\n        X = df[boundary_signals].values\n        y = df[target_signals].values\n        log_messages.append(f\" â€¢ è¾“å…¥ç‰¹å¾: {len(boundary_signals)}ä¸ª\")\n        log_messages.append(f\" â€¢ è¾“å‡ºç›®æ ‡: {len(target_signals)}ä¸ª\")\n        log_messages.append(f\" â€¢ æ€»æ ·æœ¬æ•°: {len(X):,}\")\n        yield '\\\\n'.join(log_messages)\n\n        # æ ‡å‡†åŒ–\n        scaler_X = StandardScaler()\n        scaler_y = StandardScaler()\n        X_scaled = scaler_X.fit_transform(X)\n        y_scaled = scaler_y.fit_transform(y)\n\n        # åˆ†å‰²æ•°æ®\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_scaled, y_scaled, test_size=test_size, random_state=42\n        )\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train, y_train, test_size=val_size, random_state=42\n        )\n\n        log_messages.append(f\"\\\\nğŸ“‚ æ•°æ®åˆ†å‰²:\")\n        log_messages.append(f\" â€¢ è®­ç»ƒé›†: {len(X_train):,} æ ·æœ¬ ({len(X_train)/len(X)*100:.1f}%)\")\n        log_messages.append(f\" â€¢ éªŒè¯é›†: {len(X_val):,} æ ·æœ¬ ({len(X_val)/len(X)*100:.1f}%)\")\n        log_messages.append(f\" â€¢ æµ‹è¯•é›†: {len(X_test):,} æ ·æœ¬ ({len(X_test)/len(X)*100:.1f}%)\")\n        yield '\\\\n'.join(log_messages)\n\n        # é…ç½®\n        config = {\n            'epochs': int(epochs),\n            'batch_size': int(batch_size),\n            'lr': float(lr),\n            'd_model': int(d_model),\n            'nhead': int(nhead),\n            'num_layers': int(num_layers),\n            'dropout': float(dropout),\n            'weight_decay': float(weight_decay),\n            'scheduler_patience': int(scheduler_patience),\n            'scheduler_factor': float(scheduler_factor),\n            'grad_clip': float(grad_clip),\n            'early_stop_patience': int(early_stop_patience)\n        }\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n        # è®­ç»ƒ - å®æ—¶è¾“å‡º\n        model, train_losses, val_losses, training_logs = train_static_transformer_model_complete(\n            X_train, y_train, X_val, y_val,\n            len(boundary_signals), len(target_signals), config\n        )\n\n        # é€è¡Œè¾“å‡ºè®­ç»ƒæ—¥å¿—\n        for log_line in training_logs:\n            log_messages.append(log_line)\n            yield '\\\\n'.join(log_messages)\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(\"ğŸ§ª è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½...\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n        # æµ‹è¯•é›†è¯„ä¼°\n        model.eval()\n        with torch.no_grad():\n            X_test_tensor = torch.FloatTensor(X_test).to(device)\n            y_pred_scaled = model(X_test_tensor).cpu().numpy()\n            y_pred = scaler_y.inverse_transform(y_pred_scaled)\n            y_true = scaler_y.inverse_transform(y_test)\n\n        # è®¡ç®—æŒ‡æ ‡\n        metrics = {}\n        for i, sensor in enumerate(target_signals):\n            r2 = r2_score(y_true[:, i], y_pred[:, i])\n            rmse = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n            mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n            metrics[sensor] = {'R2': r2, 'RMSE': rmse, 'MAE': mae}\n\n        avg_r2 = np.mean([m['R2'] for m in metrics.values()])\n        avg_rmse = np.mean([m['RMSE'] for m in metrics.values()])\n\n        log_messages.append(f\"\\\\nğŸ“ˆ æµ‹è¯•é›†æ•´ä½“æ€§èƒ½:\")\n        log_messages.append(f\" â€¢ å¹³å‡ RÂ²: {avg_r2:.4f}\")\n        log_messages.append(f\" â€¢ å¹³å‡ RMSE: {avg_rmse:.4f}\")\n\n        # æ˜¾ç¤ºå‰5ä¸ªä¿¡å·çš„è¯¦ç»†æŒ‡æ ‡\n        log_messages.append(f\"\\\\nğŸ“Š å‰5ä¸ªç›®æ ‡ä¿¡å·è¯¦ç»†æŒ‡æ ‡:\")\n        for i, (sensor, metric) in enumerate(list(metrics.items())[:5]):\n            log_messages.append(f\" {i+1}. {sensor[:50]}\")\n            log_messages.append(f\" RÂ²={metric['R2']:.4f}, RMSE={metric['RMSE']:.4f}, MAE={metric['MAE']:.4f}\")\n        if len(metrics) > 5:\n            log_messages.append(f\"   ... è¿˜æœ‰ {len(metrics)-5} ä¸ªä¿¡å·\")\n        yield '\\\\n'.join(log_messages)\n\n        # ä¿å­˜æ¨¡å‹\n        model_name = f\"StaticTransformer_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        global_state['trained_models'][model_name] = {\n            'model': model,\n            'type': 'StaticTransformer',\n            'boundary_signals': boundary_signals,\n            'target_signals': target_signals,\n            'temporal_signals': None,\n            'config': config,\n            'metrics': metrics,\n            'use_temporal': False\n        }\n        global_state['scalers'][model_name] = {'X': scaler_X, 'y': scaler_y}\n        global_state['training_history'][model_name] = {\n            'train_losses': train_losses,\n            'val_losses': val_losses\n        }\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(f\"âœ… è®­ç»ƒå®Œæˆå¹¶ä¿å­˜!\")\n        log_messages.append(f\"ğŸ“¦ æ¨¡å‹åç§°: {model_name}\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n    except Exception as e:\n        error_msg = f\"âŒ è®­ç»ƒå¤±è´¥:\\\\n{str(e)}\\\\n\\\\nè¯¦ç»†é”™è¯¯:\\\\n{traceback.format_exc()}\"\n        yield error_msg\n\ndef start_training_hybrid_sensor_transformer(boundary_signals, target_signals, temporal_signals,\n                     test_size, val_size, epochs, batch_size, lr, d_model, nhead,\n                     num_layers, dropout, context_window, apply_smoothing, gain,\n                     weight_decay, scheduler_patience, scheduler_factor,\n                     grad_clip, early_stop_patience):\n    \"\"\"å¼€å§‹è®­ç»ƒHybridSensorTransformeræ¨¡å‹\"\"\"\n    if global_state['df'] is None:\n        yield \"âŒ è¯·å…ˆåŠ è½½æ•°æ®!\"\n        return\n\n    if not boundary_signals:\n        yield \"âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¾¹ç•Œæ¡ä»¶ä¿¡å·!\"\n        return\n\n    if not target_signals:\n        yield \"âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç›®æ ‡ä¿¡å·!\"\n        return\n\n    # éªŒè¯ä¿¡å·äº’æ–¥æ€§\n    is_valid, error_msg = validate_signal_exclusivity_hybrid(boundary_signals, target_signals, temporal_signals)\n    if not is_valid:\n        yield error_msg\n        return\n\n    try:\n        log_messages = []\n        log_messages.append(\"=\" * 80)\n        log_messages.append(f\"å¼€å§‹è®­ç»ƒ HybridSensorTransformer æ¨¡å‹\")\n        log_messages.append(\"=\" * 80)\n\n        # å‡†å¤‡æ•°æ®\n        log_messages.append(\"\\\\nğŸ“Š å‡†å¤‡æ•°æ®...\")\n        df = global_state['df']\n        X = df[boundary_signals].values\n        y = df[target_signals].values\n        log_messages.append(f\" â€¢ è¾“å…¥ç‰¹å¾: {len(boundary_signals)}ä¸ª\")\n        log_messages.append(f\" â€¢ è¾“å‡ºç›®æ ‡: {len(target_signals)}ä¸ª\")\n        log_messages.append(f\" â€¢ æ€»æ ·æœ¬æ•°: {len(X):,}\")\n        yield '\\\\n'.join(log_messages)\n\n        # HybridSensorTransformerç‰¹å®š: IFDå¹³æ»‘\n        if apply_smoothing and temporal_signals:\n            log_messages.append(f\"\\\\nğŸ”§ åº”ç”¨IFDå¹³æ»‘æ»¤æ³¢åˆ° {len(temporal_signals)} ä¸ªä¿¡å·...\")\n            y = apply_ifd_smoothing(y, target_signals, temporal_signals)\n            yield '\\\\n'.join(log_messages)\n\n        # æ ‡å‡†åŒ–\n        scaler_X = StandardScaler()\n        scaler_y = StandardScaler()\n        X_scaled = scaler_X.fit_transform(X)\n        y_scaled = scaler_y.fit_transform(y)\n\n        # åˆ†å‰²æ•°æ®\n        X_train, X_test, y_train, y_test = train_test_split(\n            X_scaled, y_scaled, test_size=test_size, random_state=42\n        )\n        X_train, X_val, y_train, y_val = train_test_split(\n            X_train, y_train, test_size=val_size, random_state=42\n        )\n\n        log_messages.append(f\"\\\\nğŸ“‚ æ•°æ®åˆ†å‰²:\")\n        log_messages.append(f\" â€¢ è®­ç»ƒé›†: {len(X_train):,} æ ·æœ¬ ({len(X_train)/len(X)*100:.1f}%)\")\n        log_messages.append(f\" â€¢ éªŒè¯é›†: {len(X_val):,} æ ·æœ¬ ({len(X_val)/len(X)*100:.1f}%)\")\n        log_messages.append(f\" â€¢ æµ‹è¯•é›†: {len(X_test):,} æ ·æœ¬ ({len(X_test)/len(X)*100:.1f}%)\")\n        yield '\\\\n'.join(log_messages)\n\n        # é…ç½®\n        config = {\n            'epochs': int(epochs),\n            'batch_size': int(batch_size),\n            'lr': float(lr),\n            'd_model': int(d_model),\n            'nhead': int(nhead),\n            'num_layers': int(num_layers),\n            'dropout': float(dropout),\n            'context_window': int(context_window),\n            'gain': float(gain),\n            'weight_decay': float(weight_decay),\n            'scheduler_patience': int(scheduler_patience),\n            'scheduler_factor': float(scheduler_factor),\n            'grad_clip': float(grad_clip),\n            'early_stop_patience': int(early_stop_patience)\n        }\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(\"ğŸš€ å¼€å§‹è®­ç»ƒ...\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n        # è®­ç»ƒ - å®æ—¶è¾“å‡º\n        use_temporal = len(temporal_signals) > 0 if temporal_signals else False\n        model, train_losses, val_losses, training_logs = train_hybrid_sensor_transformer_model_complete(\n            X_train, y_train, X_val, y_val,\n            len(boundary_signals), len(target_signals),\n            config, use_temporal\n        )\n\n        # é€è¡Œè¾“å‡ºè®­ç»ƒæ—¥å¿—\n        for log_line in training_logs:\n            log_messages.append(log_line)\n            yield '\\\\n'.join(log_messages)\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(\"ğŸ§ª è¯„ä¼°æµ‹è¯•é›†æ€§èƒ½...\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n        # æµ‹è¯•é›†è¯„ä¼°\n        model.eval()\n        with torch.no_grad():\n            if use_temporal:\n                X_test_ctx, y_test_ctx, _ = create_temporal_context_data(\n                    X_test, y_test, context_window\n                )\n                X_test_tensor = torch.FloatTensor(X_test_ctx).to(device)\n                y_pred_scaled = model(X_test_tensor).cpu().numpy()\n                y_test_eval = y_test_ctx\n            else:\n                X_test_tensor = torch.FloatTensor(X_test).to(device)\n                y_pred_scaled = model(X_test_tensor).cpu().numpy()\n                y_test_eval = y_test\n\n            y_pred = scaler_y.inverse_transform(y_pred_scaled)\n            y_true = scaler_y.inverse_transform(y_test_eval)\n\n        # è®¡ç®—æŒ‡æ ‡\n        metrics = {}\n        for i, sensor in enumerate(target_signals):\n            r2 = r2_score(y_true[:, i], y_pred[:, i])\n            rmse = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))\n            mae = mean_absolute_error(y_true[:, i], y_pred[:, i])\n            metrics[sensor] = {'R2': r2, 'RMSE': rmse, 'MAE': mae}\n\n        avg_r2 = np.mean([m['R2'] for m in metrics.values()])\n        avg_rmse = np.mean([m['RMSE'] for m in metrics.values()])\n\n        log_messages.append(f\"\\\\nğŸ“ˆ æµ‹è¯•é›†æ•´ä½“æ€§èƒ½:\")\n        log_messages.append(f\" â€¢ å¹³å‡ RÂ²: {avg_r2:.4f}\")\n        log_messages.append(f\" â€¢ å¹³å‡ RMSE: {avg_rmse:.4f}\")\n\n        # æ˜¾ç¤ºå‰5ä¸ªä¿¡å·çš„è¯¦ç»†æŒ‡æ ‡\n        log_messages.append(f\"\\\\nğŸ“Š å‰5ä¸ªç›®æ ‡ä¿¡å·è¯¦ç»†æŒ‡æ ‡:\")\n        for i, (sensor, metric) in enumerate(list(metrics.items())[:5]):\n            log_messages.append(f\" {i+1}. {sensor[:50]}\")\n            log_messages.append(f\" RÂ²={metric['R2']:.4f}, RMSE={metric['RMSE']:.4f}, MAE={metric['MAE']:.4f}\")\n        if len(metrics) > 5:\n            log_messages.append(f\"   ... è¿˜æœ‰ {len(metrics)-5} ä¸ªä¿¡å·\")\n        yield '\\\\n'.join(log_messages)\n\n        # ä¿å­˜æ¨¡å‹\n        model_name = f\"HybridSensorTransformer_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n        global_state['trained_models'][model_name] = {\n            'model': model,\n            'type': 'HybridSensorTransformer',\n            'boundary_signals': boundary_signals,\n            'target_signals': target_signals,\n            'temporal_signals': temporal_signals,\n            'config': config,\n            'metrics': metrics,\n            'use_temporal': use_temporal\n        }\n        global_state['scalers'][model_name] = {'X': scaler_X, 'y': scaler_y}\n        global_state['training_history'][model_name] = {\n            'train_losses': train_losses,\n            'val_losses': val_losses\n        }\n\n        log_messages.append(\"\\\\n\" + \"=\" * 80)\n        log_messages.append(f\"âœ… è®­ç»ƒå®Œæˆå¹¶ä¿å­˜!\")\n        log_messages.append(f\"ğŸ“¦ æ¨¡å‹åç§°: {model_name}\")\n        log_messages.append(\"=\" * 80)\n        yield '\\\\n'.join(log_messages)\n\n    except Exception as e:\n        error_msg = f\"âŒ è®­ç»ƒå¤±è´¥:\\\\n{str(e)}\\\\n\\\\nè¯¦ç»†é”™è¯¯:\\\\n{traceback.format_exc()}\"\n        yield error_msg\n\n# ============================================================================\n# æ¨ç†Tabå›è°ƒå‡½æ•° - Inference Tab Callback Functions\n# ============================================================================\n\ndef get_model_list():\n    \"\"\"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨\"\"\"\n    return list(global_state['trained_models'].keys())\n\ndef on_model_load(model_name):\n    \"\"\"åŠ è½½æ¨¡å‹\"\"\"\n    if not model_name or model_name not in global_state['trained_models']:\n        return \"è¯·é€‰æ‹©æœ‰æ•ˆçš„æ¨¡å‹\", gr.update(choices=[])\n\n    model_info = global_state['trained_models'][model_name]\n    target_signals = model_info['target_signals']\n    metrics = model_info['metrics']\n    avg_r2 = np.mean([m['R2'] for m in metrics.values()])\n\n    info_lines = [\n        \"=\" * 60,\n        \"æ¨¡å‹ä¿¡æ¯\",\n        \"=\" * 60,\n        f\"æ¨¡å‹ç±»å‹: {model_info['type']}\",\n        f\"è¾¹ç•Œä¿¡å·æ•°: {len(model_info['boundary_signals'])}\",\n        f\"ç›®æ ‡ä¿¡å·æ•°: {len(model_info['target_signals'])}\",\n        f\"å¹³å‡RÂ²: {avg_r2:.4f}\",\n        \"\"\n    ]\n\n    if model_info['type'] == 'HybridSensorTransformer':\n        info_lines.append(f\"æ—¶åºæ¨¡å¼: {'æ˜¯' if model_info.get('use_temporal', False) else 'å¦'}\")\n        if model_info.get('temporal_signals'):\n            info_lines.append(f\"æ—¶åºä¿¡å·æ•°: {len(model_info['temporal_signals'])}\")\n\n    info_lines.append(\"\")\n    info_lines.append(\"ç›®æ ‡ä¿¡å·åˆ—è¡¨:\")\n    for i, s in enumerate(target_signals[:10]):\n        r2 = metrics[s]['R2']\n        info_lines.append(f\" {i+1:2d}. {s[:50]} (RÂ²={r2:.3f})\")\n    if len(target_signals) > 10:\n        info_lines.append(f\"   ... è¿˜æœ‰ {len(target_signals)-10} ä¸ªä¿¡å·\")\n    info_lines.append(\"=\" * 60)\n\n    return '\\\\n'.join(info_lines), gr.update(choices=target_signals, value=[])\n\ndef run_inference(model_name, start_idx, end_idx, selected_signals):\n    \"\"\"è¿è¡Œæ¨ç†\"\"\"\n    if not model_name or model_name not in global_state['trained_models']:\n        return \"âŒ è¯·å…ˆåŠ è½½æ¨¡å‹\", None, \"\"\n\n    if global_state['df'] is None:\n        return \"âŒ æ•°æ®æœªåŠ è½½\", None, \"\"\n\n    if not selected_signals:\n        return \"âŒ è¯·é€‰æ‹©è¦å¯è§†åŒ–çš„ä¿¡å·\", None, \"\"\n\n    try:\n        # è·å–æ¨¡å‹å’Œé…ç½®\n        model_info = global_state['trained_models'][model_name]\n        model = model_info['model']\n        model_type = model_info['type']\n        boundary_signals = model_info['boundary_signals']\n        target_signals = model_info['target_signals']\n        config = model_info['config']\n        scalers = global_state['scalers'][model_name]\n        scaler_X = scalers['X']\n        scaler_y = scalers['y']\n\n        # å‡†å¤‡æ•°æ®\n        df = global_state['df']\n\n        # å¤„ç†ç´¢å¼•èŒƒå›´\n        start_idx = int(start_idx)\n        end_idx = int(end_idx)\n\n        if start_idx < 0:\n            start_idx = 0\n        if end_idx > len(df):\n            end_idx = len(df)\n        if end_idx <= start_idx:\n            end_idx = min(start_idx + 1000, len(df))\n\n        df_slice = df.iloc[start_idx:end_idx]\n        X = df_slice[boundary_signals].values\n        y = df_slice[target_signals].values\n        X_scaled = scaler_X.transform(X)\n\n        # æ¨ç†\n        model.eval()\n        with torch.no_grad():\n            if model_type == \"HybridSensorTransformer\" and model_info.get('use_temporal', False):\n                context_window = config['context_window']\n                if len(X_scaled) < 2 * context_window + 1:\n                    return f\"âŒ æ•°æ®æ®µå¤ªçŸ­ï¼Œéœ€è¦è‡³å°‘ {2*context_window+1} ä¸ªæ ·æœ¬\", None, \"\"\n\n                X_ctx, _, valid_indices = create_temporal_context_data(\n                    X_scaled,\n                    np.zeros((len(X_scaled), len(target_signals))),\n                    context_window\n                )\n                X_tensor = torch.FloatTensor(X_ctx).to(device)\n                y_pred_scaled = model(X_tensor).cpu().numpy()\n\n                # è°ƒæ•´yåˆ°æœ‰æ•ˆç´¢å¼•\n                y = y[valid_indices]\n                actual_indices = np.array(valid_indices) + start_idx\n            else:\n                X_tensor = torch.FloatTensor(X_scaled).to(device)\n                y_pred_scaled = model(X_tensor).cpu().numpy()\n                actual_indices = np.arange(start_idx, end_idx)\n\n        y_pred = scaler_y.inverse_transform(y_pred_scaled)\n\n        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡\n        metrics_lines = [\"=\" * 60, \"è¯„ä¼°æŒ‡æ ‡\", \"=\" * 60, \"\"]\n        for signal in selected_signals:\n            if signal not in target_signals:\n                continue\n\n            idx = target_signals.index(signal)\n            y_true_signal = y[:, idx]\n            y_pred_signal = y_pred[:, idx]\n            residuals = y_true_signal - y_pred_signal\n\n            r2 = r2_score(y_true_signal, y_pred_signal)\n            rmse = np.sqrt(mean_squared_error(y_true_signal, y_pred_signal))\n            mae = mean_absolute_error(y_true_signal, y_pred_signal)\n\n            metrics_lines.append(f\"{signal}:\")\n            metrics_lines.append(f\" RÂ² Score: {r2:.4f}\")\n            metrics_lines.append(f\" RMSE: {rmse:.4f}\")\n            metrics_lines.append(f\" MAE: {mae:.4f}\")\n            metrics_lines.append(f\" æ®‹å·®å‡å€¼: {np.mean(residuals):.4f}\")\n            metrics_lines.append(f\" æ®‹å·®æ ‡å‡†å·®: {np.std(residuals):.4f}\")\n            metrics_lines.append(f\" æ®‹å·®èŒƒå›´: [{np.min(residuals):.4f}, {np.max(residuals):.4f}]\")\n            metrics_lines.append(\"\")\n\n        metrics_lines.append(\"=\" * 60)\n\n        # å¯è§†åŒ–\n        n_signals = len(selected_signals)\n        fig = plt.figure(figsize=(18, 5*n_signals))\n\n        for i, signal in enumerate(selected_signals):\n            if signal not in target_signals:\n                continue\n\n            idx = target_signals.index(signal)\n            y_true_signal = y[:, idx]\n            y_pred_signal = y_pred[:, idx]\n            residuals = y_true_signal - y_pred_signal\n\n            # é¢„æµ‹ vs å®é™…\n            ax1 = plt.subplot(n_signals, 3, i*3 + 1)\n            ax1.plot(actual_indices[:len(y_true_signal)], y_true_signal,\n                    label='å®é™…å€¼', linewidth=2, alpha=0.8, color='#2c3e50')\n            ax1.plot(actual_indices[:len(y_pred_signal)], y_pred_signal,\n                    label='é¢„æµ‹å€¼', linewidth=2, alpha=0.8, color='#3498db')\n            ax1.set_title(f'{signal}\\\\né¢„æµ‹ vs å®é™…', fontsize=11, fontweight='bold')\n            ax1.set_xlabel('æ•°æ®ç´¢å¼•', fontsize=10)\n            ax1.set_ylabel('å€¼', fontsize=10)\n            ax1.legend(fontsize=9)\n            ax1.grid(True, alpha=0.3)\n\n            # æ®‹å·®å›¾\n            ax2 = plt.subplot(n_signals, 3, i*3 + 2)\n            ax2.plot(actual_indices[:len(residuals)], residuals,\n                    color='#e74c3c', linewidth=1.5, alpha=0.7)\n            ax2.axhline(y=0, color='black', linestyle='--', linewidth=2)\n            ax2.fill_between(actual_indices[:len(residuals)], residuals,\n                            alpha=0.3, color='#e74c3c')\n            ax2.set_title(f'{signal}\\\\næ®‹å·®åˆ†æ', fontsize=11, fontweight='bold')\n            ax2.set_xlabel('æ•°æ®ç´¢å¼•', fontsize=10)\n            ax2.set_ylabel('æ®‹å·® (å®é™… - é¢„æµ‹)', fontsize=10)\n            ax2.grid(True, alpha=0.3)\n\n            # æ•£ç‚¹å›¾\n            ax3 = plt.subplot(n_signals, 3, i*3 + 3)\n            ax3.scatter(y_true_signal, y_pred_signal, alpha=0.6, s=20, color='#3498db')\n            min_val = min(y_true_signal.min(), y_pred_signal.min())\n            max_val = max(y_true_signal.max(), y_pred_signal.max())\n            ax3.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='å®Œç¾é¢„æµ‹')\n            r2 = r2_score(y_true_signal, y_pred_signal)\n            ax3.set_title(f'{signal}\\\\né¢„æµ‹ç²¾åº¦ (RÂ²={r2:.3f})', fontsize=11, fontweight='bold')\n            ax3.set_xlabel('å®é™…å€¼', fontsize=10)\n            ax3.set_ylabel('é¢„æµ‹å€¼', fontsize=10)\n            ax3.legend(fontsize=9)\n            ax3.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n\n        status_msg = f\"âœ… æ¨ç†å®Œæˆ!\\\\nåˆ†æèŒƒå›´: index {start_idx} åˆ° {end_idx}\\\\nå®é™…åˆ†ææ ·æœ¬æ•°: {len(y_true_signal)}\"\n\n        return status_msg, fig, '\\\\n'.join(metrics_lines)\n\n    except Exception as e:\n        error_msg = f\"âŒ æ¨ç†å¤±è´¥:\\\\n{str(e)}\\\\n\\\\nè¯¦ç»†é”™è¯¯:\\\\n{traceback.format_exc()}\"\n        return error_msg, None, \"\"\n\n# ============================================================================\n# åˆ›å»ºGradioç•Œé¢ - Create Gradio Interface\n# ============================================================================\n\nwith gr.Blocks(title=\"ä¼ æ„Ÿå™¨é¢„æµ‹æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ç³»ç»Ÿ\", theme=gr.themes.Soft()) as demo:\n    gr.Markdown(\"# ğŸš€ ä¼ æ„Ÿå™¨é¢„æµ‹æ¨¡å‹è®­ç»ƒå’Œæ¨ç†ç³»ç»Ÿ\")\n    gr.Markdown(\"### æ”¯æŒStaticTransformer (é™æ€æ˜ å°„) å’Œ HybridSensorTransformer (æ··åˆæ—¶åº+é™æ€) æ¨¡å‹\")\n\n    with gr.Tabs():\n        # ========== æ•°æ®åŠ è½½Tab ==========\n        with gr.Tab(\"ğŸ“Š æ•°æ®åŠ è½½\"):\n            gr.Markdown(\"### åŠ è½½è®­ç»ƒæ•°æ®\")\n            with gr.Row():\n                with gr.Column(scale=1):\n                    data_file = gr.File(label=\"ä¸Šä¼ CSVæ–‡ä»¶ (å¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨å…¨å±€df)\", file_types=[\".csv\"])\n                    load_data_btn = gr.Button(\"ğŸ“¥ åŠ è½½æ•°æ®\", variant=\"primary\", size=\"lg\")\n                    data_status = gr.Textbox(label=\"æ•°æ®çŠ¶æ€\", lines=10)\n\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ“‹ å¯ç”¨ä¿¡å·åˆ—è¡¨\")\n                    gr.Markdown(\"æ•°æ®åŠ è½½åï¼Œä»¥ä¸‹æ‰€æœ‰ä¿¡å·å¯ç”¨äºè®­ç»ƒ\")\n                    signals_list_display = gr.Textbox(\n                        label=\"ä¿¡å·åˆ—è¡¨\",\n                        lines=25,\n                        placeholder=\"åŠ è½½æ•°æ®åæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨ä¿¡å·...\",\n                        interactive=False\n                    )\n\n        # ========== StaticTransformerè®­ç»ƒTab ==========\n        with gr.Tab(\"ğŸ¯ StaticTransformerè®­ç»ƒ\"):\n            gr.Markdown(\"## StaticTransformer: é™æ€ä¼ æ„Ÿå™¨æ˜ å°„ Transformer\")\n\n            with gr.Row():\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ“‹ é…ç½®ç®¡ç†\")\n                    config_file_static = gr.File(label=\"å¯¼å…¥é…ç½®æ–‡ä»¶\", file_types=[\".json\"])\n                    import_config_btn_static = gr.Button(\"ğŸ“‚ å¯¼å…¥é…ç½®\", variant=\"secondary\")\n                    export_config_btn_static = gr.Button(\"ğŸ’¾ å¯¼å‡ºé…ç½®\", variant=\"secondary\")\n                    config_status_static = gr.Textbox(label=\"é…ç½®çŠ¶æ€\", lines=3)\n                    config_download_static = gr.File(label=\"ä¸‹è½½é…ç½®æ–‡ä»¶\", visible=False)\n\n                    gr.Markdown(\"### ğŸ›ï¸ ä¿¡å·é€‰æ‹©\")\n                    gr.Markdown(\"âš ï¸ **æ³¨æ„**: è¾¹ç•Œä¿¡å·å’Œç›®æ ‡ä¿¡å·ä¸èƒ½é‡å¤ï¼Œè®­ç»ƒå‰ä¼šè‡ªåŠ¨éªŒè¯\")\n\n                    boundary_signals_static = gr.Dropdown(\n                        choices=[],\n                        multiselect=True,\n                        label=\"è¾¹ç•Œæ¡ä»¶ä¿¡å· (è¾“å…¥)\",\n                        info=\"é€‰æ‹©ç”¨äºé¢„æµ‹çš„è¾“å…¥ä¿¡å·\"\n                    )\n\n                    target_signals_static = gr.Dropdown(\n                        choices=[],\n                        multiselect=True,\n                        label=\"ç›®æ ‡ä¿¡å· (è¾“å‡º)\",\n                        info=\"é€‰æ‹©è¦é¢„æµ‹çš„ä¿¡å·\"\n                    )\n\n                    gr.Markdown(\"### âš™ï¸ æ•°æ®åˆ†å‰²\")\n                    with gr.Row():\n                        test_size_static = gr.Slider(0.1, 0.4, value=0.2, step=0.05, label=\"æµ‹è¯•é›†æ¯”ä¾‹\")\n                        val_size_static = gr.Slider(0.1, 0.3, value=0.2, step=0.05, label=\"éªŒè¯é›†æ¯”ä¾‹\")\n\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ”§ è®­ç»ƒå‚æ•°\")\n                    with gr.Row():\n                        epochs_static = gr.Slider(1, 200, value=100, step=1, label=\"è®­ç»ƒè½®æ•°\")\n                        batch_size_static = gr.Slider(16, 256, value=64, step=16, label=\"æ‰¹å¤§å°\")\n\n                    with gr.Row():\n                        lr_static = gr.Number(value=0.001, label=\"å­¦ä¹ ç‡\")\n                        weight_decay_static = gr.Number(value=1e-5, label=\"æƒé‡è¡°å‡\", precision=6)\n\n                    gr.Markdown(\"### ğŸ—ï¸ æ¨¡å‹æ¶æ„\")\n                    with gr.Row():\n                        d_model_static = gr.Slider(32, 256, value=128, step=32, label=\"æ¨¡å‹ç»´åº¦\")\n                        nhead_static = gr.Slider(2, 16, value=8, step=2, label=\"æ³¨æ„åŠ›å¤´æ•°\")\n\n                    with gr.Row():\n                        num_layers_static = gr.Slider(1, 6, value=3, step=1, label=\"Transformerå±‚æ•°\")\n                        dropout_static = gr.Slider(0.0, 0.5, value=0.1, step=0.05, label=\"Dropout\")\n\n                    gr.Markdown(\"### ğŸ“ˆ ä¼˜åŒ–å™¨å‚æ•°\")\n                    with gr.Row():\n                        scheduler_patience_static = gr.Slider(5, 20, value=10, step=1, label=\"å­¦ä¹ ç‡è°ƒåº¦è€å¿ƒ\")\n                        scheduler_factor_static = gr.Slider(0.1, 0.9, value=0.5, step=0.1, label=\"å­¦ä¹ ç‡è¡°å‡å› å­\")\n\n                    with gr.Row():\n                        grad_clip_static = gr.Slider(0.5, 5.0, value=1.0, step=0.1, label=\"æ¢¯åº¦è£å‰ªé˜ˆå€¼\")\n                        early_stop_patience_static = gr.Slider(10, 50, value=25, step=5, label=\"æ—©åœè€å¿ƒ\")\n\n                    gr.Markdown(\"### ğŸš€ å¼€å§‹è®­ç»ƒ\")\n                    train_btn_static = gr.Button(\"â–¶ï¸ å¼€å§‹è®­ç»ƒ StaticTransformer æ¨¡å‹\", variant=\"primary\", size=\"lg\")\n                    training_log_static = gr.Textbox(label=\"è®­ç»ƒæ—¥å¿—\", lines=30, max_lines=50, autoscroll=True)\n\n        # ========== HybridSensorTransformerè®­ç»ƒTab ==========\n        with gr.Tab(\"ğŸ¯ HybridSensorTransformerè®­ç»ƒ\"):\n            gr.Markdown(\"## HybridSensorTransformer: æ··åˆæ—¶åº+é™æ€ Transformer\")\n\n            with gr.Row():\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ“‹ é…ç½®ç®¡ç†\")\n                    config_file_hybrid = gr.File(label=\"å¯¼å…¥é…ç½®æ–‡ä»¶\", file_types=[\".json\"])\n                    import_config_btn_hybrid = gr.Button(\"ğŸ“‚ å¯¼å…¥é…ç½®\", variant=\"secondary\")\n                    export_config_btn_hybrid = gr.Button(\"ğŸ’¾ å¯¼å‡ºé…ç½®\", variant=\"secondary\")\n                    config_status_hybrid = gr.Textbox(label=\"é…ç½®çŠ¶æ€\", lines=3)\n                    config_download_hybrid = gr.File(label=\"ä¸‹è½½é…ç½®æ–‡ä»¶\", visible=False)\n\n                    gr.Markdown(\"### ğŸ›ï¸ ä¿¡å·é€‰æ‹©\")\n                    gr.Markdown(\"âš ï¸ **æ³¨æ„**: è¾¹ç•Œä¿¡å·å’Œç›®æ ‡ä¿¡å·ä¸èƒ½é‡å¤ï¼›æ—¶åºä¿¡å·å¿…é¡»æ˜¯ç›®æ ‡ä¿¡å·çš„å­é›†ï¼Œè®­ç»ƒå‰ä¼šè‡ªåŠ¨éªŒè¯\")\n\n                    boundary_signals_hybrid = gr.Dropdown(\n                        choices=[],\n                        multiselect=True,\n                        label=\"è¾¹ç•Œæ¡ä»¶ä¿¡å· (è¾“å…¥)\",\n                        info=\"é€‰æ‹©ç”¨äºé¢„æµ‹çš„è¾“å…¥ä¿¡å·\"\n                    )\n\n                    target_signals_hybrid = gr.Dropdown(\n                        choices=[],\n                        multiselect=True,\n                        label=\"ç›®æ ‡ä¿¡å· (è¾“å‡º)\",\n                        info=\"é€‰æ‹©è¦é¢„æµ‹çš„ä¿¡å·\"\n                    )\n\n                    gr.Markdown(\"### â±ï¸ æ—¶åºé€‰é¡¹\")\n                    gr.Markdown(\"ğŸ’¡ æ—¶åºä¿¡å·å¿…é¡»ä»ç›®æ ‡ä¿¡å·ä¸­é€‰æ‹©\")\n                    with gr.Row():\n                        temporal_signals_hybrid = gr.Dropdown(\n                            choices=[],\n                            multiselect=True,\n                            label=\"æ—¶åºæ¨¡å¼ä¿¡å·\",\n                            info=\"ä»ç›®æ ‡ä¿¡å·ä¸­é€‰æ‹©éœ€è¦æ—¶åºä¸Šä¸‹æ–‡çš„ä¿¡å· (ç•™ç©ºåˆ™å…¨éƒ¨ä½¿ç”¨é™æ€æ¨¡å¼)\"\n                        )\n                        sync_temporal_btn_hybrid = gr.Button(\"ğŸ”„ åŒæ­¥ç›®æ ‡ä¿¡å·\", size=\"sm\", scale=0)\n                        context_window_hybrid = gr.Slider(1, 10, value=5, step=1, label=\"ä¸Šä¸‹æ–‡çª—å£å¤§å°\")\n                        apply_smoothing_hybrid = gr.Checkbox(label=\"åº”ç”¨IFDå¹³æ»‘æ»¤æ³¢\", value=True)\n\n                    gr.Markdown(\"### âš™ï¸ æ•°æ®åˆ†å‰²\")\n                    with gr.Row():\n                        test_size_hybrid = gr.Slider(0.1, 0.4, value=0.2, step=0.05, label=\"æµ‹è¯•é›†æ¯”ä¾‹\")\n                        val_size_hybrid = gr.Slider(0.1, 0.3, value=0.2, step=0.05, label=\"éªŒè¯é›†æ¯”ä¾‹\")\n\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### ğŸ”§ è®­ç»ƒå‚æ•°\")\n                    with gr.Row():\n                        epochs_hybrid = gr.Slider(1, 200, value=100, step=1, label=\"è®­ç»ƒè½®æ•°\")\n                        batch_size_hybrid = gr.Slider(16, 256, value=64, step=16, label=\"æ‰¹å¤§å°\")\n\n                    with gr.Row():\n                        lr_hybrid = gr.Number(value=0.001, label=\"å­¦ä¹ ç‡\")\n                        weight_decay_hybrid = gr.Number(value=1e-5, label=\"æƒé‡è¡°å‡\", precision=6)\n\n                    gr.Markdown(\"### ğŸ—ï¸ æ¨¡å‹æ¶æ„\")\n                    with gr.Row():\n                        d_model_hybrid = gr.Slider(32, 256, value=64, step=32, label=\"æ¨¡å‹ç»´åº¦\")\n                        nhead_hybrid = gr.Slider(2, 16, value=4, step=2, label=\"æ³¨æ„åŠ›å¤´æ•°\")\n\n                    with gr.Row():\n                        num_layers_hybrid = gr.Slider(1, 6, value=2, step=1, label=\"Transformerå±‚æ•°\")\n                        dropout_hybrid = gr.Slider(0.0, 0.5, value=0.1, step=0.05, label=\"Dropout\")\n\n                    with gr.Row():\n                        gain_hybrid = gr.Slider(0.01, 1.0, value=0.1, step=0.01, label=\"æƒé‡åˆå§‹åŒ–Gain\")\n\n                    gr.Markdown(\"### ğŸ“ˆ ä¼˜åŒ–å™¨å‚æ•°\")\n                    with gr.Row():\n                        scheduler_patience_hybrid = gr.Slider(5, 20, value=10, step=1, label=\"å­¦ä¹ ç‡è°ƒåº¦è€å¿ƒ\")\n                        scheduler_factor_hybrid = gr.Slider(0.1, 0.9, value=0.5, step=0.1, label=\"å­¦ä¹ ç‡è¡°å‡å› å­\")\n\n                    with gr.Row():\n                        grad_clip_hybrid = gr.Slider(0.5, 5.0, value=1.0, step=0.1, label=\"æ¢¯åº¦è£å‰ªé˜ˆå€¼\")\n                        early_stop_patience_hybrid = gr.Slider(10, 50, value=25, step=5, label=\"æ—©åœè€å¿ƒ\")\n\n                    gr.Markdown(\"### ğŸš€ å¼€å§‹è®­ç»ƒ\")\n                    train_btn_hybrid = gr.Button(\"â–¶ï¸ å¼€å§‹è®­ç»ƒ HybridSensorTransformer æ¨¡å‹\", variant=\"primary\", size=\"lg\")\n                    training_log_hybrid = gr.Textbox(label=\"è®­ç»ƒæ—¥å¿—\", lines=30, max_lines=50, autoscroll=True)\n\n        # ========== æ¨ç†Tab ==========\n        with gr.Tab(\"ğŸ”® æ¨¡å‹æ¨ç†\"):\n            with gr.Row():\n                with gr.Column(scale=1):\n                    gr.Markdown(\"### 1ï¸âƒ£ é€‰æ‹©æ¨¡å‹\")\n                    model_selector = gr.Dropdown(\n                        choices=[],\n                        label=\"å·²è®­ç»ƒæ¨¡å‹\",\n                        info=\"é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹\"\n                    )\n                    refresh_models_btn = gr.Button(\"ğŸ”„ åˆ·æ–°æ¨¡å‹åˆ—è¡¨\")\n                    load_model_btn = gr.Button(\"ğŸ“‚ åŠ è½½æ¨¡å‹\", variant=\"primary\")\n                    model_info = gr.Textbox(label=\"æ¨¡å‹ä¿¡æ¯\", lines=15)\n\n                    gr.Markdown(\"### 2ï¸âƒ£ æ¨ç†è®¾ç½®\")\n                    with gr.Row():\n                        start_idx = gr.Number(value=0, label=\"èµ·å§‹ç´¢å¼•\", precision=0)\n                        end_idx = gr.Number(value=1000, label=\"ç»“æŸç´¢å¼•\", precision=0)\n\n                    inference_signals = gr.Dropdown(\n                        choices=[],\n                        multiselect=True,\n                        label=\"é€‰æ‹©å¯è§†åŒ–ä¿¡å·\",\n                        info=\"é€‰æ‹©è¦åˆ†æçš„ç›®æ ‡ä¿¡å·ï¼ˆæœ€å¤š5ä¸ªï¼‰\"\n                    )\n\n                    inference_btn = gr.Button(\"â–¶ï¸ è¿è¡Œæ¨ç†\", variant=\"primary\", size=\"lg\")\n                    inference_status = gr.Textbox(label=\"æ¨ç†çŠ¶æ€\", lines=3)\n\n                with gr.Column(scale=2):\n                    gr.Markdown(\"### 3ï¸âƒ£ æ¨ç†ç»“æœ\")\n                    inference_plot = gr.Plot(label=\"å¯è§†åŒ–ç»“æœ\")\n                    with gr.Row():\n                        metrics_output = gr.Textbox(label=\"è¯„ä¼°æŒ‡æ ‡\", lines=20)\n\n            gr.Markdown(\"\"\"\n---\n### ğŸ“– ä½¿ç”¨è¯´æ˜\n\n**æ•°æ®åŠ è½½:**\n1. åœ¨\"æ•°æ®åŠ è½½\"Tabä¸Šä¼ CSVæ–‡ä»¶æˆ–ä½¿ç”¨å…¨å±€dfå˜é‡\n2. ç‚¹å‡»\"åŠ è½½æ•°æ®\"æŒ‰é’®\n3. åœ¨å³ä¾§å¯ä»¥çœ‹åˆ°æ‰€æœ‰å¯ç”¨ä¿¡å·çš„å®Œæ•´åˆ—è¡¨\n\n**ä¿¡å·é€‰æ‹©è§„åˆ™:**\n- **StaticTransformeræ¨¡å‹**: è¾¹ç•Œæ¡ä»¶ä¿¡å·å’Œç›®æ ‡ä¿¡å·ä¸èƒ½é‡å¤\n- **HybridSensorTransformeræ¨¡å‹**: è¾¹ç•Œæ¡ä»¶ä¿¡å·å’Œç›®æ ‡ä¿¡å·ä¸èƒ½é‡å¤ï¼›æ—¶åºä¿¡å·å¿…é¡»ä»ç›®æ ‡ä¿¡å·ä¸­é€‰æ‹©\n- **éªŒè¯æ—¶æœº**: ç‚¹å‡»\"å¼€å§‹è®­ç»ƒ\"æ—¶è‡ªåŠ¨éªŒè¯ï¼Œå¦‚æœ‰å†²çªä¼šæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯\n\n**StaticTransformeræ¨¡å‹è®­ç»ƒæµç¨‹:**\n1. (å¯é€‰) å¯¼å…¥ä¹‹å‰ä¿å­˜çš„é…ç½®æ–‡ä»¶\n2. é€‰æ‹©è¾¹ç•Œæ¡ä»¶å’Œç›®æ ‡ä¿¡å·\n3. è°ƒæ•´è®­ç»ƒå‚æ•°å’Œæ¨¡å‹æ¶æ„\n4. ç‚¹å‡»\"å¼€å§‹è®­ç»ƒ StaticTransformer æ¨¡å‹\" - ç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯ä¿¡å·é€‰æ‹©\n5. **å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦** - æ¯ä¸ªepochçš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±ä¼šå®æ—¶æ˜¾ç¤ºï¼ˆâ­è¡¨ç¤ºæœ€ä½³æ¨¡å‹ï¼‰\n6. (å¯é€‰) å¯¼å‡ºå½“å‰é…ç½®ä»¥ä¾¿åç»­ä½¿ç”¨\n\n**HybridSensorTransformeræ¨¡å‹è®­ç»ƒæµç¨‹:**\n1. (å¯é€‰) å¯¼å…¥ä¹‹å‰ä¿å­˜çš„é…ç½®æ–‡ä»¶\n2. é€‰æ‹©è¾¹ç•Œæ¡ä»¶å’Œç›®æ ‡ä¿¡å·\n3. ä»ç›®æ ‡ä¿¡å·ä¸­é€‰æ‹©éœ€è¦æ—¶åºæ¨¡å¼çš„ä¿¡å·ï¼ˆå¯ä½¿ç”¨\"åŒæ­¥ç›®æ ‡ä¿¡å·\"æŒ‰é’®å¿«é€Ÿæ›´æ–°é€‰é¡¹ï¼‰\n4. è°ƒæ•´ä¸Šä¸‹æ–‡çª—å£å¤§å°å’Œå…¶ä»–å‚æ•°\n5. è°ƒæ•´è®­ç»ƒå‚æ•°å’Œæ¨¡å‹æ¶æ„\n6. ç‚¹å‡»\"å¼€å§‹è®­ç»ƒ HybridSensorTransformer æ¨¡å‹\" - ç³»ç»Ÿä¼šè‡ªåŠ¨éªŒè¯ä¿¡å·é€‰æ‹©\n7. **å®æ—¶æŸ¥çœ‹è®­ç»ƒè¿›åº¦** - æ¯ä¸ªepochçš„è®­ç»ƒå’ŒéªŒè¯æŸå¤±ä¼šå®æ—¶æ˜¾ç¤ºï¼ˆâ­è¡¨ç¤ºæœ€ä½³æ¨¡å‹ï¼‰\n8. (å¯é€‰) å¯¼å‡ºå½“å‰é…ç½®ä»¥ä¾¿åç»­ä½¿ç”¨\n\n**è®­ç»ƒæ—¥å¿—è¯´æ˜:**\n- â­ æ ‡è®°è¡¨ç¤ºè¯¥epochè·å¾—äº†æœ€ä½³éªŒè¯æŸå¤±ï¼ˆæ¨¡å‹ä¼šè¢«ä¿å­˜ï¼‰\n- Train: è®­ç»ƒæŸå¤±\n- Val: éªŒè¯æŸå¤±\n- Best: å½“å‰æœ€ä½³éªŒè¯æŸå¤±\n- LR: å½“å‰å­¦ä¹ ç‡\n- Patience: æ—©åœè®¡æ•°å™¨ï¼ˆè¾¾åˆ°è®¾å®šå€¼ä¼šè‡ªåŠ¨åœæ­¢è®­ç»ƒï¼‰\n\n**æ¨ç†æµç¨‹:**\n1. ç‚¹å‡»\"åˆ·æ–°æ¨¡å‹åˆ—è¡¨\"\n2. é€‰æ‹©å·²è®­ç»ƒæ¨¡å‹å¹¶ç‚¹å‡»\"åŠ è½½æ¨¡å‹\"\n3. è®¾ç½®æ¨ç†çš„æ•°æ®èŒƒå›´ (èµ·å§‹å’Œç»“æŸç´¢å¼•)\n4. é€‰æ‹©è¦å¯è§†åŒ–å’Œåˆ†æçš„ä¿¡å· (å»ºè®®1-3ä¸ª)\n5. ç‚¹å‡»\"è¿è¡Œæ¨ç†\"æŸ¥çœ‹ç»“æœ\n\n**å¯è§†åŒ–è¯´æ˜:**\n- å·¦å›¾: é¢„æµ‹å€¼ä¸å®é™…å€¼çš„æ—¶åºå¯¹æ¯”\n- ä¸­å›¾: æ®‹å·®åˆ†æ (å®é™…å€¼ - é¢„æµ‹å€¼)\n- å³å›¾: é¢„æµ‹ç²¾åº¦æ•£ç‚¹å›¾ (è¶Šæ¥è¿‘å¯¹è§’çº¿è¶Šå¥½)\n\n**æç¤º:**\n- HybridSensorTransformeræ¨¡å‹çš„æ—¶åºæ¨¡å¼éœ€è¦è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡æ•°æ®\n- é…ç½®æ–‡ä»¶å¯ä»¥ä¿å­˜ä½ çš„ä¿¡å·é€‰æ‹©å’Œæ‰€æœ‰è®­ç»ƒå‚æ•°\n- å»ºè®®å…ˆç”¨å°epochæ•°ï¼ˆå¦‚1-10ï¼‰æµ‹è¯•ï¼Œç¡®è®¤æ— è¯¯åå†è¿›è¡Œå¤§è§„æ¨¡è®­ç»ƒ\n- å¦‚æœä¿¡å·é€‰æ‹©æœ‰å†²çªï¼Œè®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ï¼Œæ ¹æ®æç¤ºä¿®æ”¹å³å¯\n- è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥å®æ—¶çœ‹åˆ°æ¯ä¸ªepochçš„è¿›åº¦ï¼Œæ— éœ€ç­‰å¾…è®­ç»ƒç»“æŸ\n            \"\"\")\n\n    # ========== äº‹ä»¶ç»‘å®š ==========\n\n    # æ•°æ®åŠ è½½ - ç›´æ¥æ›´æ–°æ‰€æœ‰ä¿¡å·é€‰æ‹©æ¡†\n    load_data_btn.click(\n        fn=on_load_data,\n        inputs=[data_file],\n        outputs=[\n            data_status,\n            signals_list_display,\n            boundary_signals_static,\n            target_signals_static,\n            boundary_signals_hybrid,\n            target_signals_hybrid\n        ]\n    )\n\n    # StaticTransformeré…ç½®å¯¼å…¥å¯¼å‡º\n    import_config_btn_static.click(\n        fn=import_config,\n        inputs=[config_file_static],\n        outputs=[\n            boundary_signals_static, target_signals_static, temporal_signals_hybrid,\n            test_size_static, val_size_static, epochs_static, batch_size_static, lr_static,\n            d_model_static, nhead_static, num_layers_static, dropout_static,\n            context_window_hybrid, apply_smoothing_hybrid, gain_hybrid,\n            weight_decay_static, scheduler_patience_static, scheduler_factor_static,\n            grad_clip_static, early_stop_patience_static, config_status_static\n        ]\n    )\n\n    export_config_btn_static.click(\n        fn=export_config_static_transformer,\n        inputs=[\n            boundary_signals_static, target_signals_static,\n            test_size_static, val_size_static, epochs_static, batch_size_static, lr_static,\n            d_model_static, nhead_static, num_layers_static, dropout_static,\n            weight_decay_static, scheduler_patience_static, scheduler_factor_static,\n            grad_clip_static, early_stop_patience_static\n        ],\n        outputs=[config_download_static, config_status_static]\n    ).then(\n        fn=lambda x: gr.update(visible=True),\n        inputs=[config_download_static],\n        outputs=[config_download_static]\n    )\n\n    # HybridSensorTransformeré…ç½®å¯¼å…¥å¯¼å‡º\n    sync_temporal_btn_hybrid.click(\n        fn=lambda target_sigs: gr.update(choices=target_sigs if target_sigs else []),\n        inputs=[target_signals_hybrid],\n        outputs=[temporal_signals_hybrid]\n    )\n\n    import_config_btn_hybrid.click(\n        fn=import_config,\n        inputs=[config_file_hybrid],\n        outputs=[\n            boundary_signals_hybrid, target_signals_hybrid, temporal_signals_hybrid,\n            test_size_hybrid, val_size_hybrid, epochs_hybrid, batch_size_hybrid, lr_hybrid,\n            d_model_hybrid, nhead_hybrid, num_layers_hybrid, dropout_hybrid,\n            context_window_hybrid, apply_smoothing_hybrid, gain_hybrid,\n            weight_decay_hybrid, scheduler_patience_hybrid, scheduler_factor_hybrid,\n            grad_clip_hybrid, early_stop_patience_hybrid, config_status_hybrid\n        ]\n    )\n\n    export_config_btn_hybrid.click(\n        fn=export_config_hybrid_sensor_transformer,\n        inputs=[\n            boundary_signals_hybrid, target_signals_hybrid, temporal_signals_hybrid,\n            test_size_hybrid, val_size_hybrid, epochs_hybrid, batch_size_hybrid, lr_hybrid,\n            d_model_hybrid, nhead_hybrid, num_layers_hybrid, dropout_hybrid,\n            context_window_hybrid, apply_smoothing_hybrid, gain_hybrid,\n            weight_decay_hybrid, scheduler_patience_hybrid, scheduler_factor_hybrid,\n            grad_clip_hybrid, early_stop_patience_hybrid\n        ],\n        outputs=[config_download_hybrid, config_status_hybrid]\n    ).then(\n        fn=lambda x: gr.update(visible=True),\n        inputs=[config_download_hybrid],\n        outputs=[config_download_hybrid]\n    )\n\n    # StaticTransformerè®­ç»ƒ\n    train_btn_static.click(\n        fn=start_training_static_transformer,\n        inputs=[\n            boundary_signals_static, target_signals_static,\n            test_size_static, val_size_static, epochs_static, batch_size_static, lr_static,\n            d_model_static, nhead_static, num_layers_static, dropout_static,\n            weight_decay_static, scheduler_patience_static, scheduler_factor_static,\n            grad_clip_static, early_stop_patience_static\n        ],\n        outputs=[training_log_static]\n    )\n\n    # HybridSensorTransformerè®­ç»ƒ\n    train_btn_hybrid.click(\n        fn=start_training_hybrid_sensor_transformer,\n        inputs=[\n            boundary_signals_hybrid, target_signals_hybrid, temporal_signals_hybrid,\n            test_size_hybrid, val_size_hybrid, epochs_hybrid, batch_size_hybrid, lr_hybrid,\n            d_model_hybrid, nhead_hybrid, num_layers_hybrid, dropout_hybrid,\n            context_window_hybrid, apply_smoothing_hybrid, gain_hybrid,\n            weight_decay_hybrid, scheduler_patience_hybrid, scheduler_factor_hybrid,\n            grad_clip_hybrid, early_stop_patience_hybrid\n        ],\n        outputs=[training_log_hybrid]\n    )\n\n    # æ¨ç†\n    refresh_models_btn.click(\n        fn=lambda: gr.update(choices=get_model_list()),\n        outputs=[model_selector]\n    )\n\n    load_model_btn.click(\n        fn=on_model_load,\n        inputs=[model_selector],\n        outputs=[model_info, inference_signals]\n    )\n\n    inference_btn.click(\n        fn=run_inference,\n        inputs=[model_selector, start_idx, end_idx, inference_signals],\n        outputs=[inference_status, inference_plot, metrics_output]\n    )\n\nprint(\"=\"*80)\nprint(\"ğŸ‰ å®Œæ•´Gradioç•Œé¢å·²å‡†å¤‡å°±ç»ªï¼\")\nprint(\"=\"*80)\nprint(\"\\\\nğŸš€ ç•Œé¢åŠŸèƒ½:\")\nprint(\"  â€¢ âœ… StaticTransformer: é™æ€ä¼ æ„Ÿå™¨æ˜ å°„è®­ç»ƒ\")\nprint(\"  â€¢ âœ… HybridSensorTransformer: æ··åˆæ—¶åº+é™æ€è®­ç»ƒ\")\nprint(\"  â€¢ âœ… å®æ—¶è®­ç»ƒè¿›åº¦æ˜¾ç¤º\")\nprint(\"  â€¢ âœ… é…ç½®å¯¼å…¥/å¯¼å‡ºåŠŸèƒ½\")\nprint(\"  â€¢ âœ… å®Œæ•´æ¨ç†å’Œå¯è§†åŒ–\")\nprint(\"  â€¢ âœ… ä¿¡å·éªŒè¯å’Œé”™è¯¯æç¤º\")\nprint(\"\\\\nğŸ“ æ¨¡å‹åç§°å·²å®Œå…¨ç»Ÿä¸€:\")\nprint(\"  â€¢ V1 â†’ StaticTransformer\")\nprint(\"  â€¢ V4 â†’ HybridSensorTransformer\")\nprint(\"\\\\nğŸš€ æ‰§è¡Œ demo.launch() å¯åŠ¨ç•Œé¢\")\nprint(\"\\\\nğŸ’¡ å¦‚æœåœ¨æœ¬åœ°ï¼Œè®¿é—® http://127.0.0.1:7860\")\nprint(\"=\"*80)\n\n# å¯åŠ¨ç•Œé¢\ndemo.launch(share=True, debug=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## âœ… å®Œæˆï¼\n\nè¿è¡Œä¸Šé¢çš„cellåï¼Œæ‚¨çš„å®Œæ•´Gradioç•Œé¢å°†å¯åŠ¨ï¼ŒåŒ…å«:\n\n### åŠŸèƒ½åˆ—è¡¨\n- âœ… **æ•°æ®åŠ è½½Tab**: ä¸Šä¼ CSVã€æŸ¥çœ‹æ‰€æœ‰ä¿¡å·\n- âœ… **StaticTransformerè®­ç»ƒTab**: å®Œæ•´StaticTransformeré™æ€ä¼ æ„Ÿå™¨æ˜ å°„è®­ç»ƒ\n- âœ… **HybridSensorTransformerè®­ç»ƒTab**: å®Œæ•´HybridSensorTransformeræ··åˆæ—¶åº+é™æ€è®­ç»ƒ\n- âœ… **æ¨ç†Tab**: å¤šæ¨¡å‹æ¨ç†ã€å¯è§†åŒ–åˆ†æ\n- âœ… **é…ç½®ç®¡ç†**: JSONå¯¼å…¥/å¯¼å‡º\n- âœ… **å®æ—¶è¿›åº¦**: æ¯ä¸ªepochçš„è®­ç»ƒçŠ¶æ€\n- âœ… **ä¿¡å·éªŒè¯**: è‡ªåŠ¨æ£€æŸ¥ä¿¡å·é€‰æ‹©é”™è¯¯\n\n### è®¿é—®ç•Œé¢\n- **Colab**: ä¼šç”Ÿæˆå…¬å¼€é“¾æ¥\n- **æœ¬åœ°**: è®¿é—® http://127.0.0.1:7860\n\n### ğŸ”„ æ¨¡å‹åç§°æ›´æ–°å®Œæˆ âœ…\næ‰€æœ‰æ¨¡å‹åç§°å·²ç»Ÿä¸€æ›´æ–°ï¼š\n- **V1** â†’ **StaticTransformer** (é™æ€ä¼ æ„Ÿå™¨æ˜ å°„Transformer)\n- **V4** â†’ **HybridSensorTransformer** (æ··åˆæ—¶åº+é™æ€Transformer)\n\n**âœ… åŠŸèƒ½å®Œå…¨ä¿æŒä¸å˜**ï¼Œä»…æ›´æ–°å‘½åä»¥ä¿æŒä»£ç ä¸€è‡´æ€§ã€‚\n\n### ğŸ‰ ä»£ç å®Œæ•´æ€§\n- âœ… å®Œæ•´çš„è®­ç»ƒå‡½æ•°å·²é›†æˆ\n- âœ… æ‰€æœ‰V1/V4å¼•ç”¨å·²æ›¿æ¢ä¸ºStaticTransformer/HybridSensorTransformer\n- âœ… æ‰€æœ‰å˜é‡åç§°å·²æ›´æ–°\n- âœ… æ‰€æœ‰ç•Œé¢æ–‡æœ¬å·²æ›´æ–°\n- âœ… æ‰€æœ‰æ³¨é‡Šå·²æ›´æ–°\n- âœ… æ— éœ€ä»»ä½•æ‰‹åŠ¨ä¿®æ”¹\n\n---\n\n## ğŸ†˜ éœ€è¦å¸®åŠ©ï¼Ÿ\n\næŸ¥çœ‹æ–‡æ¡£:\n- `GRADIO_README.md` - Gradioä½¿ç”¨æ€»æŒ‡å—\n- `docs/CELL3_INTEGRATION_GUIDE.md` - è¯¦ç»†é›†æˆè¯´æ˜\n- `docs/GRADIO_INTEGRATION.md` - Gradioé›†æˆæ–‡æ¡£\n\n---"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}