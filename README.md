# Quant-Stock-Transformer

> âš ï¸ **ğŸš§ Under Active Development | å¼€å‘æµ‹è¯•ä¸­ ğŸš§**
>
> This is an experimental quantitative stock prediction framework. Code and documentation are being actively developed and refined.

---

## ğŸ“– Overview | é¡¹ç›®ç®€ä»‹

**Quant-Stock-Transformer** is a novel three-stage quantitative stock prediction framework that achieves resource savings through spatial-temporal separation.

åŸºäºç©ºé—´-æ—¶åºåˆ†ç¦»çš„ä¸‰é˜¶æ®µé‡åŒ–è‚¡ç¥¨é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡åˆ†ç¦»ç©ºé—´å…³ç³»å»ºæ¨¡å’Œæ—¶åºæ¼”åŒ–å»ºæ¨¡ï¼Œå®ç°ç®—åŠ›èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚

### ğŸ¯ Key Innovation | æ ¸å¿ƒåˆ›æ–°

1. **Spatial-Temporal Separation | ç©ºé—´-æ—¶åºåˆ†ç¦»**
   - Stage 1: Dual-output SST for spatial relationships (T-day & T+1-day)
   - Stage 2: Internal feature extraction (attention + encoder + residuals)
   - Stage 3: Temporal models for time-series enhancement (LSTM/GRU/TCN)

2. **Complete End-to-End Pipeline | å®Œæ•´ç«¯åˆ°ç«¯æµç¨‹**
   - Stock selection JSON import
   - Intelligent multi-market data fetching with batching
   - Automated preprocessing and feature engineering
   - Multi-model training and comparison
   - Comprehensive evaluation metrics

3. **Dual Usage Modes | åŒä½¿ç”¨æ¨¡å¼**
   - **CLI**: Full-featured command-line pipeline
   - **UI**: Gradio-based visual interface with 7-step workflow

4. **Multi-Model Comparison | å¤šæ¨¡å‹å¯¹æ¯”**
   - SST (baseline with dual outputs)
   - SST + LSTM (with Attention)
   - SST + GRU (lightweight)
   - SST + TCN (temporal convolution)

---

## ğŸš€ Quick Start | å¿«é€Ÿå¼€å§‹

### ğŸ“¦ Installation | å®‰è£…

```bash
# Clone the repository
git clone https://github.com/FTF1990/Quant-Stock-Transformer.git
cd Quant-Stock-Transformer

# Install dependencies
pip install -r requirements.txt
```

### ğŸ® Usage | ä½¿ç”¨æ–¹æ³•

#### âœ¨ Option 1: Gradio Visual UI (Recommended | æ¨è)

Launch the interactive web interface with 7-step visual workflow:

```bash
python gradio_pipeline_ui.py
```

Then open your browser at `http://localhost:7860`

**7-Step Workflow**:
1. ğŸ“‹ **Load Stock JSON** - Upload your stock selection file
2. ğŸ“Š **Fetch Data** - Intelligent batch data fetching (US/CN/HK/JP markets)
3. ğŸ”„ **Preprocess** - Calculate returns and split datasets
4. ğŸ§  **Train SST** - Dual-output Transformer model
5. ğŸ” **Extract Features** - Attention weights, encoder outputs, residuals
6. â° **Train Temporal** - LSTM/GRU/TCN models (choose any)
7. ğŸ“ˆ **Evaluate** - Compare all models with metrics and charts

**Features**:
- Real-time progress tracking
- Interactive parameter configuration
- Rich visualizations (training curves, feature distributions, performance comparisons)
- No command-line required

See **[UI_USAGE.md](UI_USAGE.md)** for detailed usage guide.

---

#### ğŸ–¥ï¸ Option 2: Command-Line Pipeline

Run the complete training pipeline programmatically:

```bash
# Basic usage
python complete_training_pipeline.py \
    --stocks_json data/demo.json \
    --target_market CN \
    --target_stock 600519

# Full parameters
python complete_training_pipeline.py \
    --stocks_json data/demo.json \
    --target_market CN \
    --target_stock 600519 \
    --start_date 2020-01-01 \
    --end_date 2024-12-31 \
    --fetch_data \
    --sst_epochs 50 \
    --temporal_epochs 100 \
    --seq_len 60 \
    --device cuda
```

**Key Parameters**:
- `--stocks_json`: Path to stock selection JSON
- `--target_market`: Target market (US/CN/HK/JP)
- `--target_stock`: Stock symbol to predict
- `--fetch_data`: Re-fetch historical data (vs. using cache)
- `--sst_epochs`: SST training epochs (default: 50)
- `--temporal_epochs`: Temporal model epochs (default: 100)
- `--device`: cpu or cuda

See **[PIPELINE_FLOW_CONFIRMATION.md](PIPELINE_FLOW_CONFIRMATION.md)** for complete flow verification.

---

#### ğŸ“‹ Option 3: Python API

Use individual components in your code:

```python
from complete_training_pipeline import (
    StockDataFetcher,
    StockDataProcessor,
    DualOutputSST,
    ModelTrainer,
    ModelEvaluator
)

# Fetch data
fetcher = StockDataFetcher()
historical_data = fetcher.fetch_historical_data(
    stocks_json=your_stocks,
    start_date="2020-01-01",
    end_date="2024-12-31"
)

# Preprocess
processor = StockDataProcessor(
    historical_data=historical_data,
    target_market="CN",
    target_stock="600519"
)
X, y_T, y_T1, dates = processor.prepare_training_data()

# Train SST
sst_model = DualOutputSST(
    num_boundary_sensors=X.shape[1],
    num_target_sensors=1,
    d_model=128,
    nhead=8,
    num_layers=3
)

trainer = ModelTrainer(device='cuda')
history = trainer.train_sst(sst_model, X_train, y_T_train, y_T1_train, ...)

# Evaluate
evaluator = ModelEvaluator(device='cuda')
metrics = evaluator.evaluate_sst(sst_model, X_test, y_T_test, y_T1_test)
```

---

## ğŸ“š Documentation | æ–‡æ¡£

### Core Documentation | æ ¸å¿ƒæ–‡æ¡£

- **[UI Usage Guide](UI_USAGE.md)** - Complete 7-step visual UI guide
- **[Pipeline Flow Confirmation](PIPELINE_FLOW_CONFIRMATION.md)** - End-to-end flow verification
- **[Feature Extraction Guide](docs/FEATURE_EXTRACTION_GUIDE.md)** - Technical guide for SST features
- **[SST Internals README](docs/SST_INTERNALS_EXTRACTION_README.md)** - Quick start for feature extraction

### Example Data | ç¤ºä¾‹æ•°æ®

- **[data/demo.json](data/demo.json)** - Sample stock selection (28 stocks across 4 markets)

---

## ğŸ—‚ï¸ Project Structure | é¡¹ç›®ç»“æ„

```
Quant-Stock-Transformer/
â”œâ”€â”€ models/                          # Core model implementations
â”‚   â”œâ”€â”€ static_transformer.py        # SST base model
â”‚   â”œâ”€â”€ spatial_feature_extractor.py # SST with feature extraction
â”‚   â”œâ”€â”€ relationship_extractors.py   # Attention/embedding extractors
â”‚   â””â”€â”€ temporal_predictor.py        # LSTM/GRU/TCN temporal models
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ demo.json                    # ğŸ“‹ Sample stock selection (28 stocks)
â”‚   â””â”€â”€ default_signals_config.json  # Signal configuration
â”œâ”€â”€ complete_training_pipeline.py    # ğŸš€ Complete CLI training pipeline (1139 lines)
â”œâ”€â”€ gradio_pipeline_ui.py            # ğŸ¨ Gradio visual UI (1173 lines)
â”œâ”€â”€ notebooks/                       # Jupyter/Colab notebooks
â”‚   â”œâ”€â”€ stock_analysis_agent.ipynb   # ğŸ¤– LLM-based stock analysis (optional)
â”‚   â””â”€â”€ model_training_pipeline.ipynb # Model training reference
â”œâ”€â”€ examples/                        # Example scripts
â”‚   â””â”€â”€ extract_sst_internals_demo.py # Feature extraction demo
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ FEATURE_EXTRACTION_GUIDE.md
â”‚   â”œâ”€â”€ SST_INTERNALS_EXTRACTION_README.md
â”‚   â””â”€â”€ sst_feature_extraction_demo.md
â”œâ”€â”€ UI_USAGE.md                      # ğŸ“– Gradio UI usage guide
â”œâ”€â”€ PIPELINE_FLOW_CONFIRMATION.md    # âœ… Flow verification doc
â””â”€â”€ README.md                        # This file
```

---

## ğŸ“Š Stock Selection | è‚¡ç¥¨é€‰æ‹©

### Using Claude AI Agent (Recommended | æ¨è)

Generate your stock selection JSON using Claude AI:

1. Open Claude (claude.ai)
2. Describe your stock selection strategy
3. Ask Claude to generate a JSON file in the required format
4. Save the JSON and use it with the pipeline

**Required JSON Format**:
```json
{
  "US": [
    {"symbol": "NVDA", "name": "NVIDIA", "reason": "...", "category": "..."}
  ],
  "CN": [
    {"symbol": "600519", "name": "è´µå·èŒ…å°", "reason": "...", "category": "..."}
  ],
  "HK": [...],
  "JP": [...]
}
```

### Using Demo Data | ä½¿ç”¨ç¤ºä¾‹æ•°æ®

Start with the provided demo.json:

```bash
# 28 stocks across 4 markets
data/demo.json
  â”œâ”€â”€ US: 8 stocks (NVDA, AMD, INTC, TSM, ASML, QCOM, AVGO, MU)
  â”œâ”€â”€ CN: 10 stocks (è´µå·èŒ…å°, æ‹›å•†é“¶è¡Œ, etc.)
  â”œâ”€â”€ HK: 5 stocks (è…¾è®¯, é˜¿é‡Œå·´å·´, etc.)
  â””â”€â”€ JP: 5 stocks (Sony, äº¬ç“·, etc.)
```

### Optional: LLM-Powered Analysis | LLMé©±åŠ¨åˆ†æï¼ˆå¯é€‰ï¼‰

For advanced users, use the notebook-based stock analysis agent:

- `notebooks/stock_analysis_agent.ipynb` - Industry chain analysis with LLM
- Supports: Google AI (Gemini), OpenAI, DeepSeek
- Multi-market coverage: US, CN, HK, JP
- Automatic data fetching

---

## ğŸ“ˆ Data Fetching | æ•°æ®è·å–

### Intelligent Batch Fetching | æ™ºèƒ½åˆ†æ‰¹æŠ“å–

**Features**:
- âœ… **Multi-Source Support**
  - A-shares (CN): AkShare (free, no API key)
  - US/HK/JP: yfinance (free Yahoo Finance API)
- âœ… **Smart Batching** - Avoid API rate limits
  - Configurable batch size (default: 5 stocks/batch)
  - Configurable delays (default: 2s between batches)
- âœ… **Auto-Retry** - Handles network errors gracefully
- âœ… **Progress Tracking** - Real-time progress display
- âœ… **Market Indices** - Includes S&P 500, ä¸Šè¯æŒ‡æ•°, æ’ç”ŸæŒ‡æ•°, æ—¥ç»225

**Example**:
```python
from complete_training_pipeline import StockDataFetcher

fetcher = StockDataFetcher()
historical_data = fetcher.fetch_historical_data(
    stocks_json=my_stocks,
    start_date="2020-01-01",
    end_date="2024-12-31",
    interval="1d",                    # "1h" for hourly data
    include_market_index=True,
    batch_size=5,                     # 5 stocks per batch
    delay_between_batches=2.0,        # 2 seconds between batches
    delay_between_stocks=0.5          # 0.5 seconds between stocks
)

fetcher.save_data("historical_data.pkl")
```

**Data Fields**:
- Open, High, Low, Close
- Volume
- Date index

---

## ğŸ§  Model Training | æ¨¡å‹è®­ç»ƒ

### Complete 3-Stage Pipeline | å®Œæ•´ä¸‰é˜¶æ®µæµç¨‹

**Stage 1: Dual-Output SST**
- Simultaneously predicts T-day and T+1-day returns
- Transformer encoder (8 heads, 3 layers, 128 hidden dim)
- Global average pooling
- Dual output heads

```python
from complete_training_pipeline import DualOutputSST

model = DualOutputSST(
    num_boundary_sensors=num_features,
    num_target_sensors=1,
    d_model=128,
    nhead=8,
    num_layers=3,
    enable_feature_extraction=True
)

# Returns both T and T+1 predictions
pred_T, pred_T1 = model(boundary_conditions)
```

**Stage 2: Feature Extraction**
- Encoder outputs: [batch, sensors, 128]
- Attention weights: [batch, layers, heads, sensors, sensors]
- Pooled features: [batch, 128]
- Residuals: actual - predicted

```python
# Extract features
(pred_T, pred_T1), features = model.forward_with_features(
    boundary_conditions,
    return_attention=True,
    return_encoder_output=True
)

encoder_output = features['encoder_output']
attention_weights = features['attention_weights']
pooled_features = features['pooled_features']

# Calculate residuals
residual_T = target_T - pred_T
residual_T1 = target_T1 - pred_T1
```

**Stage 3: Temporal Models**

Train time-series models using SST features:

```python
from complete_training_pipeline import (
    LSTMTemporalPredictor,
    GRUTemporalPredictor,
    TCNTemporalPredictor
)

# LSTM with Attention
lstm_model = LSTMTemporalPredictor(
    input_dim=num_features + relationship_dim,
    hidden_dim=128,
    num_layers=2,
    output_dim=1,
    use_attention=True
)

# GRU (lightweight)
gru_model = GRUTemporalPredictor(
    input_dim=num_features + relationship_dim,
    hidden_dim=128,
    num_layers=2,
    output_dim=1
)

# TCN (parallel)
tcn_model = TCNTemporalPredictor(
    input_dim=num_features + relationship_dim,
    num_channels=[64, 128, 128, 64],
    output_dim=1
)
```

---

## ğŸ“Š Model Evaluation | æ¨¡å‹è¯„ä¼°

### Metrics | è¯„ä¼°æŒ‡æ ‡

- âœ… **MSE** (Mean Squared Error) - Lower is better
- âœ… **MAE** (Mean Absolute Error) - Lower is better
- âœ… **Direction Accuracy** - Percentage of correct up/down predictions
- âœ… **Sharpe Ratio** - Risk-adjusted returns (annualized)

### Model Comparison | æ¨¡å‹å¯¹æ¯”

| Model | Status | Parameters | Features |
|-------|--------|------------|----------|
| SST (baseline) | âœ… Implemented | ~500K | Dual outputs (T + T+1) |
| SST + LSTM | âœ… Implemented | ~600K | Attention mechanism |
| SST + GRU | âœ… Implemented | ~550K | Lightweight version |
| SST + TCN | âœ… Implemented | ~580K | Parallel computation |

**Evaluation Output**:
```
Model    MSE       MAE       Direction_Acc  Sharpe_Ratio
SST      0.001234  0.025678  52.34%         0.4521
LSTM     0.001156  0.024532  54.56%         0.5234
GRU      0.001189  0.024789  53.89%         0.5123
TCN      0.001201  0.025012  53.12%         0.4987
```

*Note: Example metrics - actual values depend on data and training*

---

## ğŸ¨ Gradio UI Features | UIåŠŸèƒ½ç‰¹æ€§

### Visual Training Pipeline | å¯è§†åŒ–è®­ç»ƒæµç¨‹

**7-Step Interactive Workflow**:

1. **ğŸ“‹ Load JSON** - Upload & visualize stock lists
   - Stock count statistics
   - Market distribution pie chart
   - Detailed stock table

2. **ğŸ“Š Fetch Data** - Intelligent batch data fetching
   - Date range configuration
   - Batch size & delay settings
   - Real-time progress bar
   - Data statistics table

3. **ğŸ”„ Preprocess** - Data preparation
   - Return calculation (T & T+1)
   - Dataset split (70/15/15)
   - Return distribution plots

4. **ğŸ§  Train SST** - Transformer training
   - Epoch/batch/LR sliders
   - Real-time training curves
   - Loss breakdown (T vs T+1)

5. **ğŸ” Extract Features** - Feature visualization
   - Feature distribution plots
   - Residual analysis
   - Feature heatmaps

6. **â° Train Temporal** - Time-series models
   - Model type selector (LSTM/GRU/TCN)
   - Sequence length configuration
   - Training curve display

7. **ğŸ“ˆ Evaluate** - Performance comparison
   - Metrics comparison table
   - Performance bar charts
   - Best model highlighting

**Visualizations**:
- Training loss curves
- Feature distributions
- Performance comparison charts
- Market distribution plots
- Return histograms

---

## ğŸ› ï¸ Development Status | å¼€å‘çŠ¶æ€

### âœ… Completed | å·²å®Œæˆ

- [x] SST base model with dual outputs (T + T+1)
- [x] Spatial feature extractor with attention/encoder extraction
- [x] Complete training pipeline (CLI)
- [x] Gradio visual UI (7-step workflow)
- [x] Temporal models (LSTM, GRU, TCN)
- [x] Multi-market data fetcher with smart batching
- [x] Model evaluation and comparison
- [x] Comprehensive documentation
- [x] Demo stock selection (28 stocks)

### ğŸš§ In Progress | è¿›è¡Œä¸­

- [ ] Advanced feature engineering
- [ ] Hyperparameter optimization
- [ ] Backtesting framework
- [ ] Model ensemble methods

### ğŸ“‹ Planned | è®¡åˆ’ä¸­

- [ ] Real-time prediction API
- [ ] More temporal models (Informer, Autoformer)
- [ ] Risk management module
- [ ] Portfolio optimization
- [ ] Multi-target prediction (volume, volatility)

---

## ğŸ’¡ Usage Tips | ä½¿ç”¨æŠ€å·§

### For Beginners | æ–°æ‰‹å»ºè®®

1. Start with the Gradio UI (`python gradio_pipeline_ui.py`)
2. Use the demo.json file for initial testing
3. Try small epochs first (SST: 20, Temporal: 30)
4. Use CPU for testing, GPU for production training

### For Advanced Users | è¿›é˜¶ç”¨æˆ·

1. Generate custom stock selections with Claude AI
2. Experiment with hyperparameters
3. Try different markets and date ranges
4. Analyze feature importance from SST
5. Implement custom temporal models

### Performance Optimization | æ€§èƒ½ä¼˜åŒ–

**Training Speed**:
- Use GPU (`--device cuda`)
- Increase batch size (if memory allows)
- Use GRU instead of LSTM for faster training
- Use TCN for fastest inference

**Data Fetching**:
- Use cached data (`historical_data.pkl`) when possible
- Adjust batch size and delays based on network
- Fetch data overnight for large stock lists

---

## ğŸ› Troubleshooting | å¸¸è§é—®é¢˜

### Data Fetching Issues

**Problem**: API rate limit errors
**Solution**: Reduce batch size, increase delays

**Problem**: Stock symbol not found
**Solution**: Check symbol format (US: AAPL, CN: 600519, HK: 00700, JP: 6758.T)

### Training Issues

**Problem**: Out of memory
**Solution**: Reduce batch size, use smaller model, reduce sequence length

**Problem**: Slow training
**Solution**: Use GPU, increase batch size, reduce epochs for testing

### Model Performance

**Problem**: Low accuracy
**Solution**: More training epochs, different hyperparameters, more data, better stock selection

---

## ğŸ¤ Contributing | è´¡çŒ®

Contributions are welcome! Please feel free to submit a Pull Request.

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚

### Development Guidelines | å¼€å‘æŒ‡å—

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License | è®¸å¯è¯

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact | è”ç³»æ–¹å¼

- **Issues**: [GitHub Issues](https://github.com/FTF1990/Quant-Stock-Transformer/issues)
- **Discussions**: [GitHub Discussions](https://github.com/FTF1990/Quant-Stock-Transformer/discussions)

---

## ğŸ™ Acknowledgments | è‡´è°¢

- PyTorch team for the excellent deep learning framework
- AkShare for providing free A-share data access
- yfinance for Yahoo Finance data API
- Gradio team for the amazing UI framework
- Claude AI for intelligent code assistance

---

## âš ï¸ Disclaimer | å…è´£å£°æ˜

**This project is for research and educational purposes only. Not financial advice.**

**æœ¬é¡¹ç›®ä»…ä¾›ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚**

- Past performance does not guarantee future results
- Stock trading involves substantial risk of loss
- Always do your own research before investing
- The authors are not responsible for any financial losses

---

## ğŸ“ˆ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FTF1990/Quant-Stock-Transformer&type=Date)](https://star-history.com/#FTF1990/Quant-Stock-Transformer&Date)

---

**Made with â¤ï¸ by the Quant-Stock-Transformer Team**

**ğŸš§ Active Development - Stay Tuned for Updates! | ç§¯æå¼€å‘ä¸­ - æ•¬è¯·æœŸå¾…æ›´æ–°ï¼ğŸš§**
