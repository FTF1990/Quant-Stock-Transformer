# Industrial Digital Twin by Transformer

**[English](README.md)** | **[ä¸­æ–‡](README_CN.md)**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **An innovative Transformer-based framework for industrial digital twin modeling using sequential sensor outputs from complex systems with advanced residual boost training.**

This project introduces novel Transformer architectures and residual boost training methodology specifically designed for predicting sensor outputs in industrial digital twin applications. Unlike traditional approaches, our models leverage the **sequential nature of multi-sensor systems** in complex industrial environments to achieve superior prediction accuracy through multi-stage refinement.

## ğŸŒŸ Key Innovation

**Sequential Sensor Prediction using Transformers**: This is the first framework to apply Transformer architecture specifically to the problem of predicting sequential sensor outputs in industrial digital twins. The model treats multiple sensors as a sequence, capturing both spatial relationships between sensors and temporal dependencies in their measurements.

### Why This Matters

In complex industrial systems (manufacturing plants, chemical processes, power generation, etc.), sensors don't operate in isolation. Their outputs are:
- **Spatially correlated**: Physical proximity and process flow create dependencies
- **Temporally dependent**: Historical measurements influence current and future readings
- **Hierarchically structured**: Some sensors measure boundary conditions while others measure internal states

Traditional machine learning approaches treat sensors independently or use simple time-series models. Our Transformer-based approach **captures the full complexity of sensor interrelationships**.

## ğŸš€ Features

### Model Architecture

#### **StaticSensorTransformer (SST)**
- **Purpose**: Maps boundary condition sensors to target sensor predictions
- **Architecture**: Sensor sequence Transformer with learned positional encodings
- **Innovation**: Treats fixed sensor arrays as sequences (replacing NLP token sequences)
- **Use Case**: Industrial systems with complex sensor inter-dependencies
- **Advantages**:
  - Captures spatial sensor relationships through attention mechanism
  - Fast training and inference
  - Learns physical causality between sensors
  - Excellent for industrial digital twin applications

### ğŸ†• Enhanced Residual Boost Training System (v1.0)

#### **Stage2 Boost Training** ğŸš€
- Train secondary models on residuals from SST predictions
- Further refine predictions for improved accuracy
- Configurable architecture and training parameters
- Automatic model saving and versioning

#### **Intelligent Delta RÂ² Threshold Selection** ğŸ¯
- Calculate Delta RÂ² (RÂ²_ensemble - RÂ²_stage1) for each signal
- Selectively apply Stage2 corrections based on Delta RÂ² threshold
- Generate ensemble models combining SST + Stage2
- Optimized performance/efficiency balance
- Only use Stage2 for signals where it provides significant improvement

#### **Comprehensive Inference Comparison** ğŸ“Š
- Compare ensemble model vs. pure SST model
- Visualize performance improvements for all output signals
- Detailed per-signal metrics analysis (MAE, RMSE, RÂ²)
- CSV export with predictions and RÂ² scores
- Interactive index range selection

#### **All-Signal Visualization** ğŸ“ˆ
- Individual prediction vs actual comparison for every output signal
- Dynamic layout adapting to number of signals
- RÂ² scores displayed for each signal
- Easy identification of model improvements

### Additional Features

- âœ… **Modular Design**: Easy to extend and customize
- âœ… **Comprehensive Training Pipeline**: Built-in data preprocessing, training, and evaluation
- âœ… **Interactive Gradio Interface**: User-friendly web interface for all training stages
- âœ… **Jupyter Notebooks**: Complete tutorials and examples
- âœ… **Production Ready**: Exportable models for deployment
- âœ… **Extensive Documentation**: Clear API documentation and usage examples
- âœ… **Automated Model Management**: Intelligent model saving and loading with configurations

### âš ï¸ Deprecation Notice
- **HybridSensorTransformer (HST)** has been removed in favor of the more effective Stage2 Boost approach
- Old HST models are archived but no longer supported

## ğŸ“Š Use Cases

This framework is ideal for:

- **Manufacturing Digital Twins**: Predict equipment states from sensor arrays
- **Chemical Process Monitoring**: Model complex sensor interactions in reactors
- **Power Plant Optimization**: Forecast turbine and generator conditions
- **HVAC Systems**: Predict temperature and pressure distributions
- **Predictive Maintenance**: Early detection of anomalies from sensor patterns
- **Quality Control**: Predict product quality from process sensors

## ğŸ—ï¸ Architecture Overview

### ğŸ”‘ Core Innovation: Sensors as Sequence Elements

**Traditional NLP Transformers vs. SST (Our Innovation)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NLP Transformer (Traditional)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  [The, cat, sits, on, the, mat]  â† Words as tokens      â”‚
â”‚ Embed:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ,   Eâ‚„,  Eâ‚…,  Eâ‚†]  â† Word embeddings      â”‚
â”‚ Pos:    [Pâ‚,  Pâ‚‚,  Pâ‚ƒ,   Pâ‚„,  Pâ‚…,  Pâ‚†]  â† Temporal order       â”‚
â”‚ Attn:   Semantic relationships between words                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â¬‡ï¸  INNOVATION  â¬‡ï¸

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SST - Sensor Sequence Transformer (Ours)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  [Sâ‚,  Sâ‚‚,  Sâ‚ƒ, ..., Sâ‚™]  â† Fixed sensor array          â”‚
â”‚         (Temp, Pressure, Flow, ...)                             â”‚
â”‚ Embed:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ, ..., Eâ‚™]  â† Sensor value embeddings     â”‚
â”‚ Pos:    [Pâ‚,  Pâ‚‚,  Pâ‚ƒ, ..., Pâ‚™]  â† SPATIAL locations           â”‚
â”‚ Attn:   Physical causality & sensor inter-dependencies          â”‚
â”‚                                                                  â”‚
â”‚ Key Differences:                                                 â”‚
â”‚ â€¢ Fixed sequence length (N sensors predetermined)               â”‚
â”‚ â€¢ Position = Sensor location, NOT temporal order                â”‚
â”‚ â€¢ Attention learns cross-sensor physical relationships          â”‚
â”‚ â€¢ Domain-specific for industrial systems                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ SST Architecture Deep Dive

```
Physical Sensor Array: [Sensorâ‚, Sensorâ‚‚, ..., Sensorâ‚™]
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sensor Embedding Layer                        â”‚
â”‚  â€¢ Projects each scalar sensor reading â†’ d_model dimensions     â”‚
â”‚  â€¢ Each sensor gets its own embedding transformation            â”‚
â”‚  â€¢ Input: (batch, N_sensors) â†’ Output: (batch, N_sensors, d_model)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Learnable Position Encoding                        â”‚
â”‚  â€¢ Unlike NLP: Encodes SPATIAL sensor positions                 â”‚
â”‚  â€¢ Learns sensor location importance (e.g., inlet vs outlet)    â”‚
â”‚  â€¢ Shape: (N_sensors, d_model) - one per sensor                â”‚
â”‚  â€¢ Added to embeddings: Embed + PosEncode                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Head Self-Attention Mechanism                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Head 1: Learns temperature-pressure relationships        â”‚  â”‚
â”‚  â”‚ Head 2: Learns flow-velocity correlations               â”‚  â”‚
â”‚  â”‚ Head 3: Learns spatial proximity effects                â”‚  â”‚
â”‚  â”‚ ...                                                      â”‚  â”‚
â”‚  â”‚ Head N: Learns system-wide dependencies                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â€¢ Captures complex, non-linear sensor interactions             â”‚
â”‚  â€¢ Attention weights reveal sensor importance                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Transformer Encoder Stack                      â”‚
â”‚  Layer 1: Attention + FFN + Residual                            â”‚
â”‚  Layer 2: Attention + FFN + Residual                            â”‚
â”‚  ...                                                             â”‚
â”‚  Layer L: Attention + FFN + Residual                            â”‚
â”‚  â€¢ Each layer refines sensor relationship understanding         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Global Pooling (Sequence Aggregation)               â”‚
â”‚  â€¢ Adaptive average pooling over sensor sequence                â”‚
â”‚  â€¢ Aggregates information from all sensors                      â”‚
â”‚  â€¢ Output: (batch, d_model) - fixed-size representation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Output Projection Layer                       â”‚
â”‚  â€¢ Projects aggregated representation â†’ target sensor values    â”‚
â”‚  â€¢ Linear transformation: d_model â†’ N_target_sensors           â”‚
â”‚  â€¢ Final predictions: (batch, N_target_sensors)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              Target Sensor Predictions
```

### ğŸ“Š Stage2 Residual Boost System

Built on top of SST, the Stage2 system further refines predictions:

```
Step 1: Base SST Model
   Boundary Sensors â†’ [SST] â†’ Predictions + Residuals

Step 2: Stage2 Residual Model
   Boundary Sensors â†’ [SSTâ‚‚] â†’ Residual Corrections

Step 3: Intelligent Delta RÂ² Selection
   For each target signal:
     Delta RÂ² = RÂ²_ensemble - RÂ²_stage1
     if Delta RÂ² > threshold: Apply Stage2 correction
     else: Use base SST prediction

Step 4: Final Ensemble Model
   Predictions = Stage1 predictions + selective Stage2 corrections
```

## ğŸ”§ Installation

### Quick Start with Google Colab

```bash
# Clone the repository
!git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
%cd Industrial-digital-twin-by-transformer

# Install dependencies
!pip install -r requirements.txt
```

### Local Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“š Quick Start

### 1. Prepare Your Data

Place your CSV sensor data file in the `data/raw/` folder. Your CSV should have:
- Each row represents a timestep
- Each column represents a sensor measurement
- (Optional) First column can be a timestamp

Example CSV structure:
```csv
timestamp,sensor_1,sensor_2,sensor_3,...,sensor_n
2025-01-01 00:00:00,23.5,101.3,45.2,...,78.9
2025-01-01 00:00:01,23.6,101.4,45.1,...,79.0
...
```

### 2. Train Stage1 Model Using Jupyter Notebook (Basic Training)

This section demonstrates **basic Stage1 (SST) model training** for learning sensor prediction fundamentals.

**Note**: The notebook provides a foundation for understanding the SST architecture and basic training process. For the complete Stage2 Boost training and ensemble model generation, please use the enhanced Gradio interface (Section 3).

**Available Notebooks**:
- `notebooks/transformer_boost_Leap_final.ipynb` - Advanced example with complete Stage1 + Stage2 training on LEAP dataset

**Basic Training Example** (for your own data):

```python
from models.static_transformer import StaticSensorTransformer
from src.data_loader import SensorDataLoader
from src.trainer import ModelTrainer

# Load data
data_loader = SensorDataLoader(data_path='data/raw/your_data.csv')

# Configure signals
boundary_signals = ['sensor_1', 'sensor_2', 'sensor_3']  # Inputs
target_signals = ['sensor_4', 'sensor_5']  # Outputs to predict

# Prepare data
data_splits = data_loader.prepare_data(boundary_signals, target_signals)

# Create and train Stage1 SST model
model = StaticSensorTransformer(
    num_boundary_sensors=len(boundary_signals),
    num_target_sensors=len(target_signals)
)

trainer = ModelTrainer(model, device='cuda')
history = trainer.train(train_loader, val_loader)

# Save trained model
torch.save(model.state_dict(), 'saved_models/my_sst_model.pth')
```

**What you'll learn in Stage1**:
- Loading and preprocessing sensor data
- Configuring boundary and target sensors
- Training the Static Sensor Transformer (SST)
- Basic model evaluation and prediction

**For complete functionality** (Stage2 Boost + Ensemble Models), proceed to Section 3.

### 3. Use Enhanced Gradio Interface (Complete Stage1 + Stage2 Training)

Launch the enhanced interactive web interface with **full Stage1 + Stage2 residual boost training**:

```bash
python gradio_residual_tft_app.py
```

The enhanced interface provides the **complete end-to-end workflow**:
- ğŸ“Š **Data Loading**: Upload CSV or create example data
- ğŸ¯ **Stage1 SST Training**: Configure and train base Static Sensor Transformer models
- ğŸ”¬ **Residual Extraction**: Extract and analyze prediction errors from Stage1 models
- ğŸš€ **Stage2 Boost Training**: Train secondary models on residuals for error correction
- ğŸ¯ **Ensemble Model Generation**: Intelligent Delta RÂ² threshold-based model combination
- ğŸ“Š **Inference Comparison**: Compare Stage1 SST vs. ensemble model performance with visualizations
- ğŸ’¾ **Export**: Automatic model saving with complete configurations

**This is the recommended way to experience the full capabilities of the framework**, including:
- Automated multi-stage training pipeline
- Intelligent signal-wise Stage2 selection
- Comprehensive performance metrics and visualizations
- Production-ready ensemble model generation

**Quick Start Guide**: See `docs/QUICKSTART.md` for a 5-minute tutorial

## ğŸ“– Documentation

### Project Structure

```
Industrial-digital-twin-by-transformer/
â”œâ”€â”€ models/                      # Model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ static_transformer.py    # SST (StaticSensorTransformer)
â”‚   â”œâ”€â”€ utils.py                # Utility functions
â”‚   â””â”€â”€ saved/                  # Saved model checkpoints
â”œâ”€â”€ saved_models/               # Trained models with configs
â”‚   â”œâ”€â”€ StaticSensorTransformer_*.pth   # SST models
â”‚   â”œâ”€â”€ stage2_boost/           # Stage2 residual models
â”‚   â”œâ”€â”€ ensemble/               # Ensemble model configs
â”‚   â””â”€â”€ tft_models/            # TFT models (if used)
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py         # Data loading and preprocessing
â”‚   â”œâ”€â”€ trainer.py             # Training pipeline
â”‚   â””â”€â”€ inference.py           # Inference engine
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ ENHANCED_VERSION_README.md  # Enhanced features guide
â”‚   â”œâ”€â”€ UPDATE_NOTES.md        # Detailed update notes
â”‚   â”œâ”€â”€ QUICKSTART.md          # 5-minute quick start
â”‚   â””â”€â”€ FILE_MANIFEST.md       # File structure guide
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â””â”€â”€ transformer_boost_Leap_final.ipynb  # Advanced Stage1+Stage2 tutorial with LEAP dataset
â”œâ”€â”€ data/                      # Data folder
â”‚   â”œâ”€â”€ raw/                   # Place your CSV files here
â”‚   â””â”€â”€ residuals_*.csv       # Extracted residuals
â”œâ”€â”€ examples/                  # Example scripts
â”‚   â””â”€â”€ quick_start.py        # Quick start example
â”œâ”€â”€ configs/                   # Configuration files
â”œâ”€â”€ archive/                   # Archived old files
â”‚   â”œâ”€â”€ gradio_app.py         # Old simple interface
â”‚   â”œâ”€â”€ gradio_full_interface.py  # Old full interface
â”‚   â””â”€â”€ hybrid_transformer.py  # Deprecated HST model
â”œâ”€â”€ gradio_residual_tft_app.py # ğŸ†• Enhanced Gradio application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package setup
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                # This file
```

### Model APIs

#### StaticSensorTransformer (SST)

```python
from models.static_transformer import StaticSensorTransformer

model = StaticSensorTransformer(
    num_boundary_sensors=10,    # Number of input sensors
    num_target_sensors=5,       # Number of output sensors
    d_model=128,                # Model dimension
    nhead=8,                    # Number of attention heads
    num_layers=3,               # Number of transformer layers
    dropout=0.1                 # Dropout rate
)

# Forward pass
predictions = model(boundary_conditions)  # Shape: (batch_size, num_target_sensors)
```

#### Stage2 Residual Boost Training

```python
# Step 1: Train base SST model
base_model = StaticSensorTransformer(...)
# ... train base model ...

# Step 2: Extract residuals
residuals = true_values - base_model_predictions

# Step 3: Train Stage2 model on residuals
stage2_model = StaticSensorTransformer(...)
# ... train stage2 on residuals ...

# Step 4: Generate ensemble with intelligent Delta RÂ² selection
for signal_idx in range(num_signals):
    r2_base = calculate_r2(true_values[:, signal_idx], base_predictions[:, signal_idx])
    r2_ensemble = calculate_r2(true_values[:, signal_idx], base_pred[:, signal_idx] + stage2_pred[:, signal_idx])
    delta_r2 = r2_ensemble - r2_base

    if delta_r2 > threshold:  # e.g., threshold=0.05 (5% improvement)
        # Use Stage2 correction (significant improvement)
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx] + stage2_pred[:, signal_idx]
    else:
        # Keep base prediction (no significant improvement)
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx]
```

**Note**: The enhanced Gradio interface (`gradio_residual_tft_app.py`) automates this entire workflow.

## ğŸ¯ Performance

### Benchmark Results (Example)

On a typical industrial sensor dataset with 50 boundary sensors and 20 target sensors:

| Model | Average RÂ² | Average MAE | Average RMSE | Training Time | Inference Time |
|-------|-----------|------------|--------------|---------------|----------------|
| **SST (Base)** | 0.92 | 2.34 | 3.45 | ~15 min | 0.5 ms/sample |
| **SST + Stage2 (Ensemble)** | 0.96 | 1.87 | 2.76 | ~30 min | 0.8 ms/sample |

**Performance Improvements with Stage2 Boost:**
- MAE: 15-25% improvement
- RMSE: 12-20% improvement
- RÂ²: Significant improvement for low-RÂ² signals

*Note: Results vary depending on dataset characteristics, RÂ² threshold, and hardware.*

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Install in development mode
pip install -e .

# Run tests (if available)
python -m pytest tests/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Transformer architecture based on "Attention Is All You Need" (Vaswani et al., 2017)
- Inspired by digital twin applications in industrial automation
- Built with PyTorch, Gradio, and the amazing open-source community

## ğŸ“ Contact

For questions, issues, or collaborations:
- **GitHub Issues**: [Create an issue](https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer/issues)
- **Email**: your.email@example.com

## ğŸ”— Citation

If you use this work in your research, please cite:

```bibtex
@software{industrial_digital_twin_transformer,
  author = {Your Name},
  title = {Industrial Digital Twin by Transformer},
  year = {2025},
  url = {https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer}
}
```

## ğŸ—ºï¸ Roadmap

### v1.0 (Current) âœ…
- [x] Stage2 Boost training system
- [x] Intelligent RÂ² threshold selection
- [x] Ensemble model generation
- [x] Inference comparison tools
- [x] Enhanced Gradio interface

### v2.0 (Upcoming)
- [ ] Advanced residual analysis tools
- [ ] Multi-stage boost (Stage3+)
- [ ] Attention visualization
- [ ] Real-time streaming data support
- [ ] Docker containerization
- [ ] REST API for model serving
- [ ] Hyperparameter auto-tuning
- [ ] Additional example datasets

---

**Made with â¤ï¸ for the Industrial AI Community**
