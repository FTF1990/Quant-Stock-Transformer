# Quant-Stock-Transformer

> âš ï¸ **ğŸš§ Under Active Development | å¼€å‘æµ‹è¯•ä¸­ ğŸš§**
>
> This is an experimental quantitative stock prediction framework. Code and documentation are being actively developed and refined.

---

## ğŸ“– Overview | é¡¹ç›®ç®€ä»‹

**Quant-Stock-Transformer** is a novel three-stage quantitative stock prediction framework that achieves resource savings through spatial-temporal separation.

åŸºäºç©ºé—´-æ—¶åºåˆ†ç¦»çš„ä¸‰é˜¶æ®µé‡åŒ–è‚¡ç¥¨é¢„æµ‹æ¡†æ¶ï¼Œé€šè¿‡åˆ†ç¦»ç©ºé—´å…³ç³»å»ºæ¨¡å’Œæ—¶åºæ¼”åŒ–å»ºæ¨¡ï¼Œå®ç°ç®—åŠ›èµ„æºçš„é«˜æ•ˆåˆ©ç”¨ã€‚

### ğŸ¯ Key Innovation | æ ¸å¿ƒåˆ›æ–°

1. **Spatial-Temporal Separation | ç©ºé—´-æ—¶åºåˆ†ç¦»**
   - Stage 1: Static Sensor Transformer (SST) for spatial relationships
   - Stage 2: Internal feature extraction (attention + encoder + residuals)
   - Stage 3: Temporal models for time-series enhancement

2. **AI-Powered Stock Selection | AIé©±åŠ¨çš„è‚¡ç¥¨é€‰æ‹©**
   - LLM-based intelligent stock correlation analysis
   - Support for multiple markets (US, CN, HK, JP)
   - Automatic industry chain analysis

3. **Multi-Model Comparison | å¤šæ¨¡å‹å¯¹æ¯”**
   - SST (baseline)
   - SST + iTransformer
   - SST + LSTM
   - SST + GRU

---

## ğŸš€ Quick Start | å¿«é€Ÿå¼€å§‹

### ğŸ“¦ Installation | å®‰è£…

```bash
# Clone the repository
git clone https://github.com/FTF1990/Quant-Stock-Transformer.git
cd Quant-Stock-Transformer

# Install dependencies
pip install -r requirements.txt
```

### ğŸ® Usage | ä½¿ç”¨æ–¹æ³•

#### Option 1: Google Colab (Recommended | æ¨è)

1. **Stock Selection Agent | è‚¡ç¥¨é€‰æ‹©æ™ºèƒ½ä½“**
   - Open `notebooks/stock_analysis_agent.ipynb` in Google Colab
   - Configure your LLM (Google AI / OpenAI / DeepSeek)
   - Run cells to generate stock list and fetch historical data

2. **Model Training Pipeline | æ¨¡å‹è®­ç»ƒæµç¨‹**
   - Open `notebooks/model_training_pipeline.ipynb` in Google Colab
   - Load the data from Step 1
   - Train and evaluate models

#### Option 2: Local Environment | æœ¬åœ°ç¯å¢ƒ

```python
# Example: Using the SST model
from models.spatial_feature_extractor import SpatialFeatureExtractor

# Create model
model = SpatialFeatureExtractor(
    num_boundary_sensors=23,
    num_target_sensors=1,
    d_model=128,
    nhead=8,
    num_layers=3
)

# Extract internal features
predictions, features = model.forward_with_features(
    boundary_conditions,
    return_attention=True,
    return_encoder_output=True
)
```

---

## ğŸ“š Documentation | æ–‡æ¡£

### Core Documentation | æ ¸å¿ƒæ–‡æ¡£

- **[Feature Extraction Guide](docs/FEATURE_EXTRACTION_GUIDE.md)** - Complete technical guide for extracting SST internal features
- **[SST Internals README](docs/SST_INTERNALS_EXTRACTION_README.md)** - Quick start for feature extraction
- **[Demo Notebook](docs/sst_feature_extraction_demo.md)** - Complete demonstration of the system

### Technical Papers | æŠ€æœ¯æ–‡æ¡£

- **Three-Stage Framework** - Detailed explanation of the spatial-temporal separation approach
- **SST Architecture** - Sensor Sequence Transformer design
- **Feature Engineering** - Attention weights and encoder output analysis

---

## ğŸ—‚ï¸ Project Structure | é¡¹ç›®ç»“æ„

```
Quant-Stock-Transformer/
â”œâ”€â”€ models/                          # Core model implementations
â”‚   â”œâ”€â”€ static_transformer.py        # SST base model
â”‚   â”œâ”€â”€ spatial_feature_extractor.py # SST with feature extraction
â”‚   â”œâ”€â”€ relationship_extractors.py   # Feature extractors
â”‚   â””â”€â”€ temporal_predictor.py        # Temporal models
â”œâ”€â”€ notebooks/                       # Jupyter/Colab notebooks
â”‚   â”œâ”€â”€ stock_analysis_agent.ipynb   # ğŸ¤– AI stock selection agent
â”‚   â””â”€â”€ model_training_pipeline.ipynb # ğŸš€ Complete training pipeline
â”œâ”€â”€ examples/                        # Example scripts
â”‚   â””â”€â”€ extract_sst_internals_demo.py # Feature extraction demo
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ FEATURE_EXTRACTION_GUIDE.md
â”‚   â””â”€â”€ SST_INTERNALS_EXTRACTION_README.md
â””â”€â”€ README.md                        # This file
```

---

## ğŸ¤– AI Stock Analysis Agent | æ™ºèƒ½è‚¡ç¥¨åˆ†æ

### Features | åŠŸèƒ½ç‰¹æ€§

- âœ… **Multi-LLM Support** - Google AI (Gemini), OpenAI, DeepSeek, Custom APIs
- âœ… **Multi-Market Coverage** - US, China A-shares, Hong Kong, Japan
- âœ… **Industry Chain Analysis** - Upstream/downstream/competitors/correlations
- âœ… **Automatic Data Fetching** - Historical data (hourly/daily) with market indices
- âœ… **Configurable Minimums** - Set minimum stocks per market

### Usage Example | ä½¿ç”¨ç¤ºä¾‹

```python
from notebooks.stock_analysis_agent import StockAnalysisAgent, LLMConfig

# Configure LLM
llm_config = LLMConfig(provider="google")  # or "openai", "deepseek"

# Create agent
agent = StockAnalysisAgent(llm_config)

# Analyze industry
result = agent.analyze_industry(
    industry="åŠå¯¼ä½“",  # Semiconductor
    markets=["US", "CN", "HK", "JP"],
    min_stocks_per_market={"US": 8, "CN": 10, "HK": 5, "JP": 5}
)

# Save results
agent.save_results(
    json_path="selected_stocks.json",
    report_path="analysis_report.md"
)
```

---

## ğŸ“ˆ Data Fetching | æ•°æ®è·å–

### Supported Data Sources | æ”¯æŒçš„æ•°æ®æº

- **A-shares (CN)**: AkShare - Open source, no API key required
- **US/HK/JP**: yfinance - Free Yahoo Finance API

### Features | åŠŸèƒ½

- âœ… Hourly or daily data
- âœ… Market indices included
- âœ… OHLCV + Volume
- âœ… Automatic data cleaning
- âœ… Pickle format for fast loading

```python
from notebooks.stock_analysis_agent import StockDataFetcher

fetcher = StockDataFetcher()

historical_data = fetcher.fetch_historical_data(
    stocks_json=selected_stocks,
    start_date="2020-01-01",
    end_date="2024-12-31",
    interval="1d",  # "1h" for hourly
    include_market_index=True
)

fetcher.save_data("historical_data.pkl")
```

---

## ğŸ§  Model Training | æ¨¡å‹è®­ç»ƒ

### Stage 1: SST Training | SSTè®­ç»ƒ

Train a dual-output SST that predicts both T-day and T+1-day returns:

```python
from examples.extract_sst_internals_demo import DualOutputSST

model = DualOutputSST(
    num_boundary_sensors=23,
    num_target_sensors=1,
    d_model=128,
    nhead=8,
    num_layers=3
)

# Train
pred_T, pred_T1 = model(boundary_conditions)
loss = criterion(pred_T, target_T) + criterion(pred_T1, target_T1)
```

### Stage 2: Feature Extraction | ç‰¹å¾æå–

Extract internal features from trained SST:

```python
(pred_T, pred_T1), features = model.forward_with_features(
    boundary_conditions,
    return_attention=True,
    return_encoder_output=True
)

# features contains:
# - attention_weights: [batch, num_layers, num_heads, 23, 23]
# - encoder_output: [batch, 23, 128]
# - embeddings: [batch, 23, 128]
# - pooled_features: [batch, 128]

# Calculate residuals
residual_T = target_T - pred_T
residual_T1 = target_T1 - pred_T1
```

### Stage 3: Temporal Enhancement | æ—¶åºå¢å¼º

Train temporal models using extracted features:

```python
# Prepare LSTM input from extracted features
lstm_input = build_sequence_features(
    attention_features,   # 10-dim
    encoder_features,     # 32-dim
    residual_features     # 2-dim
)  # Result: [batch, sequence_length, 44]

# Train LSTM
lstm = nn.LSTM(input_size=44, hidden_size=64, num_layers=2)
output, (h_n, c_n) = lstm(lstm_input)
```

---

## ğŸ“Š Model Evaluation | æ¨¡å‹è¯„ä¼°

### Metrics | è¯„ä¼°æŒ‡æ ‡

- **MSE** - Mean Squared Error
- **MAE** - Mean Absolute Error
- **Direction Accuracy** - Prediction direction correctness
- **Sharpe Ratio** - Risk-adjusted returns
- **Max Drawdown** - Maximum loss from peak

### Comparison | æ¨¡å‹å¯¹æ¯”

| Model | MSE | MAE | Direction Acc | Sharpe | Status |
|-------|-----|-----|---------------|--------|--------|
| SST (baseline) | - | - | - | - | âœ… Implemented |
| SST + iTransformer | - | - | - | - | ğŸš§ In Progress |
| SST + LSTM | - | - | - | - | ğŸš§ In Progress |
| SST + GRU | - | - | - | - | ğŸš§ In Progress |

*Note: Metrics will be updated after testing phase*

---

## ğŸ› ï¸ Development Status | å¼€å‘çŠ¶æ€

### âœ… Completed | å·²å®Œæˆ

- [x] SST base model implementation
- [x] Spatial feature extractor with attention/encoder extraction
- [x] Dual-output SST (T and T+1 predictions)
- [x] Feature extraction demo
- [x] AI stock analysis agent
- [x] Multi-market data fetcher
- [x] Comprehensive documentation

### ğŸš§ In Progress | è¿›è¡Œä¸­

- [ ] Complete training pipeline notebook
- [ ] Temporal models (iTransformer, LSTM, GRU)
- [ ] Feature dimension reduction
- [ ] Model evaluation and comparison
- [ ] Backtesting framework

### ğŸ“‹ Planned | è®¡åˆ’ä¸­

- [ ] Real-time prediction API
- [ ] Web interface
- [ ] More temporal models (Informer, Autoformer)
- [ ] Ensemble methods
- [ ] Risk management module

---

## ğŸ¤ Contributing | è´¡çŒ®

Contributions are welcome! Please feel free to submit a Pull Request.

æ¬¢è¿è´¡çŒ®ï¼è¯·éšæ—¶æäº¤Pull Requestã€‚

### Development Guidelines | å¼€å‘æŒ‡å—

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License | è®¸å¯è¯

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Contact | è”ç³»æ–¹å¼

- **Issues**: [GitHub Issues](https://github.com/FTF1990/Quant-Stock-Transformer/issues)
- **Discussions**: [GitHub Discussions](https://github.com/FTF1990/Quant-Stock-Transformer/discussions)

---

## ğŸ™ Acknowledgments | è‡´è°¢

- PyTorch team for the excellent deep learning framework
- AkShare for providing free A-share data access
- yfinance for Yahoo Finance data API
- Google AI, OpenAI, DeepSeek for LLM APIs

---

## âš ï¸ Disclaimer | å…è´£å£°æ˜

**This project is for research and educational purposes only. Not financial advice.**

**æœ¬é¡¹ç›®ä»…ä¾›ç ”ç©¶å’Œæ•™è‚²ç›®çš„ä½¿ç”¨ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚**

- Past performance does not guarantee future results
- Stock trading involves substantial risk of loss
- Always do your own research before investing
- The authors are not responsible for any financial losses

---

## ğŸ“ˆ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=FTF1990/Quant-Stock-Transformer&type=Date)](https://star-history.com/#FTF1990/Quant-Stock-Transformer&Date)

---

**Made with â¤ï¸ by the Quant-Stock-Transformer Team**

**ğŸš§ Active Development - Stay Tuned for Updates! | ç§¯æå¼€å‘ä¸­ - æ•¬è¯·æœŸå¾…æ›´æ–°ï¼ğŸš§**
