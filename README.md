# Quant-Stock-Transformer

> âš ï¸ **ğŸš§ Under Active Development | å¼€å‘ä¸­ ğŸš§**
> This is an experimental quantitative stock prediction framework. Code and documentation are being actively developed and refined.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

---

**A novel three-stage quantitative stock prediction framework that achieves resource savings through spatial-temporal separation.**

åŸºäºç©ºé—´-æ—¶åºåˆ†ç¦»çš„é‡åŒ–è‚¡ç¥¨é¢„æµ‹æ¡†æ¶ï¼Œå®ç°ç®—åŠ›èµ„æºèŠ‚çœã€‚

---

## ğŸ¯ Core Idea | æ ¸å¿ƒæ€è·¯

### The Problem | é—®é¢˜

Traditional approach: Directly use TFT to process all stocks' time-series data
```
100 stocks Ã— 30 features Ã— 90 days = 270,000 data points
â†’ Memory: ~2GB, Training: ~10 min/epoch
â†’ Resource intensive! èµ„æºå¯†é›†ï¼
```

### Our Solution | æˆ‘ä»¬çš„æ–¹æ¡ˆ

**Separate spatial (cross-stock) and temporal modeling:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage1: Spatial Feature Extractor (Transformer)         â”‚
â”‚  Input:  Multi-stock cross-section (100 stocks)         â”‚
â”‚  Learn:  Stock relationships, sector effects, index     â”‚
â”‚  Output: Relationship features (32-dim) â† Dimension     â”‚
â”‚          reduction! é™ç»´ï¼                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage3: Temporal Predictor (LSTM/GRU/TCN)               â”‚
â”‚  Input:  Target stock + relationship features           â”‚
â”‚          (30 + 32 = 62 dims)                            â”‚
â”‚  Learn:  Temporal dynamics, trends                      â”‚
â”‚  Output: Final prediction                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Result: 62-dim Ã— 90 days instead of 3000-dim Ã— 90 days
â†’ Memory: ~200MB (save 90%), Training: ~1 min/epoch (10x faster)
```

---

## ğŸ’¡ Why This Works | ä¸ºä»€ä¹ˆæœ‰æ•ˆ

1. **Dimension Reduction | é™ç»´**
   - From 3000 dims (all stocks) â†’ 32 dims (relationship features)
   - Compression ratio: ~1%

2. **Information Preservation | ä¿ç•™ä¿¡æ¯**
   - Relationship features capture market structure
   - Attention mechanism learns "who affects whom"

3. **Model Specialization | æ¨¡å‹ä¸“ç²¾**
   - Transformer: Excellent at spatial relationships
   - LSTM/GRU: Excellent at temporal sequences
   - Each does what it's best at | æœ¯ä¸šæœ‰ä¸“æ”»

---

## ğŸ“Š Architecture | æ¶æ„

### Stage1: Cross-Stock Relationship Learning
```python
# At time t, snapshot of all stocks (cross-section)
Input: [Stock1_features, Stock2_features, ..., Stock100_features, Index_features]
       Shape: [batch, 3090-dim]  # 103 stocks Ã— 30 features

â†“ Transformer (Spatial attention)

Output: Relationship embedding for target stock
        Shape: [batch, 32-dim]
```

**What does it learn? | å­¦ä»€ä¹ˆï¼Ÿ**
- Which stocks influence the target stock?
- How strong is the index correlation?
- Sector rotation signals?

### Stage3: Temporal Prediction
```python
# Combine target stock features + relationship features
for each day in [Day1, Day2, ..., Day60]:
    features[day] = concat([
        target_stock_features[day],  # 30-dim
        relationship_features[day]    # 32-dim (from Stage1)
    ])  # Total: 62-dim

â†“ LSTM/GRU/TCN

Output: Future return prediction
```

---


**ğŸš§ Status: Under Active Development | ç§¯æå¼€å‘ä¸­**

We're actively refining the code and documentation. Expect frequent updates!
