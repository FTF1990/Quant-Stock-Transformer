# ä¸‰é˜¶æ®µè‚¡ç¥¨é¢„æµ‹æ¡†æ¶ - å¿«é€Ÿå¼€å§‹

## ğŸ¯ æ ¸å¿ƒæ€æƒ³

å°†**ç©ºé—´å…³ç³»å­¦ä¹ **å’Œ**æ—¶åºé¢„æµ‹**åˆ†ç¦»ï¼Œå……åˆ†åˆ©ç”¨ä¸åŒæ¨¡å‹çš„ä¼˜åŠ¿ï¼š

```
å¤šè‚¡ç¥¨æ•°æ® â†’ Stage1 (Transformer) â†’ å…³ç³»ç‰¹å¾ (é™ç»´)
                                      â†“
ç›®æ ‡è‚¡ç¥¨æ—¶åº + å…³ç³»ç‰¹å¾ â†’ Stage3 (LSTM/GRU/TCN) â†’ æœ€ç»ˆé¢„æµ‹
```

**èµ„æºèŠ‚çœ**: ~90% å†…å­˜å ç”¨, ~90% è®­ç»ƒæ—¶é—´ (ç›¸æ¯”ç›´æ¥ä½¿ç”¨TFTå¤„ç†æ‰€æœ‰è‚¡ç¥¨)

---

## ğŸ“ æ–°å¢æ–‡ä»¶

### æ ¸å¿ƒä»£ç 

1. **`models/relationship_extractors.py`** - å…³ç³»ç‰¹å¾æå–å™¨
   - `AttentionBasedExtractor`: åŸºäºAttentionæƒé‡
   - `EmbeddingBasedExtractor`: åŸºäºTransformerè¾“å‡º
   - `HybridExtractor`: æ··åˆæ–¹æ¡ˆ (æ¨è)

2. **`models/spatial_feature_extractor.py`** - Stage1æ‰©å±•ç‰ˆ
   - æ·»åŠ ç‰¹å¾æå–æ¥å£
   - æ”¯æŒè·å–attentionæƒé‡å’Œencoderè¾“å‡º

3. **`models/temporal_predictor.py`** - Stage3æ—¶åºæ¨¡å‹
   - `LSTMTemporalPredictor`: è½»é‡çº§ï¼Œé€‚åˆé•¿åºåˆ—
   - `GRUTemporalPredictor`: æ›´è½»é‡
   - `TCNTemporalPredictor`: æœ€å¿«ï¼Œå¹¶è¡Œè®¡ç®—

4. **`src/three_stage_pipeline.py`** - å®Œæ•´Pipeline
   - ç«¯åˆ°ç«¯è®­ç»ƒå’Œæ¨ç†
   - æ¨¡å‹ä¿å­˜/åŠ è½½
   - æ‰¹é‡ç‰¹å¾æå–

### æ–‡æ¡£å’Œæ•™ç¨‹

5. **`ARCHITECTURE_DESIGN.md`** - è¯¦ç»†æ¶æ„è®¾è®¡æ–‡æ¡£
6. **`notebooks/three_stage_tutorial.ipynb`** - äº¤äº’å¼æ•™ç¨‹
7. **`QUICKSTART_THREE_STAGE.md`** - æœ¬æ–‡ä»¶

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ¡ˆA: ä½¿ç”¨Pipeline (æ¨è)

```python
from src.three_stage_pipeline import ThreeStagePipeline

# 1. é…ç½®
pipeline = ThreeStagePipeline(
    stock_codes=['000001', '000002', '600000'],
    index_codes=['sh000001', 'sz399001'],
    target_stock='000001',
    feature_columns=['close', 'volume', 'MA5', 'MA20', 'RSI'],
    relationship_dim=32,
    seq_len=60
)

# 2. è®­ç»ƒStage1
pipeline.build_stage1(d_model=128, nhead=8, num_layers=3)
pipeline.train_stage1(train_df, val_df, num_epochs=50)

# 3. æå–å…³ç³»ç‰¹å¾
pipeline.build_relationship_extractor(extractor_type='hybrid')
df_with_rel = pipeline.extract_relationship_features(df)

# 4. è®­ç»ƒStage3
pipeline.build_stage3(model_type='lstm')
pipeline.train_stage3(df_with_rel, target_column='target_return_1d')

# 5. æ¨ç†
predictions = pipeline.predict(test_df)

# 6. ä¿å­˜
pipeline.save_pipeline('saved_models/my_pipeline')
```

### æ–¹æ¡ˆB: é€æ­¥æ„å»º

#### Step 1: è®­ç»ƒStage1 (ä½¿ç”¨ç°æœ‰Gradioç•Œé¢)

```bash
# ä½¿ç”¨ç°æœ‰çš„Gradioåº”ç”¨è®­ç»ƒStage1
python gradio_sensor_transformer_app.py

# åœ¨Tab2ä¸­è®­ç»ƒï¼Œä¼šå¾—åˆ°:
# - saved_models/stage1_model.pth
# - saved_models/stage2_model.pth (å¯é€‰)
```

#### Step 2: æå–å…³ç³»ç‰¹å¾

```python
from models.spatial_feature_extractor import SpatialFeatureExtractor
from models.relationship_extractors import HybridExtractor
import torch
import pandas as pd

# åŠ è½½è®­ç»ƒå¥½çš„Stage1æ¨¡å‹
model = SpatialFeatureExtractor(
    num_boundary_sensors=100,  # æ ¹æ®å®é™…è°ƒæ•´
    num_target_sensors=5,
    d_model=128
)
model.load_state_dict(torch.load('saved_models/stage1_model.pth'))
model.eval()

# åˆ›å»ºå…³ç³»ç‰¹å¾æå–å™¨
extractor = HybridExtractor(
    num_stocks=10,
    num_indices=3,
    d_model=128,
    output_dim=32
)

# æå–ç‰¹å¾
df = pd.read_csv('data/data.csv')
# ... (å‚è€ƒpipelineä»£ç )
```

#### Step 3: è®­ç»ƒStage3

```python
from models.temporal_predictor import LSTMTemporalPredictor, TemporalDataset
import torch

# å‡†å¤‡æ•°æ®
dataset = TemporalDataset(
    target_stock_features=stock_features,
    relationship_features=rel_features,
    targets=targets,
    seq_len=60
)

dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)

# åˆ›å»ºæ¨¡å‹
model = LSTMTemporalPredictor(
    input_dim=30 + 32,  # è‚¡ç¥¨ç‰¹å¾ + å…³ç³»ç‰¹å¾
    hidden_dim=128,
    output_dim=1
)

# è®­ç»ƒ
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
criterion = torch.nn.MSELoss()

for epoch in range(100):
    for batch_seq, batch_target in dataloader:
        optimizer.zero_grad()
        predictions = model(batch_seq)
        loss = criterion(predictions, batch_target)
        loss.backward()
        optimizer.step()
```

---

## ğŸ“Š ä½¿ç”¨æ•™ç¨‹

### Jupyter Notebookæ•™ç¨‹

```bash
jupyter notebook notebooks/three_stage_tutorial.ipynb
```

åŒ…å«:
- å®Œæ•´è®­ç»ƒæµç¨‹
- å…³ç³»ç‰¹å¾å¯è§†åŒ–
- Attentionæƒé‡åˆ†æ
- æ¨¡å‹å¯¹æ¯”
- æ€§èƒ½è¯„ä¼°

---

## ğŸ”§ æ¨èé…ç½®

### å°è§„æ¨¡ (5-10åªè‚¡ç¥¨, æ—¥çº¿)

```python
pipeline = ThreeStagePipeline(
    stock_codes=stocks[:10],
    relationship_dim=16,
    seq_len=60
)

pipeline.build_stage1(d_model=64, nhead=4, num_layers=2)
pipeline.build_stage3(model_type='gru', hidden_dim=64)
```

**é¢„æœŸèµ„æº**: ~500MBå†…å­˜, ~2åˆ†é’Ÿ/epoch

### ä¸­ç­‰è§„æ¨¡ (10-30åªè‚¡ç¥¨, æ—¥çº¿)

```python
pipeline = ThreeStagePipeline(
    stock_codes=stocks[:30],
    relationship_dim=32,
    seq_len=90
)

pipeline.build_stage1(d_model=128, nhead=8, num_layers=3)
pipeline.build_stage3(model_type='lstm', hidden_dim=128)
```

**é¢„æœŸèµ„æº**: ~2GBå†…å­˜, ~5åˆ†é’Ÿ/epoch

### å¤§è§„æ¨¡ (30+åªè‚¡ç¥¨æˆ–åˆ†é’Ÿçº¿)

```python
pipeline = ThreeStagePipeline(
    stock_codes=stocks,
    relationship_dim=64,
    seq_len=120
)

pipeline.build_stage1(d_model=256, nhead=8, num_layers=4)
pipeline.build_stage3(model_type='tcn')  # ä½¿ç”¨TCNæ›´å¿«
```

**é¢„æœŸèµ„æº**: ~8GBå†…å­˜, ~10åˆ†é’Ÿ/epoch

---

## ğŸ’¡ å…³é”®å‚æ•°è¯´æ˜

### `relationship_dim` (å…³ç³»ç‰¹å¾ç»´åº¦)

- **å¤ªå°** (< 16): å¯èƒ½ä¸¢å¤±é‡è¦å¸‚åœºä¿¡æ¯
- **å¤ªå¤§** (> 64): å¢åŠ Stage3è®¡ç®—é‡ï¼Œè¿‡æ‹Ÿåˆé£é™©
- **æ¨è**: 16-32 (å°è§„æ¨¡), 32-64 (å¤§è§„æ¨¡)

### `seq_len` (æ—¶åºçª—å£é•¿åº¦)

- **å¤ªçŸ­** (< 30): æ— æ³•æ•è·é•¿æœŸè¶‹åŠ¿
- **å¤ªé•¿** (> 120): è®­ç»ƒæ…¢ï¼Œæ¢¯åº¦é—®é¢˜
- **æ¨è**: 60-90å¤© (æ—¥çº¿), 240-480åˆ†é’Ÿ (åˆ†é’Ÿçº¿)

### å…³ç³»ç‰¹å¾æå–å™¨ç±»å‹

- **`attention`**: å¯è§£é‡Šæ€§å¼ºï¼Œç»´åº¦è¾ƒé«˜
- **`embedding`**: ä¿¡æ¯ä¸°å¯Œï¼Œç»´åº¦å¯æ§
- **`hybrid`**: ç»¼åˆä¼˜åŠ¿ (æ¨è)

### Stage3æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | é€Ÿåº¦ | å†…å­˜ | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|------|------|------|------|----------|
| GRU  | â­â­â­ | â­â­â­ | â­â­ | èµ„æºå—é™ |
| LSTM | â­â­ | â­â­ | â­â­â­ | é€šç”¨ (æ¨è) |
| TCN  | â­â­â­â­ | â­â­ | â­â­â­ | å¤§è§„æ¨¡æ•°æ® |

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### ä¸ä¼ ç»Ÿæ–¹æ¡ˆå¯¹æ¯”

**æ–¹æ¡ˆ1: ç›´æ¥TFTå¤„ç†æ‰€æœ‰è‚¡ç¥¨**
```
è¾“å…¥: 20è‚¡ç¥¨ Ã— 30ç‰¹å¾ = 600ç»´
åºåˆ—: 90å¤©
å†…å­˜: ~2GB
è®­ç»ƒ: ~10åˆ†é’Ÿ/epoch
```

**æ–¹æ¡ˆ2: ä¸‰é˜¶æ®µæ¶æ„ (æœ¬æ–¹æ¡ˆ)**
```
Stage1è¾“å…¥: 600ç»´ â†’ å…³ç³»ç‰¹å¾: 32ç»´
Stage3è¾“å…¥: 30 + 32 = 62ç»´
åºåˆ—: 90å¤©
å†…å­˜: ~200MB (èŠ‚çœ90%)
è®­ç»ƒ: ~1åˆ†é’Ÿ/epoch (å¿«10å€)
```

**æ€§èƒ½**: ç›¸è¿‘æˆ–æ›´å¥½ (å› ä¸ºå…³ç³»ç‰¹å¾æ›´é²æ£’)

---

## ğŸ” è°ƒè¯•å’Œå¯è§†åŒ–

### æŸ¥çœ‹Attentionæƒé‡

```python
from models.relationship_extractors import visualize_attention_relationships

attention_weights = pipeline.stage1_model.get_attention_weights(data)
avg_attention = attention_weights.mean(dim=[0, 1])

visualize_attention_relationships(
    avg_attention,
    stock_names=['000001', '000002', ...],
    target_stock_idx=0,
    save_path='attention.png'
)
```

### åˆ†æå…³ç³»ç‰¹å¾

```python
import seaborn as sns
import matplotlib.pyplot as plt

# å…³ç³»ç‰¹å¾ç›¸å…³æ€§
relationship_cols = [f'relationship_{i}' for i in range(32)]
corr = df[relationship_cols].corr()

sns.heatmap(corr, cmap='coolwarm')
plt.savefig('relationship_correlation.png')
```

### æ£€æŸ¥ç‰¹å¾é‡è¦æ€§

```python
# ä½¿ç”¨LSTM with attentionæ—¶
predictions, attn_weights = model(data, return_attention=True)

# attn_weightsæ˜¾ç¤ºå“ªäº›æ—¶é—´æ­¥æœ€é‡è¦
plt.plot(attn_weights[0].cpu().numpy())
plt.title('Temporal Attention Weights')
plt.show()
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: Stage1è®­ç»ƒå¥½åï¼Œèƒ½å¦ç”¨äºå¤šä¸ªä¸åŒçš„ç›®æ ‡è‚¡ç¥¨?

**A**: å¯ä»¥ï¼Stage1å­¦ä¹ çš„æ˜¯æ‰€æœ‰è‚¡ç¥¨çš„å…³ç³»è¡¨ç¤ºï¼Œå¯ä»¥é‡å¤ä½¿ç”¨ã€‚åªéœ€è¦:
```python
# ä¸ºä¸åŒç›®æ ‡è‚¡ç¥¨æå–å…³ç³»ç‰¹å¾
for target_stock in ['000001', '000002', '600000']:
    pipeline.target_stock = target_stock
    rel_features = pipeline.extract_relationship_features(df)
    # è®­ç»ƒå„è‡ªçš„Stage3
```

### Q2: å¯ä»¥å¢é‡æ›´æ–°å…³ç³»ç‰¹å¾å—?

**A**: å¯ä»¥ã€‚Stage1è®­ç»ƒå¥½åï¼Œæå–æ–°æ•°æ®çš„å…³ç³»ç‰¹å¾éå¸¸å¿«:
```python
# æ¯æ—¥æ›´æ–°
today_data = fetch_today_data()
today_rel_features = pipeline.extract_relationship_features(today_data)
```

### Q3: å¦‚ä½•é€‰æ‹©è‚¡ç¥¨æ± ?

**A**: å»ºè®®:
- åŒ…å«ç›®æ ‡è‚¡ç¥¨æ‰€åœ¨æ¿å—çš„ä¸»è¦è‚¡ç¥¨
- åŒ…å«ç›¸å…³è¡Œä¸šçš„ä»£è¡¨æ€§è‚¡ç¥¨
- åŒ…å«å¸‚åœºæŒ‡æ•° (ä¸Šè¯ã€æ·±è¯ã€åˆ›ä¸šæ¿ç­‰)
- æ€»æ•°10-30åªä¸ºå®œ (å¤ªå°‘ä¿¡æ¯ä¸è¶³ï¼Œå¤ªå¤šè®¡ç®—æ…¢)

### Q4: å…³ç³»ç‰¹å¾æ˜¯å¦éœ€è¦æ ‡å‡†åŒ–?

**A**: å»ºè®®æ ‡å‡†åŒ–ã€‚æå–å™¨è¾“å‡ºçš„ç‰¹å¾å¯èƒ½scaleä¸ä¸€è‡´:
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
rel_features_scaled = scaler.fit_transform(rel_features)
```

### Q5: Stage2æ®‹å·®æå‡åœ¨å“ªé‡Œ?

**A**: å½“å‰å®ç°ä¸“æ³¨Stage1å’ŒStage3ã€‚Stage2å¯ä»¥è¿™æ ·åŠ å…¥:
```python
# åœ¨Stage1åŸºç¡€ä¸Šè®­ç»ƒStage2
# ç„¶åæå–å…³ç³»ç‰¹å¾æ—¶ä½¿ç”¨ensemble
rel_features_stage1 = extract_from_stage1(data)
rel_features_stage2 = extract_from_stage2(data)
rel_features = combine(rel_features_stage1, rel_features_stage2)
```

---

## ğŸ“š è¿›ä¸€æ­¥é˜…è¯»

- **`ARCHITECTURE_DESIGN.md`**: è¯¦ç»†è®¾è®¡æ–‡æ¡£
- **`notebooks/three_stage_tutorial.ipynb`**: äº¤äº’å¼æ•™ç¨‹
- **`models/relationship_extractors.py`**: æŸ¥çœ‹å„ç§æå–å™¨çš„å®ç°
- **`models/temporal_predictor.py`**: æŸ¥çœ‹æ—¶åºæ¨¡å‹å®ç°

---

## ğŸ“ æœ€ä½³å®è·µ

1. **å…ˆç”¨å°è§„æ¨¡éªŒè¯**: ç”¨5-10åªè‚¡ç¥¨å¿«é€Ÿå®éªŒ
2. **å…³æ³¨æ•°æ®è´¨é‡**: ç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼è¿‡æ»¤
3. **ç‰¹å¾å·¥ç¨‹**: æ·»åŠ é¢†åŸŸçŸ¥è¯†ç‰¹å¾ (å¦‚æ¿å—ã€è¡Œä¸š)
4. **æ­£åˆ™åŒ–**: é€‚å½“ä½¿ç”¨dropout, weight decay
5. **æ—©åœ**: ç›‘æ§éªŒè¯é›†ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
6. **æ»šåŠ¨éªŒè¯**: ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
7. **é›†æˆå­¦ä¹ **: è®­ç»ƒå¤šä¸ªStage3æ¨¡å‹æŠ•ç¥¨

---

## ğŸ”— ç›¸å…³èµ„æº

- PyTorch Forecasting: https://pytorch-forecasting.readthedocs.io/
- Temporal Fusion Transformerè®ºæ–‡: https://arxiv.org/abs/1912.09363
- AkShareæ•°æ®æº: https://akshare.akfamily.xyz/

---

**ç¥å®éªŒé¡ºåˆ©! æœ‰é—®é¢˜è¯·æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£æˆ–æissueã€‚** ğŸš€
