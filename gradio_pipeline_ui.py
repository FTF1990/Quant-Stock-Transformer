"""
Gradioå¯è§†åŒ–è®­ç»ƒPipeline UI
====================================

åŠŸèƒ½ï¼š
- åˆ†æ­¥éª¤å¯è§†åŒ–å±•ç¤ºå®Œæ•´è®­ç»ƒæµç¨‹
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- æ•°æ®å¯è§†åŒ–
- æ¨¡å‹è®­ç»ƒæ›²çº¿
- æ€§èƒ½å¯¹æ¯”å›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python gradio_pipeline_ui.py

ä½œè€…ï¼šQuant-Stock-Transformer Team
ç‰ˆæœ¬ï¼š1.0.0
"""

import gradio as gr
import json
import pickle
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import torch
from datetime import datetime
import plotly.graph_objects as go
import plotly.express as px
from typing import Dict, Tuple, Optional

# å¯¼å…¥pipelineæ¨¡å—
from complete_training_pipeline import (
    StockDataFetcher,
    StockDataProcessor,
    DualOutputSST,
    ModelTrainer,
    ModelEvaluator,
    LSTMTemporalPredictor,
    GRUTemporalPredictor,
    TCNTemporalPredictor,
    TemporalDataset
)
from torch.utils.data import DataLoader

# è®¾ç½®ç»˜å›¾æ ·å¼
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# å…¨å±€çŠ¶æ€å­˜å‚¨
class PipelineState:
    """å­˜å‚¨pipelineæ‰§è¡ŒçŠ¶æ€"""
    def __init__(self):
        self.stocks_json = None
        self.historical_data = None
        self.processed_data = None
        self.sst_model = None
        self.lstm_model = None
        self.gru_model = None
        self.tcn_model = None
        self.trainer = None
        self.evaluator = None
        self.results = {}
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

state = PipelineState()


# ============================================================================
# æ­¥éª¤1ï¼šåŠ è½½è‚¡ç¥¨JSON
# ============================================================================

def load_stocks_json(json_file):
    """åŠ è½½å¹¶æ˜¾ç¤ºè‚¡ç¥¨åˆ—è¡¨"""
    try:
        if json_file is None:
            return "âŒ è¯·ä¸Šä¼ JSONæ–‡ä»¶", None, None

        # è¯»å–JSON
        with open(json_file.name, 'r', encoding='utf-8') as f:
            stocks_json = json.load(f)

        state.stocks_json = stocks_json

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_stocks = sum(len(v) for v in stocks_json.values())

        stats_text = f"""
## âœ… è‚¡ç¥¨åˆ—è¡¨åŠ è½½æˆåŠŸ

**æ€»è‚¡ç¥¨æ•°**: {total_stocks}åª

**å¸‚åœºåˆ†å¸ƒ**:
"""
        for market, stocks in stocks_json.items():
            stats_text += f"- **{market}å¸‚åœº**: {len(stocks)}åª\n"

        # ç”Ÿæˆè¯¦ç»†è¡¨æ ¼
        rows = []
        for market, stocks in stocks_json.items():
            for stock in stocks:
                rows.append({
                    'å¸‚åœº': market,
                    'ä»£ç ': stock['symbol'],
                    'åç§°': stock['name'],
                    'ç±»åˆ«': stock.get('category', 'N/A'),
                    'ç†ç”±': stock.get('reason', 'N/A')
                })

        df = pd.DataFrame(rows)

        # ç”Ÿæˆå¸‚åœºåˆ†å¸ƒé¥¼å›¾
        market_counts = {market: len(stocks) for market, stocks in stocks_json.items()}
        fig = px.pie(
            values=list(market_counts.values()),
            names=list(market_counts.keys()),
            title='è‚¡ç¥¨å¸‚åœºåˆ†å¸ƒ'
        )

        return stats_text, df, fig

    except Exception as e:
        return f"âŒ åŠ è½½å¤±è´¥: {str(e)}", None, None


# ============================================================================
# æ­¥éª¤2ï¼šæ•°æ®æŠ“å–
# ============================================================================

def fetch_historical_data(
    target_market,
    start_date,
    end_date,
    batch_size,
    delay_between_batches,
    progress=gr.Progress()
):
    """æŠ“å–å†å²æ•°æ®"""
    try:
        if state.stocks_json is None:
            return "âŒ è¯·å…ˆåŠ è½½è‚¡ç¥¨JSON", None

        progress(0, desc="åˆå§‹åŒ–æ•°æ®æŠ“å–...")

        fetcher = StockDataFetcher()

        # æŠ“å–æ•°æ®
        progress(0.2, desc="å¼€å§‹æŠ“å–æ•°æ®...")
        historical_data = fetcher.fetch_historical_data(
            stocks_json=state.stocks_json,
            start_date=start_date,
            end_date=end_date,
            interval="1d",
            include_market_index=True,
            batch_size=int(batch_size),
            delay_between_batches=float(delay_between_batches)
        )

        state.historical_data = historical_data

        progress(0.8, desc="ä¿å­˜æ•°æ®...")
        fetcher.save_data("historical_data.pkl")

        progress(1.0, desc="å®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… æ•°æ®æŠ“å–å®Œæˆ

**æ—¥æœŸèŒƒå›´**: {start_date} è‡³ {end_date}
**ç›®æ ‡å¸‚åœº**: {target_market}

**æ•°æ®ç»Ÿè®¡**:
"""

        rows = []
        for market, stocks_data in historical_data.items():
            for symbol, df in stocks_data.items():
                rows.append({
                    'å¸‚åœº': market,
                    'ä»£ç ': symbol,
                    'æ•°æ®æ¡æ•°': len(df),
                    'å¼€å§‹æ—¥æœŸ': df.index[0].strftime('%Y-%m-%d') if len(df) > 0 else 'N/A',
                    'ç»“æŸæ—¥æœŸ': df.index[-1].strftime('%Y-%m-%d') if len(df) > 0 else 'N/A'
                })

        df_stats = pd.DataFrame(rows)

        # æ£€æŸ¥ç›®æ ‡å¸‚åœºçš„æ•°æ®
        if target_market in historical_data:
            market_data = historical_data[target_market]
            stats_text += f"\n**{target_market}å¸‚åœº**: æˆåŠŸè·å–{len(market_data)}æ”¯è‚¡ç¥¨æ•°æ®\n"
        else:
            stats_text += f"\nâš ï¸ **{target_market}å¸‚åœºæ•°æ®æœªæ‰¾åˆ°**\n"

        return stats_text, df_stats

    except Exception as e:
        return f"âŒ æ•°æ®æŠ“å–å¤±è´¥: {str(e)}", None


# ============================================================================
# æ­¥éª¤3ï¼šæ•°æ®é¢„å¤„ç†
# ============================================================================

def preprocess_data(target_market, target_stock, progress=gr.Progress()):
    """æ•°æ®é¢„å¤„ç†"""
    try:
        if state.historical_data is None:
            return "âŒ è¯·å…ˆæŠ“å–å†å²æ•°æ®", None, None

        progress(0, desc="å¼€å§‹æ•°æ®é¢„å¤„ç†...")

        processor = StockDataProcessor(
            historical_data=state.historical_data,
            target_market=target_market,
            target_stock=target_stock
        )

        progress(0.3, desc="è®¡ç®—ç‰¹å¾...")
        X, y_T, y_T1, dates = processor.prepare_training_data()

        progress(0.6, desc="æ•°æ®é›†åˆ’åˆ†...")
        # æ•°æ®é›†åˆ’åˆ†
        train_size = int(0.7 * len(X))
        val_size = int(0.15 * len(X))

        X_train = X[:train_size]
        y_T_train = y_T[:train_size]
        y_T1_train = y_T1[:train_size]

        X_val = X[train_size:train_size+val_size]
        y_T_val = y_T[train_size:train_size+val_size]
        y_T1_val = y_T1[train_size:train_size+val_size]

        X_test = X[train_size+val_size:]
        y_T_test = y_T[train_size+val_size:]
        y_T1_test = y_T1[train_size+val_size:]

        # ä¿å­˜åˆ°çŠ¶æ€
        state.processed_data = {
            'X_train': X_train, 'y_T_train': y_T_train, 'y_T1_train': y_T1_train,
            'X_val': X_val, 'y_T_val': y_T_val, 'y_T1_val': y_T1_val,
            'X_test': X_test, 'y_T_test': y_T_test, 'y_T1_test': y_T1_test,
            'dates': dates,
            'processor': processor
        }

        progress(1.0, desc="å®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ

**ç›®æ ‡è‚¡ç¥¨**: {target_market} - {target_stock}

**æ•°æ®é›†åˆ’åˆ†**:
- è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ (70%)
- éªŒè¯é›†: {len(X_val)} æ ·æœ¬ (15%)
- æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬ (15%)

**ç‰¹å¾ç»´åº¦**: {X.shape[1]}

**ç›®æ ‡å˜é‡**:
- Tæ—¥æ”¶ç›Šç‡: {y_T.shape}
- T+1æ—¥æ”¶ç›Šç‡: {y_T1.shape}
"""

        # ç»˜åˆ¶æ”¶ç›Šç‡åˆ†å¸ƒ
        fig, axes = plt.subplots(1, 2, figsize=(12, 4))

        axes[0].hist(y_T_train, bins=50, alpha=0.7, edgecolor='black')
        axes[0].set_title('Tæ—¥æ”¶ç›Šç‡åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰')
        axes[0].set_xlabel('æ”¶ç›Šç‡')
        axes[0].set_ylabel('é¢‘æ•°')
        axes[0].grid(True, alpha=0.3)

        axes[1].hist(y_T1_train, bins=50, alpha=0.7, edgecolor='black')
        axes[1].set_title('T+1æ—¥æ”¶ç›Šç‡åˆ†å¸ƒï¼ˆè®­ç»ƒé›†ï¼‰')
        axes[1].set_xlabel('æ”¶ç›Šç‡')
        axes[1].set_ylabel('é¢‘æ•°')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        return stats_text, fig, None

    except Exception as e:
        return f"âŒ é¢„å¤„ç†å¤±è´¥: {str(e)}", None, None


# ============================================================================
# æ­¥éª¤4ï¼šSSTæ¨¡å‹è®­ç»ƒ
# ============================================================================

def train_sst_model(epochs, batch_size, learning_rate, progress=gr.Progress()):
    """è®­ç»ƒSSTæ¨¡å‹"""
    try:
        if state.processed_data is None:
            return "âŒ è¯·å…ˆå®Œæˆæ•°æ®é¢„å¤„ç†", None

        progress(0, desc="åˆå§‹åŒ–SSTæ¨¡å‹...")

        # è·å–æ•°æ®
        data = state.processed_data
        num_features = data['X_train'].shape[1]

        # åˆ›å»ºæ¨¡å‹
        sst_model = DualOutputSST(
            num_boundary_sensors=num_features,
            num_target_sensors=1,
            d_model=128,
            nhead=8,
            num_layers=3,
            dropout=0.1,
            enable_feature_extraction=True
        ).to(state.device)

        state.sst_model = sst_model

        # åˆ›å»ºè®­ç»ƒå™¨
        if state.trainer is None:
            state.trainer = ModelTrainer(device=state.device)

        progress(0.1, desc="å¼€å§‹è®­ç»ƒ...")

        # è®­ç»ƒ
        history = state.trainer.train_sst(
            sst_model,
            data['X_train'], data['y_T_train'], data['y_T1_train'],
            data['X_val'], data['y_T_val'], data['y_T1_val'],
            epochs=int(epochs),
            batch_size=int(batch_size),
            lr=float(learning_rate),
            verbose=False
        )

        progress(1.0, desc="è®­ç»ƒå®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        best_val_loss = min(history['val_loss'])
        final_train_loss = history['train_loss'][-1]

        stats_text = f"""
## âœ… SSTæ¨¡å‹è®­ç»ƒå®Œæˆ

**æ¨¡å‹å‚æ•°**: {sum(p.numel() for p in sst_model.parameters()):,}

**è®­ç»ƒé…ç½®**:
- Epochs: {epochs}
- Batch Size: {batch_size}
- Learning Rate: {learning_rate}

**è®­ç»ƒç»“æœ**:
- æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}
- æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}
"""

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        # æ€»æŸå¤±
        axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)
        axes[0].plot(history['val_loss'], label='Val Loss', linewidth=2)
        axes[0].set_title('SSTè®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        # Tå’ŒT+1åˆ†åˆ«çš„æŸå¤±
        axes[1].plot(history['train_loss_T'], label='Train Loss (Tæ—¥)', linewidth=2)
        axes[1].plot(history['train_loss_T1'], label='Train Loss (T+1æ—¥)', linewidth=2)
        axes[1].plot(history['val_loss_T'], label='Val Loss (Tæ—¥)', linewidth=2, linestyle='--')
        axes[1].plot(history['val_loss_T1'], label='Val Loss (T+1æ—¥)', linewidth=2, linestyle='--')
        axes[1].set_title('SSTåˆ†é¡¹æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('Loss')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()

        return stats_text, fig

    except Exception as e:
        return f"âŒ SSTè®­ç»ƒå¤±è´¥: {str(e)}", None


# ============================================================================
# æ­¥éª¤5ï¼šç‰¹å¾æå–
# ============================================================================

def extract_features(progress=gr.Progress()):
    """æå–SSTå†…éƒ¨ç‰¹å¾"""
    try:
        if state.sst_model is None:
            return "âŒ è¯·å…ˆè®­ç»ƒSSTæ¨¡å‹", None

        progress(0, desc="å¼€å§‹ç‰¹å¾æå–...")

        data = state.processed_data

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T_all = np.vstack([data['y_T_train'], data['y_T_val'], data['y_T_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])

        progress(0.3, desc="æå–ç‰¹å¾...")

        # æå–ç‰¹å¾
        state.sst_model.eval()
        with torch.no_grad():
            X_all_t = torch.FloatTensor(X_all).to(state.device)
            (pred_T, pred_T1), features = state.sst_model.forward_with_features(
                X_all_t,
                return_attention=True,
                return_encoder_output=True
            )

            encoder_output = features['encoder_output'].cpu().numpy()
            pooled_features = features['pooled_features'].cpu().numpy()

            # è®¡ç®—æ®‹å·®
            residual_T = y_T_all - pred_T.cpu().numpy()
            residual_T1 = y_T1_all - pred_T1.cpu().numpy()

        progress(0.7, desc="å‡†å¤‡æ—¶åºæ•°æ®...")

        # ä¿å­˜ç‰¹å¾
        state.processed_data['encoder_output'] = encoder_output
        state.processed_data['pooled_features'] = pooled_features
        state.processed_data['residual_T'] = residual_T
        state.processed_data['residual_T1'] = residual_T1

        progress(1.0, desc="å®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
## âœ… ç‰¹å¾æå–å®Œæˆ

**æå–çš„ç‰¹å¾**:
- Encoderè¾“å‡º: {encoder_output.shape}
- æ± åŒ–ç‰¹å¾: {pooled_features.shape}
- Tæ—¥æ®‹å·®: {residual_T.shape}
- T+1æ—¥æ®‹å·®: {residual_T1.shape}

**ç‰¹å¾ç»Ÿè®¡**:
- æ± åŒ–ç‰¹å¾å‡å€¼: {np.mean(pooled_features):.6f}
- æ± åŒ–ç‰¹å¾æ ‡å‡†å·®: {np.std(pooled_features):.6f}
"""

        # ç»˜åˆ¶ç‰¹å¾å¯è§†åŒ–
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        # æ± åŒ–ç‰¹å¾åˆ†å¸ƒ
        axes[0, 0].hist(pooled_features.flatten(), bins=50, alpha=0.7, edgecolor='black')
        axes[0, 0].set_title('æ± åŒ–ç‰¹å¾åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[0, 0].set_xlabel('ç‰¹å¾å€¼')
        axes[0, 0].set_ylabel('é¢‘æ•°')
        axes[0, 0].grid(True, alpha=0.3)

        # æ®‹å·®åˆ†å¸ƒ
        axes[0, 1].hist(residual_T1.flatten(), bins=50, alpha=0.7, edgecolor='black', color='orange')
        axes[0, 1].set_title('T+1æ—¥é¢„æµ‹æ®‹å·®åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        axes[0, 1].set_xlabel('æ®‹å·®')
        axes[0, 1].set_ylabel('é¢‘æ•°')
        axes[0, 1].grid(True, alpha=0.3)

        # æ± åŒ–ç‰¹å¾çƒ­å›¾ï¼ˆå‰10ç»´ï¼‰
        feature_sample = pooled_features[:100, :10]
        im = axes[1, 0].imshow(feature_sample.T, aspect='auto', cmap='viridis')
        axes[1, 0].set_title('æ± åŒ–ç‰¹å¾çƒ­å›¾ï¼ˆæ ·æœ¬Ã—ç‰¹å¾ï¼‰', fontsize=12, fontweight='bold')
        axes[1, 0].set_xlabel('æ ·æœ¬')
        axes[1, 0].set_ylabel('ç‰¹å¾ç»´åº¦')
        plt.colorbar(im, ax=axes[1, 0])

        # æ®‹å·®æ—¶é—´åºåˆ—
        axes[1, 1].plot(residual_T1[:500], alpha=0.7, linewidth=1)
        axes[1, 1].set_title('T+1æ—¥æ®‹å·®æ—¶é—´åºåˆ—ï¼ˆå‰500æ ·æœ¬ï¼‰', fontsize=12, fontweight='bold')
        axes[1, 1].set_xlabel('æ ·æœ¬ç´¢å¼•')
        axes[1, 1].set_ylabel('æ®‹å·®')
        axes[1, 1].grid(True, alpha=0.3)
        axes[1, 1].axhline(y=0, color='r', linestyle='--', linewidth=1)

        plt.tight_layout()

        return stats_text, fig

    except Exception as e:
        return f"âŒ ç‰¹å¾æå–å¤±è´¥: {str(e)}", None


# ============================================================================
# æ­¥éª¤6ï¼šæ—¶åºæ¨¡å‹è®­ç»ƒ
# ============================================================================

def train_temporal_models(
    model_type,
    epochs,
    batch_size,
    learning_rate,
    seq_len,
    progress=gr.Progress()
):
    """è®­ç»ƒæ—¶åºæ¨¡å‹"""
    try:
        if 'pooled_features' not in state.processed_data:
            return "âŒ è¯·å…ˆæå–ç‰¹å¾", None

        progress(0, desc=f"åˆå§‹åŒ–{model_type}æ¨¡å‹...")

        data = state.processed_data

        # å‡†å¤‡æ•°æ®
        train_size = len(data['X_train'])
        val_size = len(data['X_val'])

        # åˆå¹¶æ‰€æœ‰æ•°æ®
        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])
        pooled_features = data['pooled_features']

        # åˆ›å»ºæ—¶åºæ•°æ®é›†
        target_stock_features = torch.FloatTensor(X_all)
        relationship_features = torch.FloatTensor(pooled_features)
        targets = torch.FloatTensor(y_T1_all)

        train_dataset = TemporalDataset(
            target_stock_features=target_stock_features[:train_size],
            relationship_features=relationship_features[:train_size],
            targets=targets[:train_size],
            seq_len=int(seq_len)
        )

        val_dataset = TemporalDataset(
            target_stock_features=target_stock_features[train_size:train_size+val_size],
            relationship_features=relationship_features[train_size:train_size+val_size],
            targets=targets[train_size:train_size+val_size],
            seq_len=int(seq_len)
        )

        train_loader = DataLoader(train_dataset, batch_size=int(batch_size), shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=int(batch_size), shuffle=False)

        progress(0.1, desc="åˆ›å»ºæ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹
        input_dim = X_all.shape[1] + pooled_features.shape[1]

        if model_type == 'LSTM':
            model = LSTMTemporalPredictor(
                input_dim=input_dim,
                hidden_dim=128,
                num_layers=2,
                output_dim=1,
                use_attention=True
            ).to(state.device)
            state.lstm_model = model
        elif model_type == 'GRU':
            model = GRUTemporalPredictor(
                input_dim=input_dim,
                hidden_dim=128,
                num_layers=2,
                output_dim=1,
                use_attention=True
            ).to(state.device)
            state.gru_model = model
        elif model_type == 'TCN':
            model = TCNTemporalPredictor(
                input_dim=input_dim,
                num_channels=[64, 128, 128, 64],
                kernel_size=3,
                output_dim=1
            ).to(state.device)
            state.tcn_model = model
        else:
            return f"âŒ æœªçŸ¥çš„æ¨¡å‹ç±»å‹: {model_type}", None

        progress(0.2, desc="å¼€å§‹è®­ç»ƒ...")

        # è®­ç»ƒ
        if state.trainer is None:
            state.trainer = ModelTrainer(device=state.device)

        history = state.trainer.train_temporal_model(
            model,
            train_loader,
            val_loader,
            epochs=int(epochs),
            lr=float(learning_rate),
            model_name=model_type,
            verbose=False
        )

        progress(1.0, desc="è®­ç»ƒå®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        best_val_loss = min(history['val_loss'])
        final_train_loss = history['train_loss'][-1]

        stats_text = f"""
## âœ… {model_type}æ¨¡å‹è®­ç»ƒå®Œæˆ

**æ¨¡å‹å‚æ•°**: {sum(p.numel() for p in model.parameters()):,}

**è®­ç»ƒé…ç½®**:
- Epochs: {epochs}
- Batch Size: {batch_size}
- Learning Rate: {learning_rate}
- Sequence Length: {seq_len}

**è®­ç»ƒç»“æœ**:
- æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.6f}
- æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_train_loss:.6f}

**æ•°æ®é›†**:
- è®­ç»ƒæ ·æœ¬: {len(train_dataset)}
- éªŒè¯æ ·æœ¬: {len(val_dataset)}
"""

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        fig, ax = plt.subplots(figsize=(10, 6))

        ax.plot(history['train_loss'], label='Train Loss', linewidth=2)
        ax.plot(history['val_loss'], label='Val Loss', linewidth=2)
        ax.set_title(f'{model_type}è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.legend()
        ax.grid(True, alpha=0.3)

        plt.tight_layout()

        return stats_text, fig

    except Exception as e:
        return f"âŒ {model_type}è®­ç»ƒå¤±è´¥: {str(e)}", None


# ============================================================================
# æ­¥éª¤7ï¼šæ¨¡å‹è¯„ä¼°
# ============================================================================

def evaluate_all_models(seq_len, progress=gr.Progress()):
    """è¯„ä¼°æ‰€æœ‰æ¨¡å‹"""
    try:
        if state.sst_model is None:
            return "âŒ è¯·å…ˆè®­ç»ƒæ¨¡å‹", None, None

        progress(0, desc="åˆå§‹åŒ–è¯„ä¼°...")

        # åˆ›å»ºè¯„ä¼°å™¨
        if state.evaluator is None:
            state.evaluator = ModelEvaluator(device=state.device)

        data = state.processed_data

        # è¯„ä¼°SST
        progress(0.2, desc="è¯„ä¼°SSTæ¨¡å‹...")
        sst_metrics = state.evaluator.evaluate_sst(
            state.sst_model,
            data['X_test'],
            data['y_T_test'],
            data['y_T1_test'],
            model_name='SST'
        )

        # å‡†å¤‡æ—¶åºæ¨¡å‹æµ‹è¯•æ•°æ®
        train_size = len(data['X_train'])
        val_size = len(data['X_val'])

        X_all = np.vstack([data['X_train'], data['X_val'], data['X_test']])
        y_T1_all = np.vstack([data['y_T1_train'], data['y_T1_val'], data['y_T1_test']])
        pooled_features = data['pooled_features']

        target_stock_features = torch.FloatTensor(X_all)
        relationship_features = torch.FloatTensor(pooled_features)
        targets = torch.FloatTensor(y_T1_all)

        test_dataset = TemporalDataset(
            target_stock_features=target_stock_features[train_size+val_size:],
            relationship_features=relationship_features[train_size+val_size:],
            targets=targets[train_size+val_size:],
            seq_len=int(seq_len)
        )

        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

        # è¯„ä¼°æ—¶åºæ¨¡å‹
        if state.lstm_model is not None:
            progress(0.4, desc="è¯„ä¼°LSTMæ¨¡å‹...")
            lstm_metrics = state.evaluator.evaluate_temporal_model(
                state.lstm_model, test_loader, model_name='LSTM'
            )

        if state.gru_model is not None:
            progress(0.6, desc="è¯„ä¼°GRUæ¨¡å‹...")
            gru_metrics = state.evaluator.evaluate_temporal_model(
                state.gru_model, test_loader, model_name='GRU'
            )

        if state.tcn_model is not None:
            progress(0.8, desc="è¯„ä¼°TCNæ¨¡å‹...")
            tcn_metrics = state.evaluator.evaluate_temporal_model(
                state.tcn_model, test_loader, model_name='TCN'
            )

        progress(0.9, desc="ç”Ÿæˆå¯¹æ¯”...")

        # ç”Ÿæˆå¯¹æ¯”
        comparison_df = state.evaluator.compare_models()

        progress(1.0, desc="å®Œæˆï¼")

        # ç”Ÿæˆç»Ÿè®¡æ–‡æœ¬
        stats_text = """
## âœ… æ¨¡å‹è¯„ä¼°å®Œæˆ

**å·²è¯„ä¼°çš„æ¨¡å‹**:
"""
        for model_name in state.evaluator.results.keys():
            stats_text += f"- {model_name}\n"

        stats_text += "\nè¯¦ç»†æŒ‡æ ‡è¯·æŸ¥çœ‹ä¸‹æ–¹å¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨ã€‚"

        # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        models = list(state.evaluator.results.keys())

        # æ—¶åºæ¨¡å‹çš„æŒ‡æ ‡ï¼ˆæ’é™¤SSTï¼‰
        temporal_models = [m for m in models if m != 'SST']

        if len(temporal_models) > 0:
            mse_values = [state.evaluator.results[m]['metrics']['MSE'] for m in temporal_models]
            mae_values = [state.evaluator.results[m]['metrics']['MAE'] for m in temporal_models]
            dir_acc_values = [state.evaluator.results[m]['metrics']['Direction_Acc'] for m in temporal_models]
            sharpe_values = [state.evaluator.results[m]['metrics']['Sharpe_Ratio'] for m in temporal_models]

            # MSEå¯¹æ¯”
            axes[0, 0].bar(temporal_models, mse_values, alpha=0.7, edgecolor='black')
            axes[0, 0].set_title('MSEå¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[0, 0].set_ylabel('MSE')
            axes[0, 0].grid(True, alpha=0.3, axis='y')

            # MAEå¯¹æ¯”
            axes[0, 1].bar(temporal_models, mae_values, alpha=0.7, edgecolor='black', color='orange')
            axes[0, 1].set_title('MAEå¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[0, 1].set_ylabel('MAE')
            axes[0, 1].grid(True, alpha=0.3, axis='y')

            # Direction Accuracyå¯¹æ¯”
            axes[1, 0].bar(temporal_models, dir_acc_values, alpha=0.7, edgecolor='black', color='green')
            axes[1, 0].set_title('æ–¹å‘å‡†ç¡®ç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[1, 0].set_ylabel('å‡†ç¡®ç‡')
            axes[1, 0].axhline(y=0.5, color='r', linestyle='--', linewidth=1, label='éšæœºçŒœæµ‹')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3, axis='y')

            # Sharpe Ratioå¯¹æ¯”
            axes[1, 1].bar(temporal_models, sharpe_values, alpha=0.7, edgecolor='black', color='purple')
            axes[1, 1].set_title('Sharpeæ¯”ç‡å¯¹æ¯”', fontsize=12, fontweight='bold')
            axes[1, 1].set_ylabel('Sharpe Ratio')
            axes[1, 1].grid(True, alpha=0.3, axis='y')

        plt.tight_layout()

        return stats_text, comparison_df, fig

    except Exception as e:
        return f"âŒ è¯„ä¼°å¤±è´¥: {str(e)}", None, None


# ============================================================================
# Gradioç•Œé¢
# ============================================================================

def create_ui():
    """åˆ›å»ºGradio UI"""

    with gr.Blocks(title="è‚¡ç¥¨é¢„æµ‹Pipelineå¯è§†åŒ–", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
# ğŸš€ è‚¡ç¥¨é¢„æµ‹æ¨¡å‹è®­ç»ƒPipeline

å®Œæ•´çš„ç«¯åˆ°ç«¯è®­ç»ƒæµç¨‹å¯è§†åŒ–ç•Œé¢

**åŠŸèƒ½**:
- âœ… é€‰è‚¡JSONå¯¼å…¥
- âœ… å†å²æ•°æ®è·å–
- âœ… æ•°æ®é¢„å¤„ç†
- âœ… SSTæ¨¡å‹è®­ç»ƒ
- âœ… ç‰¹å¾æå–
- âœ… æ—¶åºæ¨¡å‹è®­ç»ƒï¼ˆLSTM/GRU/TCNï¼‰
- âœ… æ¨¡å‹è¯„ä¼°å¯¹æ¯”

---
        """)

        # ========================================================================
        # æ­¥éª¤1ï¼šåŠ è½½JSON
        # ========================================================================

        with gr.Tab("ğŸ“‹ æ­¥éª¤1: åŠ è½½è‚¡ç¥¨JSON"):
            gr.Markdown("### ä¸Šä¼ ä½ çš„è‚¡ç¥¨é€‰æ‹©JSONæ–‡ä»¶")

            with gr.Row():
                json_file = gr.File(
                    label="ä¸Šä¼ JSONæ–‡ä»¶",
                    file_types=[".json"],
                    type="filepath"
                )

            load_btn = gr.Button("ğŸ“¥ åŠ è½½è‚¡ç¥¨åˆ—è¡¨", variant="primary", size="lg")

            with gr.Row():
                json_stats = gr.Markdown()

            with gr.Row():
                stocks_table = gr.DataFrame(label="è‚¡ç¥¨è¯¦ç»†åˆ—è¡¨")

            with gr.Row():
                market_chart = gr.Plot(label="å¸‚åœºåˆ†å¸ƒ")

            load_btn.click(
                fn=load_stocks_json,
                inputs=[json_file],
                outputs=[json_stats, stocks_table, market_chart]
            )

        # ========================================================================
        # æ­¥éª¤2ï¼šæ•°æ®æŠ“å–
        # ========================================================================

        with gr.Tab("ğŸ“Š æ­¥éª¤2: æ•°æ®æŠ“å–"):
            gr.Markdown("### æŠ“å–å†å²è‚¡ç¥¨æ•°æ®")

            with gr.Row():
                with gr.Column():
                    target_market = gr.Dropdown(
                        choices=['US', 'CN', 'HK', 'JP'],
                        value='CN',
                        label="ç›®æ ‡å¸‚åœº"
                    )
                    start_date = gr.Textbox(
                        value="2020-01-01",
                        label="å¼€å§‹æ—¥æœŸ (YYYY-MM-DD)"
                    )
                    end_date = gr.Textbox(
                        value="2024-12-31",
                        label="ç»“æŸæ—¥æœŸ (YYYY-MM-DD)"
                    )

                with gr.Column():
                    batch_size = gr.Slider(
                        minimum=1,
                        maximum=10,
                        value=5,
                        step=1,
                        label="æ‰¹é‡å¤§å°"
                    )
                    delay_between_batches = gr.Slider(
                        minimum=0.5,
                        maximum=5.0,
                        value=2.0,
                        step=0.5,
                        label="æ‰¹æ¬¡é—´å»¶è¿Ÿï¼ˆç§’ï¼‰"
                    )

            fetch_btn = gr.Button("ğŸ“¥ å¼€å§‹æŠ“å–æ•°æ®", variant="primary", size="lg")

            with gr.Row():
                fetch_stats = gr.Markdown()

            with gr.Row():
                fetch_table = gr.DataFrame(label="æ•°æ®æŠ“å–ç»Ÿè®¡")

            fetch_btn.click(
                fn=fetch_historical_data,
                inputs=[target_market, start_date, end_date, batch_size, delay_between_batches],
                outputs=[fetch_stats, fetch_table]
            )

        # ========================================================================
        # æ­¥éª¤3ï¼šæ•°æ®é¢„å¤„ç†
        # ========================================================================

        with gr.Tab("ğŸ”„ æ­¥éª¤3: æ•°æ®é¢„å¤„ç†"):
            gr.Markdown("### æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹")

            with gr.Row():
                target_stock = gr.Textbox(
                    value="600519",
                    label="ç›®æ ‡è‚¡ç¥¨ä»£ç "
                )

            preprocess_btn = gr.Button("ğŸ”„ å¼€å§‹é¢„å¤„ç†", variant="primary", size="lg")

            with gr.Row():
                preprocess_stats = gr.Markdown()

            with gr.Row():
                preprocess_plot = gr.Plot(label="æ”¶ç›Šç‡åˆ†å¸ƒ")

            preprocess_btn.click(
                fn=preprocess_data,
                inputs=[target_market, target_stock],
                outputs=[preprocess_stats, preprocess_plot, gr.State()]
            )

        # ========================================================================
        # æ­¥éª¤4ï¼šSSTè®­ç»ƒ
        # ========================================================================

        with gr.Tab("ğŸ§  æ­¥éª¤4: SSTæ¨¡å‹è®­ç»ƒ"):
            gr.Markdown("### è®­ç»ƒåŒè¾“å‡ºSSTæ¨¡å‹")

            with gr.Row():
                with gr.Column():
                    sst_epochs = gr.Slider(
                        minimum=10,
                        maximum=200,
                        value=50,
                        step=10,
                        label="è®­ç»ƒè½®æ•°"
                    )
                    sst_batch_size = gr.Slider(
                        minimum=8,
                        maximum=128,
                        value=32,
                        step=8,
                        label="æ‰¹é‡å¤§å°"
                    )

                with gr.Column():
                    sst_lr = gr.Slider(
                        minimum=0.0001,
                        maximum=0.01,
                        value=0.001,
                        step=0.0001,
                        label="å­¦ä¹ ç‡"
                    )

            sst_train_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒSST", variant="primary", size="lg")

            with gr.Row():
                sst_stats = gr.Markdown()

            with gr.Row():
                sst_plot = gr.Plot(label="è®­ç»ƒæ›²çº¿")

            sst_train_btn.click(
                fn=train_sst_model,
                inputs=[sst_epochs, sst_batch_size, sst_lr],
                outputs=[sst_stats, sst_plot]
            )

        # ========================================================================
        # æ­¥éª¤5ï¼šç‰¹å¾æå–
        # ========================================================================

        with gr.Tab("ğŸ” æ­¥éª¤5: ç‰¹å¾æå–"):
            gr.Markdown("### æå–SSTå†…éƒ¨ç‰¹å¾")

            extract_btn = gr.Button("ğŸ” å¼€å§‹ç‰¹å¾æå–", variant="primary", size="lg")

            with gr.Row():
                extract_stats = gr.Markdown()

            with gr.Row():
                extract_plot = gr.Plot(label="ç‰¹å¾å¯è§†åŒ–")

            extract_btn.click(
                fn=extract_features,
                inputs=[],
                outputs=[extract_stats, extract_plot]
            )

        # ========================================================================
        # æ­¥éª¤6ï¼šæ—¶åºæ¨¡å‹è®­ç»ƒ
        # ========================================================================

        with gr.Tab("â° æ­¥éª¤6: æ—¶åºæ¨¡å‹è®­ç»ƒ"):
            gr.Markdown("### è®­ç»ƒLSTM/GRU/TCNæ—¶åºæ¨¡å‹")

            with gr.Row():
                with gr.Column():
                    temporal_model_type = gr.Dropdown(
                        choices=['LSTM', 'GRU', 'TCN'],
                        value='LSTM',
                        label="æ¨¡å‹ç±»å‹"
                    )
                    temporal_epochs = gr.Slider(
                        minimum=10,
                        maximum=200,
                        value=100,
                        step=10,
                        label="è®­ç»ƒè½®æ•°"
                    )
                    temporal_batch_size = gr.Slider(
                        minimum=8,
                        maximum=128,
                        value=32,
                        step=8,
                        label="æ‰¹é‡å¤§å°"
                    )

                with gr.Column():
                    temporal_lr = gr.Slider(
                        minimum=0.0001,
                        maximum=0.01,
                        value=0.001,
                        step=0.0001,
                        label="å­¦ä¹ ç‡"
                    )
                    temporal_seq_len = gr.Slider(
                        minimum=20,
                        maximum=120,
                        value=60,
                        step=10,
                        label="åºåˆ—é•¿åº¦"
                    )

            temporal_train_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒæ—¶åºæ¨¡å‹", variant="primary", size="lg")

            with gr.Row():
                temporal_stats = gr.Markdown()

            with gr.Row():
                temporal_plot = gr.Plot(label="è®­ç»ƒæ›²çº¿")

            temporal_train_btn.click(
                fn=train_temporal_models,
                inputs=[temporal_model_type, temporal_epochs, temporal_batch_size,
                        temporal_lr, temporal_seq_len],
                outputs=[temporal_stats, temporal_plot]
            )

        # ========================================================================
        # æ­¥éª¤7ï¼šæ¨¡å‹è¯„ä¼°
        # ========================================================================

        with gr.Tab("ğŸ“ˆ æ­¥éª¤7: æ¨¡å‹è¯„ä¼°"):
            gr.Markdown("### è¯„ä¼°æ‰€æœ‰æ¨¡å‹å¹¶å¯¹æ¯”æ€§èƒ½")

            with gr.Row():
                eval_seq_len = gr.Slider(
                    minimum=20,
                    maximum=120,
                    value=60,
                    step=10,
                    label="åºåˆ—é•¿åº¦ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰"
                )

            eval_btn = gr.Button("ğŸ“Š å¼€å§‹è¯„ä¼°", variant="primary", size="lg")

            with gr.Row():
                eval_stats = gr.Markdown()

            with gr.Row():
                eval_table = gr.DataFrame(label="æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨")

            with gr.Row():
                eval_plot = gr.Plot(label="æ€§èƒ½å¯¹æ¯”å›¾")

            eval_btn.click(
                fn=evaluate_all_models,
                inputs=[eval_seq_len],
                outputs=[eval_stats, eval_table, eval_plot]
            )

        # ========================================================================
        # ä½¿ç”¨è¯´æ˜
        # ========================================================================

        with gr.Tab("ğŸ“– ä½¿ç”¨è¯´æ˜"):
            gr.Markdown("""
## ğŸ“– ä½¿ç”¨æµç¨‹

### 1ï¸âƒ£ åŠ è½½è‚¡ç¥¨JSON
- ä¸Šä¼ ä½ çš„è‚¡ç¥¨é€‰æ‹©JSONæ–‡ä»¶ï¼ˆå¦‚`data/demo.json`ï¼‰
- æŸ¥çœ‹è‚¡ç¥¨åˆ—è¡¨å’Œå¸‚åœºåˆ†å¸ƒ

### 2ï¸âƒ£ æ•°æ®æŠ“å–
- é€‰æ‹©ç›®æ ‡å¸‚åœºï¼ˆUS/CN/HK/JPï¼‰
- è®¾ç½®æ—¥æœŸèŒƒå›´
- é…ç½®æ‰¹é‡æŠ“å–å‚æ•°ï¼ˆé¿å…APIé™æµï¼‰
- ç‚¹å‡»"å¼€å§‹æŠ“å–æ•°æ®"

### 3ï¸âƒ£ æ•°æ®é¢„å¤„ç†
- è¾“å…¥ç›®æ ‡è‚¡ç¥¨ä»£ç 
- è‡ªåŠ¨è®¡ç®—æ”¶ç›Šç‡
- æ•°æ®é›†åˆ’åˆ†ï¼ˆ70% train, 15% val, 15% testï¼‰

### 4ï¸âƒ£ SSTæ¨¡å‹è®­ç»ƒ
- é…ç½®è®­ç»ƒå‚æ•°ï¼ˆepochs, batch size, learning rateï¼‰
- è®­ç»ƒåŒè¾“å‡ºSSTæ¨¡å‹
- æŸ¥çœ‹è®­ç»ƒæ›²çº¿

### 5ï¸âƒ£ ç‰¹å¾æå–
- ä»SSTæ¨¡å‹æå–å†…éƒ¨ç‰¹å¾
- åŒ…æ‹¬ï¼šEncoderè¾“å‡ºã€Attentionæƒé‡ã€æ± åŒ–ç‰¹å¾ã€æ®‹å·®

### 6ï¸âƒ£ æ—¶åºæ¨¡å‹è®­ç»ƒ
- é€‰æ‹©æ¨¡å‹ç±»å‹ï¼ˆLSTM/GRU/TCNï¼‰
- é…ç½®è®­ç»ƒå‚æ•°
- å¯ä»¥è®­ç»ƒå¤šä¸ªæ¨¡å‹è¿›è¡Œå¯¹æ¯”

### 7ï¸âƒ£ æ¨¡å‹è¯„ä¼°
- è¯„ä¼°æ‰€æœ‰è®­ç»ƒçš„æ¨¡å‹
- æŸ¥çœ‹æ€§èƒ½å¯¹æ¯”è¡¨å’Œå›¾è¡¨
- æŒ‡æ ‡ï¼šMSE, MAE, Direction Accuracy, Sharpe Ratio

---

## ğŸ’¡ æç¤º

- **æ•°æ®æŠ“å–**: å»ºè®®ä½¿ç”¨é»˜è®¤çš„æ‰¹é‡å‚æ•°ï¼Œé¿å…APIé™æµ
- **SSTè®­ç»ƒ**: 50ä¸ªepoché€šå¸¸è¶³å¤Ÿï¼Œå¯ä»¥å…ˆç”¨å°epochæ•°æµ‹è¯•
- **æ—¶åºæ¨¡å‹**: LSTMå’ŒGRUæ€§èƒ½æ¥è¿‘ï¼ŒTCNè®­ç»ƒæ›´å¿«
- **åºåˆ—é•¿åº¦**: 60å¤©æ˜¯å¸¸ç”¨å€¼ï¼Œå¯æ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

**SSTæ¨¡å‹**:
- åŒè¾“å‡ºæ¶æ„ï¼ˆTæ—¥ + T+1æ—¥ï¼‰
- Transformerç¼–ç å™¨ï¼ˆ8 heads, 3 layersï¼‰
- éšè—ç»´åº¦ï¼š128

**æ—¶åºæ¨¡å‹**:
- LSTM: 128 hidden, 2 layers, with Attention
- GRU: 128 hidden, 2 layers, with Attention
- TCN: [64, 128, 128, 64] channels

**è¯„ä¼°æŒ‡æ ‡**:
- MSE: å‡æ–¹è¯¯å·®
- MAE: å¹³å‡ç»å¯¹è¯¯å·®
- Direction Accuracy: æ–¹å‘å‡†ç¡®ç‡
- Sharpe Ratio: é£é™©è°ƒæ•´åæ”¶ç›Š

---

## ğŸ“ å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ
1. æ£€æŸ¥JSONæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
2. ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ï¼ˆæ•°æ®æŠ“å–éœ€è¦ï¼‰
3. æŸ¥çœ‹ç»ˆç«¯é”™è¯¯ä¿¡æ¯
4. å‚è€ƒREADME.mdæ–‡æ¡£

---

**Quant-Stock-Transformer Team** | Version 1.0.0
            """)

    return demo


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

if __name__ == "__main__":
    demo = create_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,              # Set to True for public URL (useful for Colab)
        show_error=True,
        debug=False
    )
